From c4158f6ba91c90294e2f73bb25b5769f5a2a5a52 Mon Sep 17 00:00:00 2001
From: "H.J. Lu" <hjl.tools@gmail.com>
Date: Tue, 14 Apr 2020 10:43:52 -0700
Subject: [PATCH 4/7] Apply Intel CET patches for Linux kernel 5.8

---
 ...ocumentation-x86-Add-CET-description.patch | 220 +++++++
 ...Add-CET-CPU-feature-flags-for-Contro.patch |  53 ++
 ...ntroduce-CET-MSR-XSAVES-supervisor-s.patch | 205 +++++++
 ...Add-control-protection-fault-handler.patch | 157 +++++
 ...d-Kconfig-option-for-user-mode-Shado.patch |  79 +++
 ...Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch | 195 ++++++
 ...-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch |  48 ++
 0008-x86-mm-Introduce-_PAGE_COW.patch         | 371 ++++++++++++
 ...ange-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch |  29 +
 ...6-mm-Update-pte_modify-for-_PAGE_COW.patch |  83 +++
 ...ep_set_wrprotect-and-pmdp_set_wrprot.patch | 116 ++++
 ...uce-VM_SHSTK-for-shadow-stack-memory.patch |  82 +++
 ...adow-Stack-page-fault-error-checking.patch |  95 +++
 ...pdate-maybe_mkwrite-for-shadow-stack.patch | 132 ++++
 ...laces-that-call-pte_mkwrite-directly.patch |  80 +++
 ...dd-guard-pages-around-a-shadow-stack.patch |  98 +++
 ...dow-stack-pages-to-memory-accounting.patch |  83 +++
 ...an_follow_write_pte-for-shadow-stack.patch |  80 +++
 ...shstk-User-mode-shadow-stack-support.patch | 378 ++++++++++++
 ...hstk-Handle-signals-for-shadow-stack.patch | 569 ++++++++++++++++++
 ...e-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch |  36 ++
 ...LF-Introduce-arch_setup_elf_property.patch |  55 ++
 ...-ELF-header-parsing-for-shadow-stack.patch |  98 +++
 ...cet-shstk-Handle-thread-shadow-stack.patch | 149 +++++
 ...d-arch_prctl-functions-for-shadow-st.patch | 324 ++++++++++
 ...Kconfig-option-for-user-mode-Indirec.patch |  52 ++
 ...-mode-Indirect-Branch-Tracking-suppo.patch | 178 ++++++
 ...le-signals-for-Indirect-Branch-Track.patch | 105 ++++
 ...header-parsing-for-Indirect-Branch-T.patch |  52 ++
 ...arch_prctl-functions-for-Indirect-Br.patch |  51 ++
 ...x86-cet-Add-PTRACE-interface-for-CET.patch | 151 +++++
 ...ENDBR32-to-__kernel_vsyscall-entry-p.patch |  31 +
 ...-vdso-Insert-endbr32-endbr64-to-vDSO.patch |  34 ++
 ...yscall-emulation-when-CET-is-enabled.patch |  59 ++
 ...la-sections-when-CONFIG_RELOCATABLE-.patch |  56 ++
 ...u.property-sections-in-generic-NOTES.patch |  81 +++
 ...est-x86-Enable-CET-for-selftests-x86.patch |  54 ++
 0038-selftest-x86-Fix-sigreturn_64-test.patch |  93 +++
 ...lftest-x86-Fix-sysret_rip-with-ENDBR.patch |  46 ++
 0040-selftest-x86-Add-CET-quick-test.patch    | 191 ++++++
 kernel.spec                                   |  41 ++
 41 files changed, 5090 insertions(+)
 create mode 100644 0001-Documentation-x86-Add-CET-description.patch
 create mode 100644 0002-x86-cpufeatures-Add-CET-CPU-feature-flags-for-Contro.patch
 create mode 100644 0003-x86-fpu-xstate-Introduce-CET-MSR-XSAVES-supervisor-s.patch
 create mode 100644 0004-x86-cet-Add-control-protection-fault-handler.patch
 create mode 100644 0005-x86-cet-shstk-Add-Kconfig-option-for-user-mode-Shado.patch
 create mode 100644 0006-x86-mm-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch
 create mode 100644 0007-x86-mm-Remove-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch
 create mode 100644 0008-x86-mm-Introduce-_PAGE_COW.patch
 create mode 100644 0009-drm-i915-gvt-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch
 create mode 100644 0010-x86-mm-Update-pte_modify-for-_PAGE_COW.patch
 create mode 100644 0011-x86-mm-Update-ptep_set_wrprotect-and-pmdp_set_wrprot.patch
 create mode 100644 0012-mm-Introduce-VM_SHSTK-for-shadow-stack-memory.patch
 create mode 100644 0013-x86-mm-Shadow-Stack-page-fault-error-checking.patch
 create mode 100644 0014-x86-mm-Update-maybe_mkwrite-for-shadow-stack.patch
 create mode 100644 0015-mm-Fixup-places-that-call-pte_mkwrite-directly.patch
 create mode 100644 0016-mm-Add-guard-pages-around-a-shadow-stack.patch
 create mode 100644 0017-mm-mmap-Add-shadow-stack-pages-to-memory-accounting.patch
 create mode 100644 0018-mm-Update-can_follow_write_pte-for-shadow-stack.patch
 create mode 100644 0019-x86-cet-shstk-User-mode-shadow-stack-support.patch
 create mode 100644 0020-x86-cet-shstk-Handle-signals-for-shadow-stack.patch
 create mode 100644 0021-binfmt_elf-Define-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch
 create mode 100644 0022-ELF-Introduce-arch_setup_elf_property.patch
 create mode 100644 0023-x86-cet-shstk-ELF-header-parsing-for-shadow-stack.patch
 create mode 100644 0024-x86-cet-shstk-Handle-thread-shadow-stack.patch
 create mode 100644 0025-x86-cet-shstk-Add-arch_prctl-functions-for-shadow-st.patch
 create mode 100644 0026-x86-cet-ibt-Add-Kconfig-option-for-user-mode-Indirec.patch
 create mode 100644 0027-x86-cet-ibt-User-mode-Indirect-Branch-Tracking-suppo.patch
 create mode 100644 0028-x86-cet-ibt-Handle-signals-for-Indirect-Branch-Track.patch
 create mode 100644 0029-x86-cet-ibt-ELF-header-parsing-for-Indirect-Branch-T.patch
 create mode 100644 0030-x86-cet-ibt-Add-arch_prctl-functions-for-Indirect-Br.patch
 create mode 100644 0031-x86-cet-Add-PTRACE-interface-for-CET.patch
 create mode 100644 0032-x86-vdso-32-Add-ENDBR32-to-__kernel_vsyscall-entry-p.patch
 create mode 100644 0033-x86-vdso-Insert-endbr32-endbr64-to-vDSO.patch
 create mode 100644 0034-x86-Disallow-vsyscall-emulation-when-CET-is-enabled.patch
 create mode 100644 0035-powerpc-Keep-.rela-sections-when-CONFIG_RELOCATABLE-.patch
 create mode 100644 0036-Discard-.note.gnu.property-sections-in-generic-NOTES.patch
 create mode 100644 0037-selftest-x86-Enable-CET-for-selftests-x86.patch
 create mode 100644 0038-selftest-x86-Fix-sigreturn_64-test.patch
 create mode 100644 0039-selftest-x86-Fix-sysret_rip-with-ENDBR.patch
 create mode 100644 0040-selftest-x86-Add-CET-quick-test.patch

diff --git a/0001-Documentation-x86-Add-CET-description.patch b/0001-Documentation-x86-Add-CET-description.patch
new file mode 100644
index 000000000..e25c80cb6
--- /dev/null
+++ b/0001-Documentation-x86-Add-CET-description.patch
@@ -0,0 +1,220 @@
+From ce1e078b5704bbc3bacf96e0735cb304fec1dcc8 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Sun, 17 Dec 2017 09:09:23 -0800
+Subject: [PATCH 01/40] Documentation/x86: Add CET description
+
+Explain no_user_shstk/no_user_ibt kernel parameters, and introduce a new
+document on Control-flow Enforcement Technology (CET).
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v11:
+- Add back GLIBC tunables information.
+- Add ARCH_X86_CET_MMAP_SHSTK information.
+
+v10:
+- Change no_cet_shstk and no_cet_ibt to no_user_shstk and no_user_ibt.
+- Remove the opcode section, as it is already in the Intel SDM.
+- Remove sections related to GLIBC implementation.
+- Remove shadow stack memory management section, as it is already in the
+  code comments.
+- Remove legacy bitmap related information, as it is not supported now.
+- Fix arch_ioctl() related text.
+- Change SHSTK, IBT to plain English.
+---
+ .../admin-guide/kernel-parameters.txt         |   6 +
+ Documentation/x86/index.rst                   |   1 +
+ Documentation/x86/intel_cet.rst               | 152 ++++++++++++++++++
+ 3 files changed, 159 insertions(+)
+ create mode 100644 Documentation/x86/intel_cet.rst
+
+diff --git a/Documentation/admin-guide/kernel-parameters.txt b/Documentation/admin-guide/kernel-parameters.txt
+index fb95fad81c79..e1571661e4a0 100644
+--- a/Documentation/admin-guide/kernel-parameters.txt
++++ b/Documentation/admin-guide/kernel-parameters.txt
+@@ -3139,6 +3139,12 @@
+ 			noexec=on: enable non-executable mappings (default)
+ 			noexec=off: disable non-executable mappings
+ 
++	no_user_shstk	[X86-64] Disable Shadow Stack for user-mode
++			applications
++
++	no_user_ibt	[X86-64] Disable Indirect Branch Tracking for user-mode
++			applications
++
+ 	nosmap		[X86,PPC]
+ 			Disable SMAP (Supervisor Mode Access Prevention)
+ 			even if it is supported by processor.
+diff --git a/Documentation/x86/index.rst b/Documentation/x86/index.rst
+index 265d9e9a093b..2aef972a868d 100644
+--- a/Documentation/x86/index.rst
++++ b/Documentation/x86/index.rst
+@@ -19,6 +19,7 @@ x86-specific Documentation
+    tlb
+    mtrr
+    pat
++   intel_cet
+    intel-iommu
+    intel_txt
+    amd-memory-encryption
+diff --git a/Documentation/x86/intel_cet.rst b/Documentation/x86/intel_cet.rst
+new file mode 100644
+index 000000000000..acedbe5457e9
+--- /dev/null
++++ b/Documentation/x86/intel_cet.rst
+@@ -0,0 +1,152 @@
++.. SPDX-License-Identifier: GPL-2.0
++
++=========================================
++Control-flow Enforcement Technology (CET)
++=========================================
++
++[1] Overview
++============
++
++Control-flow Enforcement Technology (CET) is an Intel processor feature
++that provides protection against return/jump-oriented programming (ROP)
++attacks.  It can be set up to protect both applications and the kernel.
++Only user-mode protection is implemented in the 64-bit kernel, including
++support for running legacy 32-bit applications.
++
++CET introduces Shadow Stack and Indirect Branch Tracking.  Shadow stack is
++a secondary stack allocated from memory and cannot be directly modified by
++applications.  When executing a CALL, the processor pushes the return
++address to both the normal stack and the shadow stack.  Upon function
++return, the processor pops the shadow stack copy and compares it to the
++normal stack copy.  If the two differ, the processor raises a control-
++protection fault.  Indirect branch tracking verifies indirect CALL/JMP
++targets are intended as marked by the compiler with 'ENDBR' opcodes.
++
++There are two kernel configuration options:
++
++    X86_INTEL_SHADOW_STACK_USER, and
++    X86_INTEL_BRANCH_TRACKING_USER.
++
++These need to be enabled to build a CET-enabled kernel, and Binutils v2.31
++and GCC v8.1 or later are required to build a CET kernel.  To build a CET-
++enabled application, GLIBC v2.28 or later is also required.
++
++There are two command-line options for disabling CET features::
++
++    no_user_shstk - disables user shadow stack, and
++    no_user_ibt   - disables user indirect branch tracking.
++
++At run time, /proc/cpuinfo shows CET features if the processor supports
++CET.
++
++[2] Application Enabling
++========================
++
++An application's CET capability is marked in its ELF header and can be
++verified from the following command output, in the NT_GNU_PROPERTY_TYPE_0
++field:
++
++    readelf -n <application>
++
++If an application supports CET and is statically linked, it will run with
++CET protection.  If the application needs any shared libraries, the loader
++checks all dependencies and enables CET when all requirements are met.
++
++[3] Backward Compatibility
++==========================
++
++GLIBC provides a few tunables for backward compatibility.
++
++GLIBC_TUNABLES=glibc.tune.hwcaps=-SHSTK,-IBT
++    Turn off SHSTK/IBT for the current shell.
++
++GLIBC_TUNABLES=glibc.tune.x86_shstk=<on, permissive>
++    This controls how dlopen() handles SHSTK legacy libraries::
++
++        on         - continue with SHSTK enabled;
++        permissive - continue with SHSTK off.
++
++[4] CET arch_prctl()'s
++======================
++
++Several arch_prctl()'s have been added for CET:
++
++arch_prctl(ARCH_X86_CET_STATUS, u64 *addr)
++    Return CET feature status.
++
++    The parameter 'addr' is a pointer to a user buffer.
++    On returning to the caller, the kernel fills the following
++    information::
++
++        *addr       = shadow stack/indirect branch tracking status
++        *(addr + 1) = shadow stack base address
++        *(addr + 2) = shadow stack size
++
++arch_prctl(ARCH_X86_CET_DISABLE, u64 features)
++    Disable shadow stack and/or indirect branch tracking as specified in
++    'features'.  Return -EPERM if CET is locked.
++
++arch_prctl(ARCH_X86_CET_LOCK)
++    Lock in all CET features.  They cannot be turned off afterwards.
++
++arch_prctl(ARCH_X86_CET_ALLOC_SHSTK, u64 *addr)
++    Allocate a new shadow stack and put a restore token at top.
++
++    The parameter 'addr' is a pointer to a user buffer and indicates the
++    shadow stack size to allocate.  On returning to the caller, the kernel
++    fills '*addr' with the base address of the new shadow stack.
++
++    User-level threads that need a new stack are expected to allocate a
++    new shadow stack.
++
++arch_prctl(ARCH_X86_CET_MMAP_SHSTK, u64 *args)
++    Allocate a new shadow stack and put a restore token at top.
++
++    The parameter 'args' is a pointer to a user buffer::
++
++        *args = allocated shadow stack address
++        *(args + 1) = desired size
++        *(args + 2) = MAP_32BIT or MAP_POPULATE
++
++Note:
++  There is no CET-enabling arch_prctl function.  By design, CET is enabled
++  automatically if the binary and the system can support it.
++
++[5] The implementation of the Shadow Stack
++==========================================
++
++Shadow Stack size
++-----------------
++
++A task's shadow stack is allocated from memory to a fixed size of
++MIN(RLIMIT_STACK, 4 GB).  In other words, the shadow stack is allocated to
++the maximum size of the normal stack, but capped to 4 GB.  However,
++a compat-mode application's address space is smaller, each of its thread's
++shadow stack size is MIN(1/4 RLIMIT_STACK, 4 GB).
++
++Signal
++------
++
++The main program and its signal handlers use the same shadow stack.
++Because the shadow stack stores only return addresses, a large shadow
++stack covers the condition that both the program stack and the signal
++alternate stack run out.
++
++The kernel creates a restore token for the shadow stack restoring address
++and verifies that token when restoring from the signal handler.
++
++Fork
++----
++
++The shadow stack's vma has VM_SHSTK flag set; its PTEs are required to be
++read-only and dirty.  When a shadow stack PTE is not RO and dirty, a
++shadow access triggers a page fault with the shadow stack access bit set
++in the page fault error code.
++
++When a task forks a child, its shadow stack PTEs are copied and both the
++parent's and the child's shadow stack PTEs are cleared of the dirty bit.
++Upon the next shadow stack access, the resulting shadow stack page fault
++is handled by page copy/re-use.
++
++When a pthread child is created, the kernel allocates a new shadow stack
++for the new thread.
+-- 
+2.26.2
+
diff --git a/0002-x86-cpufeatures-Add-CET-CPU-feature-flags-for-Contro.patch b/0002-x86-cpufeatures-Add-CET-CPU-feature-flags-for-Contro.patch
new file mode 100644
index 000000000..71986626d
--- /dev/null
+++ b/0002-x86-cpufeatures-Add-CET-CPU-feature-flags-for-Contro.patch
@@ -0,0 +1,53 @@
+From 6e4c945c8f4a6a6ef8e94d3e7d1411c14a9428fd Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Wed, 9 Nov 2016 16:26:37 -0800
+Subject: [PATCH 02/40] x86/cpufeatures: Add CET CPU feature flags for
+ Control-flow Enforcement Technology (CET)
+
+Add CPU feature flags for Control-flow Enforcement Technology (CET).
+
+CPUID.(EAX=7,ECX=0):ECX[bit 7] Shadow stack
+CPUID.(EAX=7,ECX=0):EDX[bit 20] Indirect Branch Tracking
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/include/asm/cpufeatures.h | 2 ++
+ arch/x86/kernel/cpu/cpuid-deps.c   | 2 ++
+ 2 files changed, 4 insertions(+)
+
+diff --git a/arch/x86/include/asm/cpufeatures.h b/arch/x86/include/asm/cpufeatures.h
+index 02dabc9e77b0..32a353951089 100644
+--- a/arch/x86/include/asm/cpufeatures.h
++++ b/arch/x86/include/asm/cpufeatures.h
+@@ -339,6 +339,7 @@
+ #define X86_FEATURE_OSPKE		(16*32+ 4) /* OS Protection Keys Enable */
+ #define X86_FEATURE_WAITPKG		(16*32+ 5) /* UMONITOR/UMWAIT/TPAUSE Instructions */
+ #define X86_FEATURE_AVX512_VBMI2	(16*32+ 6) /* Additional AVX512 Vector Bit Manipulation Instructions */
++#define X86_FEATURE_SHSTK		(16*32+ 7) /* Shadow Stack */
+ #define X86_FEATURE_GFNI		(16*32+ 8) /* Galois Field New Instructions */
+ #define X86_FEATURE_VAES		(16*32+ 9) /* Vector AES */
+ #define X86_FEATURE_VPCLMULQDQ		(16*32+10) /* Carry-Less Multiplication Double Quadword */
+@@ -366,6 +367,7 @@
+ #define X86_FEATURE_MD_CLEAR		(18*32+10) /* VERW clears CPU buffers */
+ #define X86_FEATURE_TSX_FORCE_ABORT	(18*32+13) /* "" TSX_FORCE_ABORT */
+ #define X86_FEATURE_PCONFIG		(18*32+18) /* Intel PCONFIG */
++#define X86_FEATURE_IBT			(18*32+20) /* Indirect Branch Tracking */
+ #define X86_FEATURE_SPEC_CTRL		(18*32+26) /* "" Speculation Control (IBRS + IBPB) */
+ #define X86_FEATURE_INTEL_STIBP		(18*32+27) /* "" Single Thread Indirect Branch Predictors */
+ #define X86_FEATURE_FLUSH_L1D		(18*32+28) /* Flush L1D cache */
+diff --git a/arch/x86/kernel/cpu/cpuid-deps.c b/arch/x86/kernel/cpu/cpuid-deps.c
+index 3cbe24ca80ab..fec83cc74b9e 100644
+--- a/arch/x86/kernel/cpu/cpuid-deps.c
++++ b/arch/x86/kernel/cpu/cpuid-deps.c
+@@ -69,6 +69,8 @@ static const struct cpuid_dep cpuid_deps[] = {
+ 	{ X86_FEATURE_CQM_MBM_TOTAL,		X86_FEATURE_CQM_LLC   },
+ 	{ X86_FEATURE_CQM_MBM_LOCAL,		X86_FEATURE_CQM_LLC   },
+ 	{ X86_FEATURE_AVX512_BF16,		X86_FEATURE_AVX512VL  },
++	{ X86_FEATURE_SHSTK,			X86_FEATURE_XSAVES    },
++	{ X86_FEATURE_IBT,			X86_FEATURE_XSAVES    },
+ 	{}
+ };
+ 
+-- 
+2.26.2
+
diff --git a/0003-x86-fpu-xstate-Introduce-CET-MSR-XSAVES-supervisor-s.patch b/0003-x86-fpu-xstate-Introduce-CET-MSR-XSAVES-supervisor-s.patch
new file mode 100644
index 000000000..0ca2b4a36
--- /dev/null
+++ b/0003-x86-fpu-xstate-Introduce-CET-MSR-XSAVES-supervisor-s.patch
@@ -0,0 +1,205 @@
+From 2727991144fd8f58f7a9a24624bea2aaea9db172 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 10 Nov 2016 10:13:56 -0800
+Subject: [PATCH 03/40] x86/fpu/xstate: Introduce CET MSR XSAVES supervisor
+ states
+
+Control-flow Enforcement Technology (CET) adds five MSRs.  Introduce them
+and their XSAVES supervisor states:
+
+    MSR_IA32_U_CET (user-mode CET settings),
+    MSR_IA32_PL3_SSP (user-mode Shadow Stack pointer),
+    MSR_IA32_PL0_SSP (kernel-mode Shadow Stack pointer),
+    MSR_IA32_PL1_SSP (Privilege Level 1 Shadow Stack pointer),
+    MSR_IA32_PL2_SSP (Privilege Level 2 Shadow Stack pointer).
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v11:
+- Drop MSR_IA32 prefix for individual bits, and use BIT_ULL().
+- Drop MSR_IA32_CET_BITMAP_MASK.
+
+v6:
+- Remove __packed from struct cet_user_state, struct cet_kernel_state.
+---
+ arch/x86/include/asm/fpu/types.h            | 22 ++++++++++++++++++
+ arch/x86/include/asm/fpu/xstate.h           |  5 +++--
+ arch/x86/include/asm/msr-index.h            | 17 ++++++++++++++
+ arch/x86/include/uapi/asm/processor-flags.h |  2 ++
+ arch/x86/kernel/fpu/xstate.c                | 25 +++++++++++++++++++--
+ 5 files changed, 67 insertions(+), 4 deletions(-)
+
+diff --git a/arch/x86/include/asm/fpu/types.h b/arch/x86/include/asm/fpu/types.h
+index f098f6cab94b..d7ef4d9c7ad5 100644
+--- a/arch/x86/include/asm/fpu/types.h
++++ b/arch/x86/include/asm/fpu/types.h
+@@ -114,6 +114,9 @@ enum xfeature {
+ 	XFEATURE_Hi16_ZMM,
+ 	XFEATURE_PT_UNIMPLEMENTED_SO_FAR,
+ 	XFEATURE_PKRU,
++	XFEATURE_RESERVED,
++	XFEATURE_CET_USER,
++	XFEATURE_CET_KERNEL,
+ 
+ 	XFEATURE_MAX,
+ };
+@@ -128,6 +131,8 @@ enum xfeature {
+ #define XFEATURE_MASK_Hi16_ZMM		(1 << XFEATURE_Hi16_ZMM)
+ #define XFEATURE_MASK_PT		(1 << XFEATURE_PT_UNIMPLEMENTED_SO_FAR)
+ #define XFEATURE_MASK_PKRU		(1 << XFEATURE_PKRU)
++#define XFEATURE_MASK_CET_USER		(1 << XFEATURE_CET_USER)
++#define XFEATURE_MASK_CET_KERNEL	(1 << XFEATURE_CET_KERNEL)
+ 
+ #define XFEATURE_MASK_FPSSE		(XFEATURE_MASK_FP | XFEATURE_MASK_SSE)
+ #define XFEATURE_MASK_AVX512		(XFEATURE_MASK_OPMASK \
+@@ -229,6 +234,23 @@ struct pkru_state {
+ 	u32				pad;
+ } __packed;
+ 
++/*
++ * State component 11 is Control-flow Enforcement user states
++ */
++struct cet_user_state {
++	u64 user_cet;			/* user control-flow settings */
++	u64 user_ssp;			/* user shadow stack pointer */
++};
++
++/*
++ * State component 12 is Control-flow Enforcement kernel states
++ */
++struct cet_kernel_state {
++	u64 kernel_ssp;			/* kernel shadow stack */
++	u64 pl1_ssp;			/* privilege level 1 shadow stack */
++	u64 pl2_ssp;			/* privilege level 2 shadow stack */
++};
++
+ struct xstate_header {
+ 	u64				xfeatures;
+ 	u64				xcomp_bv;
+diff --git a/arch/x86/include/asm/fpu/xstate.h b/arch/x86/include/asm/fpu/xstate.h
+index 422d8369012a..db89d796b22e 100644
+--- a/arch/x86/include/asm/fpu/xstate.h
++++ b/arch/x86/include/asm/fpu/xstate.h
+@@ -33,13 +33,14 @@
+ 				      XFEATURE_MASK_BNDCSR)
+ 
+ /* All currently supported supervisor features */
+-#define XFEATURE_MASK_SUPERVISOR_SUPPORTED (0)
++#define XFEATURE_MASK_SUPERVISOR_SUPPORTED (XFEATURE_MASK_CET_USER)
+ 
+ /*
+  * Unsupported supervisor features. When a supervisor feature in this mask is
+  * supported in the future, move it to the supported supervisor feature mask.
+  */
+-#define XFEATURE_MASK_SUPERVISOR_UNSUPPORTED (XFEATURE_MASK_PT)
++#define XFEATURE_MASK_SUPERVISOR_UNSUPPORTED (XFEATURE_MASK_PT | \
++					      XFEATURE_MASK_CET_KERNEL)
+ 
+ /* All supervisor states including supported and unsupported states. */
+ #define XFEATURE_MASK_SUPERVISOR_ALL (XFEATURE_MASK_SUPERVISOR_SUPPORTED | \
+diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
+index e8370e64a155..3a71a072d8d3 100644
+--- a/arch/x86/include/asm/msr-index.h
++++ b/arch/x86/include/asm/msr-index.h
+@@ -892,4 +892,21 @@
+ #define MSR_VM_IGNNE                    0xc0010115
+ #define MSR_VM_HSAVE_PA                 0xc0010117
+ 
++/* Control-flow Enforcement Technology MSRs */
++#define MSR_IA32_U_CET		0x6a0 /* user mode cet setting */
++#define MSR_IA32_S_CET		0x6a2 /* kernel mode cet setting */
++#define MSR_IA32_PL0_SSP	0x6a4 /* kernel shstk pointer */
++#define MSR_IA32_PL1_SSP	0x6a5 /* ring-1 shstk pointer */
++#define MSR_IA32_PL2_SSP	0x6a6 /* ring-2 shstk pointer */
++#define MSR_IA32_PL3_SSP	0x6a7 /* user shstk pointer */
++#define MSR_IA32_INT_SSP_TAB	0x6a8 /* exception shstk table */
++
++/* MSR_IA32_U_CET and MSR_IA32_S_CET bits */
++#define CET_SHSTK_EN		BIT_ULL(0)
++#define CET_WRSS_EN		BIT_ULL(1)
++#define CET_ENDBR_EN		BIT_ULL(2)
++#define CET_LEG_IW_EN		BIT_ULL(3)
++#define CET_NO_TRACK_EN		BIT_ULL(4)
++#define CET_WAIT_ENDBR		BIT_ULL(11)
++
+ #endif /* _ASM_X86_MSR_INDEX_H */
+diff --git a/arch/x86/include/uapi/asm/processor-flags.h b/arch/x86/include/uapi/asm/processor-flags.h
+index bcba3c643e63..a8df907e8017 100644
+--- a/arch/x86/include/uapi/asm/processor-flags.h
++++ b/arch/x86/include/uapi/asm/processor-flags.h
+@@ -130,6 +130,8 @@
+ #define X86_CR4_SMAP		_BITUL(X86_CR4_SMAP_BIT)
+ #define X86_CR4_PKE_BIT		22 /* enable Protection Keys support */
+ #define X86_CR4_PKE		_BITUL(X86_CR4_PKE_BIT)
++#define X86_CR4_CET_BIT		23 /* enable Control-flow Enforcement */
++#define X86_CR4_CET		_BITUL(X86_CR4_CET_BIT)
+ 
+ /*
+  * x86-64 Task Priority Register, CR8
+diff --git a/arch/x86/kernel/fpu/xstate.c b/arch/x86/kernel/fpu/xstate.c
+index ad3a2b37927d..505dff739a24 100644
+--- a/arch/x86/kernel/fpu/xstate.c
++++ b/arch/x86/kernel/fpu/xstate.c
+@@ -38,6 +38,9 @@ static const char *xfeature_names[] =
+ 	"Processor Trace (unused)"	,
+ 	"Protection Keys User registers",
+ 	"unknown xstate feature"	,
++	"Control-flow User registers"	,
++	"Control-flow Kernel registers"	,
++	"unknown xstate feature"	,
+ };
+ 
+ static short xsave_cpuid_features[] __initdata = {
+@@ -51,6 +54,9 @@ static short xsave_cpuid_features[] __initdata = {
+ 	X86_FEATURE_AVX512F,
+ 	X86_FEATURE_INTEL_PT,
+ 	X86_FEATURE_PKU,
++	-1,		   /* Unused */
++	X86_FEATURE_SHSTK, /* XFEATURE_CET_USER */
++	X86_FEATURE_SHSTK, /* XFEATURE_CET_KERNEL */
+ };
+ 
+ /*
+@@ -316,6 +322,8 @@ static void __init print_xstate_features(void)
+ 	print_xstate_feature(XFEATURE_MASK_ZMM_Hi256);
+ 	print_xstate_feature(XFEATURE_MASK_Hi16_ZMM);
+ 	print_xstate_feature(XFEATURE_MASK_PKRU);
++	print_xstate_feature(XFEATURE_MASK_CET_USER);
++	print_xstate_feature(XFEATURE_MASK_CET_KERNEL);
+ }
+ 
+ /*
+@@ -590,6 +598,8 @@ static void check_xstate_against_struct(int nr)
+ 	XCHECK_SZ(sz, nr, XFEATURE_ZMM_Hi256, struct avx_512_zmm_uppers_state);
+ 	XCHECK_SZ(sz, nr, XFEATURE_Hi16_ZMM,  struct avx_512_hi16_state);
+ 	XCHECK_SZ(sz, nr, XFEATURE_PKRU,      struct pkru_state);
++	XCHECK_SZ(sz, nr, XFEATURE_CET_USER,   struct cet_user_state);
++	XCHECK_SZ(sz, nr, XFEATURE_CET_KERNEL, struct cet_kernel_state);
+ 
+ 	/*
+ 	 * Make *SURE* to add any feature numbers in below if
+@@ -797,8 +807,19 @@ void __init fpu__init_system_xstate(void)
+ 	 * Clear XSAVE features that are disabled in the normal CPUID.
+ 	 */
+ 	for (i = 0; i < ARRAY_SIZE(xsave_cpuid_features); i++) {
+-		if (!boot_cpu_has(xsave_cpuid_features[i]))
+-			xfeatures_mask_all &= ~BIT_ULL(i);
++		if (xsave_cpuid_features[i] == X86_FEATURE_SHSTK) {
++			/*
++			 * X86_FEATURE_SHSTK and X86_FEATURE_IBT share
++			 * same states, but can be enabled separately.
++			 */
++			if (!boot_cpu_has(X86_FEATURE_SHSTK) &&
++			    !boot_cpu_has(X86_FEATURE_IBT))
++				xfeatures_mask_all &= ~BIT_ULL(i);
++		} else {
++			if ((xsave_cpuid_features[i] == -1) ||
++			    !boot_cpu_has(xsave_cpuid_features[i]))
++				xfeatures_mask_all &= ~BIT_ULL(i);
++		}
+ 	}
+ 
+ 	xfeatures_mask_all &= fpu__get_supported_xfeatures_mask();
+-- 
+2.26.2
+
diff --git a/0004-x86-cet-Add-control-protection-fault-handler.patch b/0004-x86-cet-Add-control-protection-fault-handler.patch
new file mode 100644
index 000000000..0708c3a32
--- /dev/null
+++ b/0004-x86-cet-Add-control-protection-fault-handler.patch
@@ -0,0 +1,157 @@
+From 268d645a0a2cccc3a76f01dff014b38b10f65a0b Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Mon, 15 Jun 2020 14:26:27 -0700
+Subject: [PATCH 04/40] x86/cet: Add control-protection fault handler
+
+A control-protection fault is triggered when a control-flow transfer
+attempt violates Shadow Stack or Indirect Branch Tracking constraints.
+For example, the return address for a RET instruction differs from the copy
+on the Shadow Stack; or an indirect JMP instruction, without the NOTRACK
+prefix, arrives at a non-ENDBR opcode.
+
+The control-protection fault handler works in a similar way as the general
+protection fault handler.  It provides the si_code SEGV_CPERR to the signal
+handler.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Change CONFIG_X86_64 to CONFIG_X86_INTEL_CET.
+
+v9:
+- Add Shadow Stack pointer to the fault printout.
+---
+ arch/x86/include/asm/idtentry.h    |  4 +++
+ arch/x86/kernel/idt.c              |  4 +++
+ arch/x86/kernel/signal_compat.c    |  2 +-
+ arch/x86/kernel/traps.c            | 56 ++++++++++++++++++++++++++++++
+ include/uapi/asm-generic/siginfo.h |  3 +-
+ 5 files changed, 67 insertions(+), 2 deletions(-)
+
+diff --git a/arch/x86/include/asm/idtentry.h b/arch/x86/include/asm/idtentry.h
+index 80d3b30d3ee3..bc068e85cbf8 100644
+--- a/arch/x86/include/asm/idtentry.h
++++ b/arch/x86/include/asm/idtentry.h
+@@ -536,6 +536,10 @@ DECLARE_IDTENTRY_ERRORCODE(X86_TRAP_SS,	exc_stack_segment);
+ DECLARE_IDTENTRY_ERRORCODE(X86_TRAP_GP,	exc_general_protection);
+ DECLARE_IDTENTRY_ERRORCODE(X86_TRAP_AC,	exc_alignment_check);
+ 
++#ifdef CONFIG_X86_INTEL_CET
++DECLARE_IDTENTRY_ERRORCODE(X86_TRAP_CP, exc_control_protection);
++#endif
++
+ /* Raw exception entries which need extra work */
+ DECLARE_IDTENTRY_RAW(X86_TRAP_UD,		exc_invalid_op);
+ DECLARE_IDTENTRY_RAW(X86_TRAP_BP,		exc_int3);
+diff --git a/arch/x86/kernel/idt.c b/arch/x86/kernel/idt.c
+index 0db21206f2f3..286b36740432 100644
+--- a/arch/x86/kernel/idt.c
++++ b/arch/x86/kernel/idt.c
+@@ -112,6 +112,10 @@ static const __initconst struct idt_data def_idts[] = {
+ #elif defined(CONFIG_X86_32)
+ 	SYSG(IA32_SYSCALL_VECTOR,	entry_INT80_32),
+ #endif
++
++#ifdef CONFIG_X86_INTEL_CET
++	INTG(X86_TRAP_CP,		asm_exc_control_protection),
++#endif
+ };
+ 
+ /*
+diff --git a/arch/x86/kernel/signal_compat.c b/arch/x86/kernel/signal_compat.c
+index 9ccbf0576cd0..c572a3de1037 100644
+--- a/arch/x86/kernel/signal_compat.c
++++ b/arch/x86/kernel/signal_compat.c
+@@ -27,7 +27,7 @@ static inline void signal_compat_build_tests(void)
+ 	 */
+ 	BUILD_BUG_ON(NSIGILL  != 11);
+ 	BUILD_BUG_ON(NSIGFPE  != 15);
+-	BUILD_BUG_ON(NSIGSEGV != 7);
++	BUILD_BUG_ON(NSIGSEGV != 8);
+ 	BUILD_BUG_ON(NSIGBUS  != 5);
+ 	BUILD_BUG_ON(NSIGTRAP != 5);
+ 	BUILD_BUG_ON(NSIGCHLD != 6);
+diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
+index b7cb3e0716f7..074bcb411c04 100644
+--- a/arch/x86/kernel/traps.c
++++ b/arch/x86/kernel/traps.c
+@@ -598,6 +598,62 @@ DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
+ 	cond_local_irq_disable(regs);
+ }
+ 
++static const char * const control_protection_err[] = {
++	"unknown",
++	"near-ret",
++	"far-ret/iret",
++	"endbranch",
++	"rstorssp",
++	"setssbsy",
++};
++
++/*
++ * When a control protection exception occurs, send a signal
++ * to the responsible application.  Currently, control
++ * protection is only enabled for the user mode.  This
++ * exception should not come from the kernel mode.
++ */
++DEFINE_IDTENTRY_ERRORCODE(exc_control_protection)
++{
++	struct task_struct *tsk;
++
++	if (notify_die(DIE_TRAP, "control protection fault", regs,
++		       error_code, X86_TRAP_CP, SIGSEGV) == NOTIFY_STOP)
++		return;
++	cond_local_irq_enable(regs);
++
++	if (!user_mode(regs))
++		die("kernel control protection fault", regs, error_code);
++
++	if (!static_cpu_has(X86_FEATURE_SHSTK) &&
++	    !static_cpu_has(X86_FEATURE_IBT))
++		WARN_ONCE(1, "CET is disabled but got control protection fault\n");
++
++	tsk = current;
++	tsk->thread.error_code = error_code;
++	tsk->thread.trap_nr = X86_TRAP_CP;
++
++	if (show_unhandled_signals && unhandled_signal(tsk, SIGSEGV) &&
++	    printk_ratelimit()) {
++		unsigned int max_err;
++		unsigned long ssp;
++
++		max_err = ARRAY_SIZE(control_protection_err) - 1;
++		if ((error_code < 0) || (error_code > max_err))
++			error_code = 0;
++		rdmsrl(MSR_IA32_PL3_SSP, ssp);
++		pr_info("%s[%d] control protection ip:%lx sp:%lx ssp:%lx error:%lx(%s)",
++			tsk->comm, task_pid_nr(tsk),
++			regs->ip, regs->sp, ssp, error_code,
++			control_protection_err[error_code]);
++		print_vma_addr(KERN_CONT " in ", regs->ip);
++		pr_cont("\n");
++	}
++
++	force_sig_fault(SIGSEGV, SEGV_CPERR,
++			(void __user *)uprobe_get_trap_addr(regs));
++}
++
+ static bool do_int3(struct pt_regs *regs)
+ {
+ 	int res;
+diff --git a/include/uapi/asm-generic/siginfo.h b/include/uapi/asm-generic/siginfo.h
+index cb3d6c267181..91e10cbe3bb0 100644
+--- a/include/uapi/asm-generic/siginfo.h
++++ b/include/uapi/asm-generic/siginfo.h
+@@ -229,7 +229,8 @@ typedef struct siginfo {
+ #define SEGV_ACCADI	5	/* ADI not enabled for mapped object */
+ #define SEGV_ADIDERR	6	/* Disrupting MCD error */
+ #define SEGV_ADIPERR	7	/* Precise MCD exception */
+-#define NSIGSEGV	7
++#define SEGV_CPERR	8	/* Control protection fault */
++#define NSIGSEGV	8
+ 
+ /*
+  * SIGBUS si_codes
+-- 
+2.26.2
+
diff --git a/0005-x86-cet-shstk-Add-Kconfig-option-for-user-mode-Shado.patch b/0005-x86-cet-shstk-Add-Kconfig-option-for-user-mode-Shado.patch
new file mode 100644
index 000000000..8fc21078a
--- /dev/null
+++ b/0005-x86-cet-shstk-Add-Kconfig-option-for-user-mode-Shado.patch
@@ -0,0 +1,79 @@
+From a91ee1a1f1f393d2b4f759e5ac3647c8ac75bcbc Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 3 Oct 2017 12:55:03 -0700
+Subject: [PATCH 05/40] x86/cet/shstk: Add Kconfig option for user-mode Shadow
+ Stack
+
+Shadow Stack provides protection against function return address
+corruption.  It is active when the processor supports it, the kernel has
+CONFIG_X86_INTEL_SHADOW_STACK_USER, and the application is built for the
+feature.  This is only implemented for the 64-bit kernel.  When it is
+enabled, legacy non-shadow stack applications continue to work, but without
+protection.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Change SHSTK to shadow stack in the help text.
+- Change build-time check to config-time check.
+- Change ARCH_HAS_SHSTK to ARCH_HAS_SHADOW_STACK.
+---
+ arch/x86/Kconfig                      | 30 +++++++++++++++++++++++++++
+ scripts/as-x86_64-has-shadow-stack.sh |  4 ++++
+ 2 files changed, 34 insertions(+)
+ create mode 100755 scripts/as-x86_64-has-shadow-stack.sh
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index 883da0abf779..3dedb666d9f7 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1926,6 +1926,36 @@ config X86_INTEL_TSX_MODE_AUTO
+ 	  side channel attacks- equals the tsx=auto command line parameter.
+ endchoice
+ 
++config AS_HAS_SHADOW_STACK
++	def_bool $(success,$(srctree)/scripts/as-x86_64-has-shadow-stack.sh $(CC))
++	help
++	  Test the assembler for shadow stack instructions.
++
++config X86_INTEL_CET
++	def_bool n
++
++config ARCH_HAS_SHADOW_STACK
++	def_bool n
++
++config X86_INTEL_SHADOW_STACK_USER
++	prompt "Intel Shadow Stacks for user-mode"
++	def_bool n
++	depends on CPU_SUP_INTEL && X86_64
++	depends on AS_HAS_SHADOW_STACK
++	select ARCH_USES_HIGH_VMA_FLAGS
++	select X86_INTEL_CET
++	select ARCH_HAS_SHADOW_STACK
++	help
++	  Shadow Stacks provides protection against program stack
++	  corruption.  It's a hardware feature.  This only matters
++	  if you have the right hardware.  It's a security hardening
++	  feature and apps must be enabled to use it.  You get no
++	  protection "for free" on old userspace.  The hardware can
++	  support user and kernel, but this option is for user space
++	  only.
++
++	  If unsure, say y.
++
+ config EFI
+ 	bool "EFI runtime service support"
+ 	depends on ACPI
+diff --git a/scripts/as-x86_64-has-shadow-stack.sh b/scripts/as-x86_64-has-shadow-stack.sh
+new file mode 100755
+index 000000000000..fac1d363a1b8
+--- /dev/null
++++ b/scripts/as-x86_64-has-shadow-stack.sh
+@@ -0,0 +1,4 @@
++#!/bin/sh
++# SPDX-License-Identifier: GPL-2.0
++
++echo "wrussq %rax, (%rbx)" | $* -x assembler -c -
+-- 
+2.26.2
+
diff --git a/0006-x86-mm-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch b/0006-x86-mm-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch
new file mode 100644
index 000000000..f4d164b22
--- /dev/null
+++ b/0006-x86-mm-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch
@@ -0,0 +1,195 @@
+From 63eb6dc0b71c2e75d519cb6591ce3a7291500ed2 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 12 Apr 2018 09:32:59 -0700
+Subject: [PATCH 06/40] x86/mm: Change _PAGE_DIRTY to _PAGE_DIRTY_HW
+
+Before introducing _PAGE_COW for non-hardware memory management purposes in
+the next patch, rename _PAGE_DIRTY to _PAGE_DIRTY_HW and _PAGE_BIT_DIRTY to
+_PAGE_BIT_DIRTY_HW to make meanings more clear.  There are no functional
+changes from this patch.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v9:
+- At some places _PAGE_DIRTY were not changed to _PAGE_DIRTY_HW, because
+  they will be changed again in the next patch to _PAGE_DIRTY_BITS.
+  However, this causes compile issues if the next patch is not yet applied.
+  Fix it by changing all _PAGE_DIRTY to _PAGE_DRITY_HW.
+---
+ arch/x86/include/asm/pgtable.h       | 18 +++++++++---------
+ arch/x86/include/asm/pgtable_types.h | 11 +++++------
+ arch/x86/kernel/relocate_kernel_64.S |  2 +-
+ arch/x86/kvm/vmx/vmx.c               |  2 +-
+ 4 files changed, 16 insertions(+), 17 deletions(-)
+
+diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
+index 76aa21e8128d..69a9498506ec 100644
+--- a/arch/x86/include/asm/pgtable.h
++++ b/arch/x86/include/asm/pgtable.h
+@@ -124,7 +124,7 @@ extern pmdval_t early_pmd_flags;
+  */
+ static inline int pte_dirty(pte_t pte)
+ {
+-	return pte_flags(pte) & _PAGE_DIRTY;
++	return pte_flags(pte) & _PAGE_DIRTY_HW;
+ }
+ 
+ 
+@@ -163,7 +163,7 @@ static inline int pte_young(pte_t pte)
+ 
+ static inline int pmd_dirty(pmd_t pmd)
+ {
+-	return pmd_flags(pmd) & _PAGE_DIRTY;
++	return pmd_flags(pmd) & _PAGE_DIRTY_HW;
+ }
+ 
+ static inline int pmd_young(pmd_t pmd)
+@@ -173,7 +173,7 @@ static inline int pmd_young(pmd_t pmd)
+ 
+ static inline int pud_dirty(pud_t pud)
+ {
+-	return pud_flags(pud) & _PAGE_DIRTY;
++	return pud_flags(pud) & _PAGE_DIRTY_HW;
+ }
+ 
+ static inline int pud_young(pud_t pud)
+@@ -334,7 +334,7 @@ static inline pte_t pte_clear_uffd_wp(pte_t pte)
+ 
+ static inline pte_t pte_mkclean(pte_t pte)
+ {
+-	return pte_clear_flags(pte, _PAGE_DIRTY);
++	return pte_clear_flags(pte, _PAGE_DIRTY_HW);
+ }
+ 
+ static inline pte_t pte_mkold(pte_t pte)
+@@ -354,7 +354,7 @@ static inline pte_t pte_mkexec(pte_t pte)
+ 
+ static inline pte_t pte_mkdirty(pte_t pte)
+ {
+-	return pte_set_flags(pte, _PAGE_DIRTY | _PAGE_SOFT_DIRTY);
++	return pte_set_flags(pte, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
+ }
+ 
+ static inline pte_t pte_mkyoung(pte_t pte)
+@@ -435,7 +435,7 @@ static inline pmd_t pmd_mkold(pmd_t pmd)
+ 
+ static inline pmd_t pmd_mkclean(pmd_t pmd)
+ {
+-	return pmd_clear_flags(pmd, _PAGE_DIRTY);
++	return pmd_clear_flags(pmd, _PAGE_DIRTY_HW);
+ }
+ 
+ static inline pmd_t pmd_wrprotect(pmd_t pmd)
+@@ -445,7 +445,7 @@ static inline pmd_t pmd_wrprotect(pmd_t pmd)
+ 
+ static inline pmd_t pmd_mkdirty(pmd_t pmd)
+ {
+-	return pmd_set_flags(pmd, _PAGE_DIRTY | _PAGE_SOFT_DIRTY);
++	return pmd_set_flags(pmd, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
+ }
+ 
+ static inline pmd_t pmd_mkdevmap(pmd_t pmd)
+@@ -489,7 +489,7 @@ static inline pud_t pud_mkold(pud_t pud)
+ 
+ static inline pud_t pud_mkclean(pud_t pud)
+ {
+-	return pud_clear_flags(pud, _PAGE_DIRTY);
++	return pud_clear_flags(pud, _PAGE_DIRTY_HW);
+ }
+ 
+ static inline pud_t pud_wrprotect(pud_t pud)
+@@ -499,7 +499,7 @@ static inline pud_t pud_wrprotect(pud_t pud)
+ 
+ static inline pud_t pud_mkdirty(pud_t pud)
+ {
+-	return pud_set_flags(pud, _PAGE_DIRTY | _PAGE_SOFT_DIRTY);
++	return pud_set_flags(pud, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
+ }
+ 
+ static inline pud_t pud_mkdevmap(pud_t pud)
+diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h
+index 816b31c68550..192e1326b3db 100644
+--- a/arch/x86/include/asm/pgtable_types.h
++++ b/arch/x86/include/asm/pgtable_types.h
+@@ -15,7 +15,7 @@
+ #define _PAGE_BIT_PWT		3	/* page write through */
+ #define _PAGE_BIT_PCD		4	/* page cache disabled */
+ #define _PAGE_BIT_ACCESSED	5	/* was accessed (raised by CPU) */
+-#define _PAGE_BIT_DIRTY		6	/* was written to (raised by CPU) */
++#define _PAGE_BIT_DIRTY_HW	6	/* was written to (raised by CPU) */
+ #define _PAGE_BIT_PSE		7	/* 4 MB (or 2MB) page */
+ #define _PAGE_BIT_PAT		7	/* on 4KB pages */
+ #define _PAGE_BIT_GLOBAL	8	/* Global TLB entry PPro+ */
+@@ -46,7 +46,7 @@
+ #define _PAGE_PWT	(_AT(pteval_t, 1) << _PAGE_BIT_PWT)
+ #define _PAGE_PCD	(_AT(pteval_t, 1) << _PAGE_BIT_PCD)
+ #define _PAGE_ACCESSED	(_AT(pteval_t, 1) << _PAGE_BIT_ACCESSED)
+-#define _PAGE_DIRTY	(_AT(pteval_t, 1) << _PAGE_BIT_DIRTY)
++#define _PAGE_DIRTY_HW	(_AT(pteval_t, 1) << _PAGE_BIT_DIRTY_HW)
+ #define _PAGE_PSE	(_AT(pteval_t, 1) << _PAGE_BIT_PSE)
+ #define _PAGE_GLOBAL	(_AT(pteval_t, 1) << _PAGE_BIT_GLOBAL)
+ #define _PAGE_SOFTW1	(_AT(pteval_t, 1) << _PAGE_BIT_SOFTW1)
+@@ -74,7 +74,7 @@
+ 			 _PAGE_PKEY_BIT3)
+ 
+ #if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
+-#define _PAGE_KNL_ERRATUM_MASK (_PAGE_DIRTY | _PAGE_ACCESSED)
++#define _PAGE_KNL_ERRATUM_MASK (_PAGE_DIRTY_HW | _PAGE_ACCESSED)
+ #else
+ #define _PAGE_KNL_ERRATUM_MASK 0
+ #endif
+@@ -126,7 +126,7 @@
+  * pte_modify() does modify it.
+  */
+ #define _PAGE_CHG_MASK	(PTE_PFN_MASK | _PAGE_PCD | _PAGE_PWT |		\
+-			 _PAGE_SPECIAL | _PAGE_ACCESSED | _PAGE_DIRTY |	\
++			 _PAGE_SPECIAL | _PAGE_ACCESSED | _PAGE_DIRTY_HW |	\
+ 			 _PAGE_SOFT_DIRTY | _PAGE_DEVMAP | _PAGE_ENC |  \
+ 			 _PAGE_UFFD_WP)
+ #define _HPAGE_CHG_MASK (_PAGE_CHG_MASK | _PAGE_PSE)
+@@ -163,7 +163,7 @@ enum page_cache_mode {
+ #define __RW _PAGE_RW
+ #define _USR _PAGE_USER
+ #define ___A _PAGE_ACCESSED
+-#define ___D _PAGE_DIRTY
++#define ___D _PAGE_DIRTY_HW
+ #define ___G _PAGE_GLOBAL
+ #define __NX _PAGE_NX
+ 
+@@ -205,7 +205,6 @@ enum page_cache_mode {
+ #define __PAGE_KERNEL_IO		__PAGE_KERNEL
+ #define __PAGE_KERNEL_IO_NOCACHE	__PAGE_KERNEL_NOCACHE
+ 
+-
+ #ifndef __ASSEMBLY__
+ 
+ #define __PAGE_KERNEL_ENC	(__PAGE_KERNEL    | _ENC)
+diff --git a/arch/x86/kernel/relocate_kernel_64.S b/arch/x86/kernel/relocate_kernel_64.S
+index a4d9a261425b..e3bb4ff95523 100644
+--- a/arch/x86/kernel/relocate_kernel_64.S
++++ b/arch/x86/kernel/relocate_kernel_64.S
+@@ -17,7 +17,7 @@
+  */
+ 
+ #define PTR(x) (x << 3)
+-#define PAGE_ATTR (_PAGE_PRESENT | _PAGE_RW | _PAGE_ACCESSED | _PAGE_DIRTY)
++#define PAGE_ATTR (_PAGE_PRESENT | _PAGE_RW | _PAGE_ACCESSED | _PAGE_DIRTY_HW)
+ 
+ /*
+  * control_page + KEXEC_CONTROL_CODE_MAX_SIZE
+diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
+index 13745f2a5ecd..7f0c4e78881b 100644
+--- a/arch/x86/kvm/vmx/vmx.c
++++ b/arch/x86/kvm/vmx/vmx.c
+@@ -3608,7 +3608,7 @@ static int init_rmode_identity_map(struct kvm *kvm)
+ 	/* Set up identity-mapping pagetable for EPT in real mode */
+ 	for (i = 0; i < PT32_ENT_PER_PAGE; i++) {
+ 		tmp = (i << 22) + (_PAGE_PRESENT | _PAGE_RW | _PAGE_USER |
+-			_PAGE_ACCESSED | _PAGE_DIRTY | _PAGE_PSE);
++			_PAGE_ACCESSED | _PAGE_DIRTY_HW | _PAGE_PSE);
+ 		r = kvm_write_guest_page(kvm, identity_map_pfn,
+ 				&tmp, i * sizeof(tmp), sizeof(tmp));
+ 		if (r < 0)
+-- 
+2.26.2
+
diff --git a/0007-x86-mm-Remove-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch b/0007-x86-mm-Remove-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch
new file mode 100644
index 000000000..3c091b774
--- /dev/null
+++ b/0007-x86-mm-Remove-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch
@@ -0,0 +1,48 @@
+From 6b72d3e587d9b38083413a7187d455fa565819a8 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 14 Apr 2020 14:48:14 -0700
+Subject: [PATCH 07/40] x86/mm: Remove _PAGE_DIRTY_HW from kernel RO pages
+
+Kernel read-only PTEs are setup as _PAGE_DIRTY_HW.  Since these become
+shadow stack PTEs, remove the dirty bit.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/include/asm/pgtable_types.h | 6 +++---
+ arch/x86/mm/pat/set_memory.c         | 2 +-
+ 2 files changed, 4 insertions(+), 4 deletions(-)
+
+diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h
+index 192e1326b3db..5f31f1c407b9 100644
+--- a/arch/x86/include/asm/pgtable_types.h
++++ b/arch/x86/include/asm/pgtable_types.h
+@@ -193,10 +193,10 @@ enum page_cache_mode {
+ #define _KERNPG_TABLE		 (__PP|__RW|   0|___A|   0|___D|   0|   0| _ENC)
+ #define _PAGE_TABLE_NOENC	 (__PP|__RW|_USR|___A|   0|___D|   0|   0)
+ #define _PAGE_TABLE		 (__PP|__RW|_USR|___A|   0|___D|   0|   0| _ENC)
+-#define __PAGE_KERNEL_RO	 (__PP|   0|   0|___A|__NX|___D|   0|___G)
+-#define __PAGE_KERNEL_ROX	 (__PP|   0|   0|___A|   0|___D|   0|___G)
++#define __PAGE_KERNEL_RO	 (__PP|   0|   0|___A|__NX|   0|   0|___G)
++#define __PAGE_KERNEL_ROX	 (__PP|   0|   0|___A|   0|   0|   0|___G)
+ #define __PAGE_KERNEL_NOCACHE	 (__PP|__RW|   0|___A|__NX|___D|   0|___G| __NC)
+-#define __PAGE_KERNEL_VVAR	 (__PP|   0|_USR|___A|__NX|___D|   0|___G)
++#define __PAGE_KERNEL_VVAR	 (__PP|   0|_USR|___A|__NX|   0|   0|___G)
+ #define __PAGE_KERNEL_LARGE	 (__PP|__RW|   0|___A|__NX|___D|_PSE|___G)
+ #define __PAGE_KERNEL_LARGE_EXEC (__PP|__RW|   0|___A|   0|___D|_PSE|___G)
+ #define __PAGE_KERNEL_WP	 (__PP|__RW|   0|___A|__NX|___D|   0|___G| __WP)
+diff --git a/arch/x86/mm/pat/set_memory.c b/arch/x86/mm/pat/set_memory.c
+index 77e04304a2a7..43ac7866f20d 100644
+--- a/arch/x86/mm/pat/set_memory.c
++++ b/arch/x86/mm/pat/set_memory.c
+@@ -1932,7 +1932,7 @@ int set_memory_nx(unsigned long addr, int numpages)
+ 
+ int set_memory_ro(unsigned long addr, int numpages)
+ {
+-	return change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_RW), 0);
++	return change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_RW | _PAGE_DIRTY_HW), 0);
+ }
+ 
+ int set_memory_rw(unsigned long addr, int numpages)
+-- 
+2.26.2
+
diff --git a/0008-x86-mm-Introduce-_PAGE_COW.patch b/0008-x86-mm-Introduce-_PAGE_COW.patch
new file mode 100644
index 000000000..4b346978d
--- /dev/null
+++ b/0008-x86-mm-Introduce-_PAGE_COW.patch
@@ -0,0 +1,371 @@
+From 01e949539342f47a1c36f8c6fee7686d8961a484 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Wed, 24 Jan 2018 10:27:13 -0800
+Subject: [PATCH 08/40] x86/mm: Introduce _PAGE_COW
+
+There is essentially no room left in the x86 hardware PTEs on some OSes
+(not Linux).  That left the hardware architects looking for a way to
+represent a new memory type (shadow stack) within the existing bits.
+They chose to repurpose a lightly-used state: Write=0,Dirty=1.
+
+The reason it's lightly used is that Dirty=1 is normally set by hardware
+and cannot normally be set by hardware on a Write=0 PTE.  Software must
+normally be involved to create one of these PTEs, so software can simply
+opt to not create them.
+
+But that leaves us with a Linux problem: we need to ensure we never create
+Write=0,Dirty=1 PTEs.  In places where we do create them, we need to find
+an alternative way to represent them _without_ using the same hardware bit
+combination.  Thus, enter _PAGE_COW.  This results in the following:
+
+(a) A modified, copy-on-write (COW) page: (R/O + _PAGE_COW)
+(b) A R/O page that has been COW'ed: (R/O + _PAGE_COW)
+    The user page is in a R/O VMA, and get_user_pages() needs a writable
+    copy.  The page fault handler creates a copy of the page and sets
+    the new copy's PTE as R/O and _PAGE_COW.
+(c) A shadow stack PTE: (R/O + _PAGE_DIRTY_HW)
+(d) A shared shadow stack PTE: (R/O + _PAGE_COW)
+    When a shadow stack page is being shared among processes (this happens
+    at fork()), its PTE is cleared of _PAGE_DIRTY_HW, so the next shadow
+    stack access causes a fault, and the page is duplicated and
+    _PAGE_DIRTY_HW is set again.  This is the COW equivalent for shadow
+    stack pages, even though it's copy-on-access rather than copy-on-write.
+(e) A page where the processor observed a Write=1 PTE, started a write, set
+    Dirty=1, but then observed a Write=0 PTE.  That's possible today, but
+    will not happen on processors that support shadow stack.
+
+Use _PAGE_COW in pte_wrprotect() and _PAGE_DIRTY_HW in pte_mkwrite().
+Apply the same changes to pmd and pud.
+
+When this patch is applied, there are six free bits left in the 64-bit PTE.
+There are no more free bits in the 32-bit PTE (except for PAE) and shadow
+stack is not implemented for the 32-bit kernel.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Change _PAGE_BIT_DIRTY_SW to _PAGE_BIT_COW, as it is used for copy-on-
+  write PTEs.
+- Update pte_write() and treat shadow stack as writable.
+- Change *_mkdirty_shstk() to *_mkwrite_shstk() as these make shadow stack
+  pages writable.
+- Use bit test & shift to move _PAGE_BIT_DIRTY_HW to _PAGE_BIT_COW.
+- Change static_cpu_has() to cpu_feature_enabled().
+- Revise commit log.
+
+v9:
+- Remove pte_move_flags() etc. and put the logic directly in
+  pte_wrprotect()/pte_mkwrite() etc.
+- Change compile-time conditionals to run-time checks.
+- Split out pte_modify()/pmd_modify() to a new patch.
+- Update comments.
+---
+ arch/x86/include/asm/pgtable.h       | 120 ++++++++++++++++++++++++---
+ arch/x86/include/asm/pgtable_types.h |  41 ++++++++-
+ 2 files changed, 150 insertions(+), 11 deletions(-)
+
+diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
+index 69a9498506ec..1b57b5543adb 100644
+--- a/arch/x86/include/asm/pgtable.h
++++ b/arch/x86/include/asm/pgtable.h
+@@ -122,9 +122,9 @@ extern pmdval_t early_pmd_flags;
+  * The following only work if pte_present() is true.
+  * Undefined behaviour if not..
+  */
+-static inline int pte_dirty(pte_t pte)
++static inline bool pte_dirty(pte_t pte)
+ {
+-	return pte_flags(pte) & _PAGE_DIRTY_HW;
++	return pte_flags(pte) & _PAGE_DIRTY_BITS;
+ }
+ 
+ 
+@@ -161,9 +161,9 @@ static inline int pte_young(pte_t pte)
+ 	return pte_flags(pte) & _PAGE_ACCESSED;
+ }
+ 
+-static inline int pmd_dirty(pmd_t pmd)
++static inline bool pmd_dirty(pmd_t pmd)
+ {
+-	return pmd_flags(pmd) & _PAGE_DIRTY_HW;
++	return pmd_flags(pmd) & _PAGE_DIRTY_BITS;
+ }
+ 
+ static inline int pmd_young(pmd_t pmd)
+@@ -171,9 +171,9 @@ static inline int pmd_young(pmd_t pmd)
+ 	return pmd_flags(pmd) & _PAGE_ACCESSED;
+ }
+ 
+-static inline int pud_dirty(pud_t pud)
++static inline bool pud_dirty(pud_t pud)
+ {
+-	return pud_flags(pud) & _PAGE_DIRTY_HW;
++	return pud_flags(pud) & _PAGE_DIRTY_BITS;
+ }
+ 
+ static inline int pud_young(pud_t pud)
+@@ -183,6 +183,12 @@ static inline int pud_young(pud_t pud)
+ 
+ static inline int pte_write(pte_t pte)
+ {
++	/*
++	 * If _PAGE_DIRTY_HW is set, the PTE must either have
++	 * _PAGE_RW or be a shadow stack PTE, which is logically writable.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK))
++		return pte_flags(pte) & (_PAGE_RW | _PAGE_DIRTY_HW);
+ 	return pte_flags(pte) & _PAGE_RW;
+ }
+ 
+@@ -334,7 +340,7 @@ static inline pte_t pte_clear_uffd_wp(pte_t pte)
+ 
+ static inline pte_t pte_mkclean(pte_t pte)
+ {
+-	return pte_clear_flags(pte, _PAGE_DIRTY_HW);
++	return pte_clear_flags(pte, _PAGE_DIRTY_BITS);
+ }
+ 
+ static inline pte_t pte_mkold(pte_t pte)
+@@ -344,6 +350,17 @@ static inline pte_t pte_mkold(pte_t pte)
+ 
+ static inline pte_t pte_wrprotect(pte_t pte)
+ {
++	/*
++	 * Blindly clearing _PAGE_RW might accidentally create
++	 * a shadow stack PTE (RW=0,Dirty=1).  Move the hardware
++	 * dirty value to the software bit.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		pte.pte |= (pte.pte & _PAGE_DIRTY_HW) >>
++			   _PAGE_BIT_DIRTY_HW << _PAGE_BIT_COW;
++		pte = pte_clear_flags(pte, _PAGE_DIRTY_HW);
++	}
++
+ 	return pte_clear_flags(pte, _PAGE_RW);
+ }
+ 
+@@ -354,6 +371,18 @@ static inline pte_t pte_mkexec(pte_t pte)
+ 
+ static inline pte_t pte_mkdirty(pte_t pte)
+ {
++	pteval_t dirty = _PAGE_DIRTY_HW;
++
++	/* Avoid creating (HW)Dirty=1,Write=0 PTEs */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK) && !pte_write(pte))
++		dirty = _PAGE_COW;
++
++	return pte_set_flags(pte, dirty | _PAGE_SOFT_DIRTY);
++}
++
++static inline pte_t pte_mkwrite_shstk(pte_t pte)
++{
++	pte = pte_clear_flags(pte, _PAGE_COW);
+ 	return pte_set_flags(pte, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
+ }
+ 
+@@ -364,6 +393,13 @@ static inline pte_t pte_mkyoung(pte_t pte)
+ 
+ static inline pte_t pte_mkwrite(pte_t pte)
+ {
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		if (pte_flags(pte) & _PAGE_COW) {
++			pte = pte_clear_flags(pte, _PAGE_COW);
++			pte = pte_set_flags(pte, _PAGE_DIRTY_HW);
++		}
++	}
++
+ 	return pte_set_flags(pte, _PAGE_RW);
+ }
+ 
+@@ -435,16 +471,41 @@ static inline pmd_t pmd_mkold(pmd_t pmd)
+ 
+ static inline pmd_t pmd_mkclean(pmd_t pmd)
+ {
+-	return pmd_clear_flags(pmd, _PAGE_DIRTY_HW);
++	return pmd_clear_flags(pmd, _PAGE_DIRTY_BITS);
+ }
+ 
+ static inline pmd_t pmd_wrprotect(pmd_t pmd)
+ {
++	/*
++	 * Blindly clearing _PAGE_RW might accidentally create
++	 * a shadow stack PMD (RW=0,Dirty=1).  Move the hardware
++	 * dirty value to the software bit.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		pmdval_t v = native_pmd_val(pmd);
++
++		v |= (v & _PAGE_DIRTY_HW) >> _PAGE_BIT_DIRTY_HW <<
++		     _PAGE_BIT_COW;
++		pmd = pmd_clear_flags(__pmd(v), _PAGE_DIRTY_HW);
++	}
++
+ 	return pmd_clear_flags(pmd, _PAGE_RW);
+ }
+ 
+ static inline pmd_t pmd_mkdirty(pmd_t pmd)
+ {
++	pmdval_t dirty = _PAGE_DIRTY_HW;
++
++	/* Avoid creating (HW)Dirty=1,Write=0 PMDs */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK) && !(pmd_flags(pmd) & _PAGE_RW))
++		dirty = _PAGE_COW;
++
++	return pmd_set_flags(pmd, dirty | _PAGE_SOFT_DIRTY);
++}
++
++static inline pmd_t pmd_mkwrite_shstk(pmd_t pmd)
++{
++	pmd = pmd_clear_flags(pmd, _PAGE_COW);
+ 	return pmd_set_flags(pmd, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
+ }
+ 
+@@ -465,6 +526,13 @@ static inline pmd_t pmd_mkyoung(pmd_t pmd)
+ 
+ static inline pmd_t pmd_mkwrite(pmd_t pmd)
+ {
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		if (pmd_flags(pmd) & _PAGE_COW) {
++			pmd = pmd_clear_flags(pmd, _PAGE_COW);
++			pmd = pmd_set_flags(pmd, _PAGE_DIRTY_HW);
++		}
++	}
++
+ 	return pmd_set_flags(pmd, _PAGE_RW);
+ }
+ 
+@@ -489,17 +557,36 @@ static inline pud_t pud_mkold(pud_t pud)
+ 
+ static inline pud_t pud_mkclean(pud_t pud)
+ {
+-	return pud_clear_flags(pud, _PAGE_DIRTY_HW);
++	return pud_clear_flags(pud, _PAGE_DIRTY_BITS);
+ }
+ 
+ static inline pud_t pud_wrprotect(pud_t pud)
+ {
++	/*
++	 * Blindly clearing _PAGE_RW might accidentally create
++	 * a shadow stack PUD (RW=0,Dirty=1).  Move the hardware
++	 * dirty value to the software bit.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		pudval_t v = native_pud_val(pud);
++
++		v |= (v & _PAGE_DIRTY_HW) >> _PAGE_BIT_DIRTY_HW <<
++		     _PAGE_BIT_COW;
++		pud = pud_clear_flags(__pud(v), _PAGE_DIRTY_HW);
++	}
++
+ 	return pud_clear_flags(pud, _PAGE_RW);
+ }
+ 
+ static inline pud_t pud_mkdirty(pud_t pud)
+ {
+-	return pud_set_flags(pud, _PAGE_DIRTY_HW | _PAGE_SOFT_DIRTY);
++	pudval_t dirty = _PAGE_DIRTY_HW;
++
++	/* Avoid creating (HW)Dirty=1,Write=0 PUDs */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK) && !(pud_flags(pud) & _PAGE_RW))
++		dirty = _PAGE_COW;
++
++	return pud_set_flags(pud, dirty | _PAGE_SOFT_DIRTY);
+ }
+ 
+ static inline pud_t pud_mkdevmap(pud_t pud)
+@@ -519,6 +606,13 @@ static inline pud_t pud_mkyoung(pud_t pud)
+ 
+ static inline pud_t pud_mkwrite(pud_t pud)
+ {
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		if (pud_flags(pud) & _PAGE_COW) {
++			pud = pud_clear_flags(pud, _PAGE_COW);
++			pud = pud_set_flags(pud, _PAGE_DIRTY_HW);
++		}
++	}
++
+ 	return pud_set_flags(pud, _PAGE_RW);
+ }
+ 
+@@ -1135,6 +1229,12 @@ extern int pmdp_clear_flush_young(struct vm_area_struct *vma,
+ #define pmd_write pmd_write
+ static inline int pmd_write(pmd_t pmd)
+ {
++	/*
++	 * If _PAGE_DIRTY_HW is set, then the PMD must either have
++	 * _PAGE_RW or be a shadow stack PMD, which is logically writable.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK))
++		return pmd_flags(pmd) & (_PAGE_RW | _PAGE_DIRTY_HW);
+ 	return pmd_flags(pmd) & _PAGE_RW;
+ }
+ 
+diff --git a/arch/x86/include/asm/pgtable_types.h b/arch/x86/include/asm/pgtable_types.h
+index 5f31f1c407b9..b57483567b8b 100644
+--- a/arch/x86/include/asm/pgtable_types.h
++++ b/arch/x86/include/asm/pgtable_types.h
+@@ -23,7 +23,8 @@
+ #define _PAGE_BIT_SOFTW2	10	/* " */
+ #define _PAGE_BIT_SOFTW3	11	/* " */
+ #define _PAGE_BIT_PAT_LARGE	12	/* On 2MB or 1GB pages */
+-#define _PAGE_BIT_SOFTW4	58	/* available for programmer */
++#define _PAGE_BIT_SOFTW4	57	/* available for programmer */
++#define _PAGE_BIT_SOFTW5	58	/* available for programmer */
+ #define _PAGE_BIT_PKEY_BIT0	59	/* Protection Keys, bit 1/4 */
+ #define _PAGE_BIT_PKEY_BIT1	60	/* Protection Keys, bit 2/4 */
+ #define _PAGE_BIT_PKEY_BIT2	61	/* Protection Keys, bit 3/4 */
+@@ -36,6 +37,16 @@
+ #define _PAGE_BIT_SOFT_DIRTY	_PAGE_BIT_SOFTW3 /* software dirty tracking */
+ #define _PAGE_BIT_DEVMAP	_PAGE_BIT_SOFTW4
+ 
++/*
++ * This bit indicates a copy-on-write page, and is different from
++ * _PAGE_BIT_SOFT_DIRTY, which tracks which pages a task writes to.
++ */
++#ifdef CONFIG_X86_64
++#define _PAGE_BIT_COW		_PAGE_BIT_SOFTW5 /* copy-on-write */
++#else
++#define _PAGE_BIT_COW		0
++#endif
++
+ /* If _PAGE_BIT_PRESENT is clear, we use these: */
+ /* - if the user mapped it with PROT_NONE; pte_present gives true */
+ #define _PAGE_BIT_PROTNONE	_PAGE_BIT_GLOBAL
+@@ -117,6 +128,34 @@
+ #define _PAGE_DEVMAP	(_AT(pteval_t, 0))
+ #endif
+ 
++/*
++ * _PAGE_COW is used to separate R/O and copy-on-write PTEs created by
++ * software from the shadow stack PTE setting required by the hardware:
++ * (a) A modified, copy-on-write (COW) page: (R/O + _PAGE_COW)
++ * (b) A R/O page that has been COW'ed: (R/O +_PAGE_COW)
++ *     The user page is in a R/O VMA, and get_user_pages() needs a
++ *     writable copy.  The page fault handler creates a copy of the page
++ *     and sets the new copy's PTE as R/O and _PAGE_COW.
++ * (c) A shadow stack PTE: (R/O + _PAGE_DIRTY_HW)
++ * (d) A shared (copy-on-access) shadow stack PTE: (R/O + _PAGE_COW)
++ *     When a shadow stack page is being shared among processes (this
++ *     happens at fork()), its PTE is cleared of _PAGE_DIRTY_HW, so the
++ *     next shadow stack access causes a fault, and the page is duplicated
++ *     and _PAGE_DIRTY_HW is set again.  This is the COW equivalent for
++ *     shadow stack pages, even though it's copy-on-access rather than
++ *     copy-on-write.
++ * (e) A page where the processor observed a Write=1 PTE, started a write,
++ *     set Dirty=1, but then observed a Write=0 PTE.  That's possible
++ *     today, but will not happen on processors that support shadow stack.
++ */
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++#define _PAGE_COW	(_AT(pteval_t, 1) << _PAGE_BIT_COW)
++#else
++#define _PAGE_COW	(_AT(pteval_t, 0))
++#endif
++
++#define _PAGE_DIRTY_BITS (_PAGE_DIRTY_HW | _PAGE_COW)
++
+ #define _PAGE_PROTNONE	(_AT(pteval_t, 1) << _PAGE_BIT_PROTNONE)
+ 
+ /*
+-- 
+2.26.2
+
diff --git a/0009-drm-i915-gvt-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch b/0009-drm-i915-gvt-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch
new file mode 100644
index 000000000..1f7a8ba28
--- /dev/null
+++ b/0009-drm-i915-gvt-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch
@@ -0,0 +1,29 @@
+From 207e9ea9cb806e3a704b22ebc9518a17582bd5f5 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 28 Aug 2018 13:01:49 -0700
+Subject: [PATCH 09/40] drm/i915/gvt: Change _PAGE_DIRTY to _PAGE_DIRTY_BITS
+
+After the introduction of _PAGE_COW, a modified page's PTE can have either
+_PAGE_DIRTY_HW or _PAGE_COW.  Change _PAGE_DIRTY to _PAGE_DIRTY_BITS.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ drivers/gpu/drm/i915/gvt/gtt.c | 2 +-
+ 1 file changed, 1 insertion(+), 1 deletion(-)
+
+diff --git a/drivers/gpu/drm/i915/gvt/gtt.c b/drivers/gpu/drm/i915/gvt/gtt.c
+index 210016192ce7..c01f4880c794 100644
+--- a/drivers/gpu/drm/i915/gvt/gtt.c
++++ b/drivers/gpu/drm/i915/gvt/gtt.c
+@@ -1207,7 +1207,7 @@ static int split_2MB_gtt_entry(struct intel_vgpu *vgpu,
+ 	}
+ 
+ 	/* Clear dirty field. */
+-	se->val64 &= ~_PAGE_DIRTY;
++	se->val64 &= ~_PAGE_DIRTY_BITS;
+ 
+ 	ops->clear_pse(se);
+ 	ops->clear_ips(se);
+-- 
+2.26.2
+
diff --git a/0010-x86-mm-Update-pte_modify-for-_PAGE_COW.patch b/0010-x86-mm-Update-pte_modify-for-_PAGE_COW.patch
new file mode 100644
index 000000000..99aa2db81
--- /dev/null
+++ b/0010-x86-mm-Update-pte_modify-for-_PAGE_COW.patch
@@ -0,0 +1,83 @@
+From 994bc9351fb1c9ecebfdd1781ea8878559f42517 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 29 Aug 2019 09:24:13 -0700
+Subject: [PATCH 10/40] x86/mm: Update pte_modify for _PAGE_COW
+
+Pte_modify() changes a PTE to 'newprot'.  It doesn't use the pte_*()
+helpers that a previous patch fixed up, so we need a new site.
+
+Introduce fixup_dirty_pte() to set the dirty bits based on _PAGE_RW, and
+apply the same changes to pmd_modify().
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Replace _PAGE_CHG_MASK approach with fixup functions.
+---
+ arch/x86/include/asm/pgtable.h | 33 +++++++++++++++++++++++++++++++++
+ 1 file changed, 33 insertions(+)
+
+diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
+index 1b57b5543adb..53048a3ff876 100644
+--- a/arch/x86/include/asm/pgtable.h
++++ b/arch/x86/include/asm/pgtable.h
+@@ -727,6 +727,21 @@ static inline pmd_t pmd_mkinvalid(pmd_t pmd)
+ 
+ static inline u64 flip_protnone_guard(u64 oldval, u64 val, u64 mask);
+ 
++static inline pteval_t fixup_dirty_pte(pteval_t pteval)
++{
++	pte_t pte = __pte(pteval);
++
++	if (pte_dirty(pte)) {
++		pte = pte_mkclean(pte);
++
++		if (pte_flags(pte) & _PAGE_RW)
++			pte = pte_set_flags(pte, _PAGE_DIRTY_HW);
++		else
++			pte = pte_set_flags(pte, _PAGE_COW);
++	}
++	return pte_val(pte);
++}
++
+ static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+ {
+ 	pteval_t val = pte_val(pte), oldval = val;
+@@ -737,16 +752,34 @@ static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+ 	 */
+ 	val &= _PAGE_CHG_MASK;
+ 	val |= check_pgprot(newprot) & ~_PAGE_CHG_MASK;
++	val = fixup_dirty_pte(val);
+ 	val = flip_protnone_guard(oldval, val, PTE_PFN_MASK);
+ 	return __pte(val);
+ }
+ 
++static inline int pmd_write(pmd_t pmd);
++static inline pmdval_t fixup_dirty_pmd(pmdval_t pmdval)
++{
++	pmd_t pmd = __pmd(pmdval);
++
++	if (pmd_dirty(pmd)) {
++		pmd = pmd_mkclean(pmd);
++
++		if (pmd_flags(pmd) & _PAGE_RW)
++			pmd = pmd_set_flags(pmd, _PAGE_DIRTY_HW);
++		else
++			pmd = pmd_set_flags(pmd, _PAGE_COW);
++	}
++	return pmd_val(pmd);
++}
++
+ static inline pmd_t pmd_modify(pmd_t pmd, pgprot_t newprot)
+ {
+ 	pmdval_t val = pmd_val(pmd), oldval = val;
+ 
+ 	val &= _HPAGE_CHG_MASK;
+ 	val |= check_pgprot(newprot) & ~_HPAGE_CHG_MASK;
++	val = fixup_dirty_pmd(val);
+ 	val = flip_protnone_guard(oldval, val, PHYSICAL_PMD_PAGE_MASK);
+ 	return __pmd(val);
+ }
+-- 
+2.26.2
+
diff --git a/0011-x86-mm-Update-ptep_set_wrprotect-and-pmdp_set_wrprot.patch b/0011-x86-mm-Update-ptep_set_wrprotect-and-pmdp_set_wrprot.patch
new file mode 100644
index 000000000..1b7a48bf6
--- /dev/null
+++ b/0011-x86-mm-Update-ptep_set_wrprotect-and-pmdp_set_wrprot.patch
@@ -0,0 +1,116 @@
+From 905043b9a8465bbf8d610e7485220cb7af8b061d Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Fri, 15 Jun 2018 09:33:40 -0700
+Subject: [PATCH 11/40] x86/mm: Update ptep_set_wrprotect() and
+ pmdp_set_wrprotect() for transition from _PAGE_DIRTY_HW to _PAGE_COW
+
+When shadow stack is introduced, [R/O + _PAGE_DIRTY_HW] PTE is reserved
+for shadow stack.  Copy-on-write PTEs have [R/O + _PAGE_COW].
+
+When a PTE goes from [R/W + _PAGE_DIRTY_HW] to [R/O + _PAGE_COW], it could
+become a transient shadow stack PTE in two cases:
+
+The first case is that some processors can start a write but end up seeing
+a read-only PTE by the time they get to the Dirty bit, creating a transient
+shadow stack PTE.  However, this will not occur on processors supporting
+shadow stack, therefore we don't need a TLB flush here.
+
+The second case is that when the software, without atomic, tests & replaces
+_PAGE_DIRTY_HW with _PAGE_COW, a transient shadow stack PTE can exist.
+This is prevented with cmpxchg.
+
+Dave Hansen, Jann Horn, Andy Lutomirski, and Peter Zijlstra provided many
+insights to the issue.  Jann Horn provided the cmpxchg solution.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Replace bit shift with pte_wrprotect()/pmd_wrprotect(), which use bit
+  test & shift.
+- Move READ_ONCE of old_pte into try_cmpxchg() loop.
+- Change static_cpu_has() to cpu_feature_enabled().
+
+v9:
+- Change compile-time conditionals to runtime checks.
+- Fix parameters of try_cmpxchg(): change pte_t/pmd_t to
+  pte_t.pte/pmd_t.pmd.
+
+v4:
+- Implement try_cmpxchg().
+---
+ arch/x86/include/asm/pgtable.h | 52 ++++++++++++++++++++++++++++++++++
+ 1 file changed, 52 insertions(+)
+
+diff --git a/arch/x86/include/asm/pgtable.h b/arch/x86/include/asm/pgtable.h
+index 53048a3ff876..18dfedbbd87a 100644
+--- a/arch/x86/include/asm/pgtable.h
++++ b/arch/x86/include/asm/pgtable.h
+@@ -1233,6 +1233,32 @@ static inline pte_t ptep_get_and_clear_full(struct mm_struct *mm,
+ static inline void ptep_set_wrprotect(struct mm_struct *mm,
+ 				      unsigned long addr, pte_t *ptep)
+ {
++	/*
++	 * Some processors can start a write, but end up seeing a read-only
++	 * PTE by the time they get to the Dirty bit.  In this case, they
++	 * will set the Dirty bit, leaving a read-only, Dirty PTE which
++	 * looks like a shadow stack PTE.
++	 *
++	 * However, this behavior has been improved and will not occur on
++	 * processors supporting shadow stack.  Without this guarantee, a
++	 * transition to a non-present PTE and flush the TLB would be
++	 * needed.
++	 *
++	 * When changing a writable PTE to read-only and if the PTE has
++	 * _PAGE_DIRTY_HW set, move that bit to _PAGE_COW so that the
++	 * PTE is not a shadow stack PTE.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		pte_t old_pte, new_pte;
++
++		do {
++			old_pte = READ_ONCE(*ptep);
++			new_pte = pte_wrprotect(old_pte);
++
++		} while (!try_cmpxchg(&ptep->pte, &old_pte.pte, new_pte.pte));
++
++		return;
++	}
+ 	clear_bit(_PAGE_BIT_RW, (unsigned long *)&ptep->pte);
+ }
+ 
+@@ -1289,6 +1315,32 @@ static inline pud_t pudp_huge_get_and_clear(struct mm_struct *mm,
+ static inline void pmdp_set_wrprotect(struct mm_struct *mm,
+ 				      unsigned long addr, pmd_t *pmdp)
+ {
++	/*
++	 * Some processors can start a write, but end up seeing a read-only
++	 * PMD by the time they get to the Dirty bit.  In this case, they
++	 * will set the Dirty bit, leaving a read-only, Dirty PMD which
++	 * looks like a Shadow Stack PMD.
++	 *
++	 * However, this behavior has been improved and will not occur on
++	 * processors supporting Shadow Stack.  Without this guarantee, a
++	 * transition to a non-present PMD and flush the TLB would be
++	 * needed.
++	 *
++	 * When changing a writable PMD to read-only and if the PMD has
++	 * _PAGE_DIRTY_HW set, we move that bit to _PAGE_COW so that the
++	 * PMD is not a shadow stack PMD.
++	 */
++	if (cpu_feature_enabled(X86_FEATURE_SHSTK)) {
++		pmd_t old_pmd, new_pmd;
++
++		do {
++			old_pmd = READ_ONCE(*pmdp);
++			new_pmd = pmd_wrprotect(old_pmd);
++
++		} while (!try_cmpxchg((pmdval_t *)pmdp, (pmdval_t *)&old_pmd, pmd_val(new_pmd)));
++
++		return;
++	}
+ 	clear_bit(_PAGE_BIT_RW, (unsigned long *)pmdp);
+ }
+ 
+-- 
+2.26.2
+
diff --git a/0012-mm-Introduce-VM_SHSTK-for-shadow-stack-memory.patch b/0012-mm-Introduce-VM_SHSTK-for-shadow-stack-memory.patch
new file mode 100644
index 000000000..154ae5b53
--- /dev/null
+++ b/0012-mm-Introduce-VM_SHSTK-for-shadow-stack-memory.patch
@@ -0,0 +1,82 @@
+From 6404e5270c8cb4ae4e5b70017a0d6a2ef1c1dc4f Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Fri, 12 Jan 2018 15:04:54 -0800
+Subject: [PATCH 12/40] mm: Introduce VM_SHSTK for shadow stack memory
+
+A Shadow Stack PTE must be read-only and have _PAGE_DIRTY set.  However,
+read-only and Dirty PTEs also exist for copy-on-write (COW) pages.  These
+two cases are handled differently for page faults.  Introduce VM_SHSTK to
+track shadow stack VMAs.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v9:
+- Add VM_SHSTK case to arch_vma_name().
+- Revise the commit log to explain why adding a new VM flag.
+---
+ arch/x86/mm/mmap.c | 2 ++
+ fs/proc/task_mmu.c | 3 +++
+ include/linux/mm.h | 8 ++++++++
+ 3 files changed, 13 insertions(+)
+
+diff --git a/arch/x86/mm/mmap.c b/arch/x86/mm/mmap.c
+index c90c20904a60..a22c6b6fc607 100644
+--- a/arch/x86/mm/mmap.c
++++ b/arch/x86/mm/mmap.c
+@@ -165,6 +165,8 @@ unsigned long get_mmap_base(int is_legacy)
+ 
+ const char *arch_vma_name(struct vm_area_struct *vma)
+ {
++	if (vma->vm_flags & VM_SHSTK)
++		return "[shadow stack]";
+ 	return NULL;
+ }
+ 
+diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
+index dbda4499a859..0605426a933d 100644
+--- a/fs/proc/task_mmu.c
++++ b/fs/proc/task_mmu.c
+@@ -663,6 +663,9 @@ static void show_smap_vma_flags(struct seq_file *m, struct vm_area_struct *vma)
+ 		[ilog2(VM_PKEY_BIT4)]	= "",
+ #endif
+ #endif /* CONFIG_ARCH_HAS_PKEYS */
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++		[ilog2(VM_SHSTK)]	= "ss",
++#endif
+ 	};
+ 	size_t i;
+ 
+diff --git a/include/linux/mm.h b/include/linux/mm.h
+index dc7b87310c10..0dc33e581c54 100644
+--- a/include/linux/mm.h
++++ b/include/linux/mm.h
+@@ -295,11 +295,13 @@ extern unsigned int kobjsize(const void *objp);
+ #define VM_HIGH_ARCH_BIT_2	34	/* bit only usable on 64-bit architectures */
+ #define VM_HIGH_ARCH_BIT_3	35	/* bit only usable on 64-bit architectures */
+ #define VM_HIGH_ARCH_BIT_4	36	/* bit only usable on 64-bit architectures */
++#define VM_HIGH_ARCH_BIT_5	37	/* bit only usable on 64-bit architectures */
+ #define VM_HIGH_ARCH_0	BIT(VM_HIGH_ARCH_BIT_0)
+ #define VM_HIGH_ARCH_1	BIT(VM_HIGH_ARCH_BIT_1)
+ #define VM_HIGH_ARCH_2	BIT(VM_HIGH_ARCH_BIT_2)
+ #define VM_HIGH_ARCH_3	BIT(VM_HIGH_ARCH_BIT_3)
+ #define VM_HIGH_ARCH_4	BIT(VM_HIGH_ARCH_BIT_4)
++#define VM_HIGH_ARCH_5	BIT(VM_HIGH_ARCH_BIT_5)
+ #endif /* CONFIG_ARCH_USES_HIGH_VMA_FLAGS */
+ 
+ #ifdef CONFIG_ARCH_HAS_PKEYS
+@@ -333,6 +335,12 @@ extern unsigned int kobjsize(const void *objp);
+ # define VM_MAPPED_COPY	VM_ARCH_1	/* T if mapped copy of data (nommu mmap) */
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++# define VM_SHSTK	VM_HIGH_ARCH_5
++#else
++# define VM_SHSTK	VM_NONE
++#endif
++
+ #ifndef VM_GROWSUP
+ # define VM_GROWSUP	VM_NONE
+ #endif
+-- 
+2.26.2
+
diff --git a/0013-x86-mm-Shadow-Stack-page-fault-error-checking.patch b/0013-x86-mm-Shadow-Stack-page-fault-error-checking.patch
new file mode 100644
index 000000000..e46b2ba78
--- /dev/null
+++ b/0013-x86-mm-Shadow-Stack-page-fault-error-checking.patch
@@ -0,0 +1,95 @@
+From 97711f7fc1f9e9a4b8745ed105b71326c981f993 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 28 Nov 2017 13:01:18 -0800
+Subject: [PATCH 13/40] x86/mm: Shadow Stack page fault error checking
+
+Shadow stack accesses are those that are performed by the CPU where it
+expects to encounter a shadow stack mapping.  These accesses are performed
+implicitly by CALL/RET at the site of the shadow stack pointer.  These
+accesses are made explicitly by shadow stack management instructions like
+WRUSSQ.
+
+Shadow stacks accesses to shadow-stack mapping can see faults in normal,
+valid operation just like regular accesses to regular mappings.  Shadow
+stacks need some of the same features like delayed allocation, swap and
+copy-on-write.
+
+Shadow stack accesses can also result in errors, such as when a shadow
+stack overflows, or if a shadow stack access occurs to a non-shadow-stack
+mapping.
+
+In handling a shadow stack page fault, verify it occurs within a shadow
+stack mapping.  It is always an error otherwise.  For valid shadow stack
+accesses, set FAULT_FLAG_WRITE to effect copy-on-write.  Because clearing
+_PAGE_DIRTY_HW (vs. _PAGE_RW) is used to trigger the fault, shadow stack
+read fault and shadow stack write fault are not differentiated and both are
+handled as a write access.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+-Revise commit log.
+---
+ arch/x86/include/asm/traps.h |  2 ++
+ arch/x86/mm/fault.c          | 19 +++++++++++++++++++
+ 2 files changed, 21 insertions(+)
+
+diff --git a/arch/x86/include/asm/traps.h b/arch/x86/include/asm/traps.h
+index 714b1a30e7b0..28b493c53d70 100644
+--- a/arch/x86/include/asm/traps.h
++++ b/arch/x86/include/asm/traps.h
+@@ -50,6 +50,7 @@ void __noreturn handle_stack_overflow(const char *message,
+  *   bit 3 ==				1: use of reserved bit detected
+  *   bit 4 ==				1: fault was an instruction fetch
+  *   bit 5 ==				1: protection keys block access
++ *   bit 6 ==				1: shadow stack access fault
+  */
+ enum x86_pf_error_code {
+ 	X86_PF_PROT	=		1 << 0,
+@@ -58,5 +59,6 @@ enum x86_pf_error_code {
+ 	X86_PF_RSVD	=		1 << 3,
+ 	X86_PF_INSTR	=		1 << 4,
+ 	X86_PF_PK	=		1 << 5,
++	X86_PF_SHSTK	=		1 << 6,
+ };
+ #endif /* _ASM_X86_TRAPS_H */
+diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
+index 1ead568c0101..8c95dc851615 100644
+--- a/arch/x86/mm/fault.c
++++ b/arch/x86/mm/fault.c
+@@ -1064,6 +1064,17 @@ access_error(unsigned long error_code, struct vm_area_struct *vma)
+ 				       (error_code & X86_PF_INSTR), foreign))
+ 		return 1;
+ 
++	/*
++	 * Verify a shadow stack access is within a shadow stack VMA.
++	 * It is always an error otherwise.  Normal data access to a
++	 * shadow stack area is checked in the case followed.
++	 */
++	if (error_code & X86_PF_SHSTK) {
++		if (!(vma->vm_flags & VM_SHSTK))
++			return 1;
++		return 0;
++	}
++
+ 	if (error_code & X86_PF_WRITE) {
+ 		/* write, present and write, not present: */
+ 		if (unlikely(!(vma->vm_flags & VM_WRITE)))
+@@ -1198,6 +1209,14 @@ void do_user_addr_fault(struct pt_regs *regs,
+ 
+ 	perf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);
+ 
++	/*
++	 * Clearing _PAGE_DIRTY_HW is used to detect shadow stack access.
++	 * This method cannot distinguish shadow stack read vs. write.
++	 * For valid shadow stack accesses, set FAULT_FLAG_WRITE to effect
++	 * copy-on-write.
++	 */
++	if (hw_error_code & X86_PF_SHSTK)
++		flags |= FAULT_FLAG_WRITE;
+ 	if (hw_error_code & X86_PF_WRITE)
+ 		flags |= FAULT_FLAG_WRITE;
+ 	if (hw_error_code & X86_PF_INSTR)
+-- 
+2.26.2
+
diff --git a/0014-x86-mm-Update-maybe_mkwrite-for-shadow-stack.patch b/0014-x86-mm-Update-maybe_mkwrite-for-shadow-stack.patch
new file mode 100644
index 000000000..e5f17cfa2
--- /dev/null
+++ b/0014-x86-mm-Update-maybe_mkwrite-for-shadow-stack.patch
@@ -0,0 +1,132 @@
+From f9330f1aa9d71c305e475f67ca32575e1e5059b8 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 7 Apr 2020 16:03:36 -0700
+Subject: [PATCH 14/40] x86/mm: Update maybe_mkwrite() for shadow stack
+
+Shadow stack memory is writable, but its VMA has VM_SHSTK instead of
+VM_WRITE.  Update maybe_mkwrite() to include the shadow stack.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/Kconfig        |  4 ++++
+ arch/x86/mm/pgtable.c   | 18 ++++++++++++++++++
+ include/linux/mm.h      |  2 ++
+ include/linux/pgtable.h | 24 ++++++++++++++++++++++++
+ mm/huge_memory.c        |  2 ++
+ 5 files changed, 50 insertions(+)
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index 3dedb666d9f7..7c0493c41420 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1934,6 +1934,9 @@ config AS_HAS_SHADOW_STACK
+ config X86_INTEL_CET
+ 	def_bool n
+ 
++config ARCH_MAYBE_MKWRITE
++	def_bool n
++
+ config ARCH_HAS_SHADOW_STACK
+ 	def_bool n
+ 
+@@ -1944,6 +1947,7 @@ config X86_INTEL_SHADOW_STACK_USER
+ 	depends on AS_HAS_SHADOW_STACK
+ 	select ARCH_USES_HIGH_VMA_FLAGS
+ 	select X86_INTEL_CET
++	select ARCH_MAYBE_MKWRITE
+ 	select ARCH_HAS_SHADOW_STACK
+ 	help
+ 	  Shadow Stacks provides protection against program stack
+diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c
+index dfd82f51ba66..a9666b64bc05 100644
+--- a/arch/x86/mm/pgtable.c
++++ b/arch/x86/mm/pgtable.c
+@@ -610,6 +610,24 @@ int pmdp_clear_flush_young(struct vm_area_struct *vma,
+ }
+ #endif
+ 
++#ifdef CONFIG_ARCH_MAYBE_MKWRITE
++pte_t arch_maybe_mkwrite(pte_t pte, struct vm_area_struct *vma)
++{
++	if (likely(vma->vm_flags & VM_SHSTK))
++		pte = pte_mkwrite_shstk(pte);
++	return pte;
++}
++
++#ifdef CONFIG_TRANSPARENT_HUGEPAGE
++pmd_t arch_maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma)
++{
++	if (likely(vma->vm_flags & VM_SHSTK))
++		pmd = pmd_mkwrite_shstk(pmd);
++	return pmd;
++}
++#endif /* CONFIG_TRANSPARENT_HUGEPAGE */
++#endif /* CONFIG_ARCH_MAYBE_MKWRITE */
++
+ /**
+  * reserve_top_address - reserves a hole in the top of kernel address space
+  * @reserve - size of hole to reserve
+diff --git a/include/linux/mm.h b/include/linux/mm.h
+index 0dc33e581c54..81d7a65fa208 100644
+--- a/include/linux/mm.h
++++ b/include/linux/mm.h
+@@ -952,6 +952,8 @@ static inline pte_t maybe_mkwrite(pte_t pte, struct vm_area_struct *vma)
+ {
+ 	if (likely(vma->vm_flags & VM_WRITE))
+ 		pte = pte_mkwrite(pte);
++	else
++		pte = arch_maybe_mkwrite(pte, vma);
+ 	return pte;
+ }
+ 
+diff --git a/include/linux/pgtable.h b/include/linux/pgtable.h
+index 56c1e8eb7bb0..03a0815c49e6 100644
+--- a/include/linux/pgtable.h
++++ b/include/linux/pgtable.h
+@@ -1351,6 +1351,30 @@ static inline bool arch_has_pfn_modify_check(void)
+ }
+ #endif /* !_HAVE_ARCH_PFN_MODIFY_ALLOWED */
+ 
++#ifdef CONFIG_MMU
++#ifdef CONFIG_ARCH_MAYBE_MKWRITE
++pte_t arch_maybe_mkwrite(pte_t pte, struct vm_area_struct *vma);
++
++#ifdef CONFIG_TRANSPARENT_HUGEPAGE
++pmd_t arch_maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma);
++#endif /* CONFIG_TRANSPARENT_HUGEPAGE */
++
++#else /* !CONFIG_ARCH_MAYBE_MKWRITE */
++static inline pte_t arch_maybe_mkwrite(pte_t pte, struct vm_area_struct *vma)
++{
++	return pte;
++}
++
++#ifdef CONFIG_TRANSPARENT_HUGEPAGE
++static inline pmd_t arch_maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma)
++{
++	return pmd;
++}
++#endif /* CONFIG_TRANSPARENT_HUGEPAGE */
++
++#endif /* CONFIG_ARCH_MAYBE_MKWRITE */
++#endif /* CONFIG_MMU */
++
+ /*
+  * Architecture PAGE_KERNEL_* fallbacks
+  *
+diff --git a/mm/huge_memory.c b/mm/huge_memory.c
+index 78c84bee7e29..6b1512961f32 100644
+--- a/mm/huge_memory.c
++++ b/mm/huge_memory.c
+@@ -485,6 +485,8 @@ pmd_t maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma)
+ {
+ 	if (likely(vma->vm_flags & VM_WRITE))
+ 		pmd = pmd_mkwrite(pmd);
++	else
++		pmd = arch_maybe_pmd_mkwrite(pmd, vma);
+ 	return pmd;
+ }
+ 
+-- 
+2.26.2
+
diff --git a/0015-mm-Fixup-places-that-call-pte_mkwrite-directly.patch b/0015-mm-Fixup-places-that-call-pte_mkwrite-directly.patch
new file mode 100644
index 000000000..4ed4224cf
--- /dev/null
+++ b/0015-mm-Fixup-places-that-call-pte_mkwrite-directly.patch
@@ -0,0 +1,80 @@
+From e756baaf123ea5348d9e67389aa9498e8e5b1027 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Mon, 13 Apr 2020 13:21:22 -0700
+Subject: [PATCH 15/40] mm: Fixup places that call pte_mkwrite() directly
+
+A shadow stack page is made writable by pte_mkwrite_shstk(), which sets
+_PAGE_DIRTY_HW.  There are a few places that call pte_mkwrite() directly
+and miss the maybe_mkwrite() fixup in the previous patch.  Fix them with
+maybe_mkwrite():
+
+- do_anonymous_page() and migrate_vma_insert_page() check VM_WRITE directly
+  and call pte_mkwrite(), which is the same as maybe_mkwrite().  Change
+  them to maybe_mkwrite().
+
+- In do_numa_page(), if the numa entry 'was-writable', then pte_mkwrite()
+  is called directly.  Fix it by doing maybe_mkwrite().
+
+- In change_pte_range(), pte_mkwrite() is called directly.  Replace it with
+  maybe_mkwrite().
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ mm/memory.c   | 5 ++---
+ mm/migrate.c  | 3 +--
+ mm/mprotect.c | 2 +-
+ 3 files changed, 4 insertions(+), 6 deletions(-)
+
+diff --git a/mm/memory.c b/mm/memory.c
+index 3ecad55103ad..5334d088472c 100644
+--- a/mm/memory.c
++++ b/mm/memory.c
+@@ -3388,8 +3388,7 @@ static vm_fault_t do_anonymous_page(struct vm_fault *vmf)
+ 
+ 	entry = mk_pte(page, vma->vm_page_prot);
+ 	entry = pte_sw_mkyoung(entry);
+-	if (vma->vm_flags & VM_WRITE)
+-		entry = pte_mkwrite(pte_mkdirty(entry));
++	entry = maybe_mkwrite(pte_mkdirty(entry), vma);
+ 
+ 	vmf->pte = pte_offset_map_lock(vma->vm_mm, vmf->pmd, vmf->address,
+ 			&vmf->ptl);
+@@ -4043,7 +4042,7 @@ static vm_fault_t do_numa_page(struct vm_fault *vmf)
+ 	pte = pte_modify(old_pte, vma->vm_page_prot);
+ 	pte = pte_mkyoung(pte);
+ 	if (was_writable)
+-		pte = pte_mkwrite(pte);
++		pte = maybe_mkwrite(pte, vma);
+ 	ptep_modify_prot_commit(vma, vmf->address, vmf->pte, old_pte, pte);
+ 	update_mmu_cache(vma, vmf->address, vmf->pte);
+ 
+diff --git a/mm/migrate.c b/mm/migrate.c
+index 40cd7016ae6f..8fea8636563e 100644
+--- a/mm/migrate.c
++++ b/mm/migrate.c
+@@ -2794,8 +2794,7 @@ static void migrate_vma_insert_page(struct migrate_vma *migrate,
+ 		}
+ 	} else {
+ 		entry = mk_pte(page, vma->vm_page_prot);
+-		if (vma->vm_flags & VM_WRITE)
+-			entry = pte_mkwrite(pte_mkdirty(entry));
++		entry = maybe_mkwrite(pte_mkdirty(entry), vma);
+ 	}
+ 
+ 	ptep = pte_offset_map_lock(mm, pmdp, addr, &ptl);
+diff --git a/mm/mprotect.c b/mm/mprotect.c
+index ce8b8a5eacbb..a8edbcb3af99 100644
+--- a/mm/mprotect.c
++++ b/mm/mprotect.c
+@@ -135,7 +135,7 @@ static unsigned long change_pte_range(struct vm_area_struct *vma, pmd_t *pmd,
+ 			if (dirty_accountable && pte_dirty(ptent) &&
+ 					(pte_soft_dirty(ptent) ||
+ 					 !(vma->vm_flags & VM_SOFTDIRTY))) {
+-				ptent = pte_mkwrite(ptent);
++				ptent = maybe_mkwrite(ptent, vma);
+ 			}
+ 			ptep_modify_prot_commit(vma, addr, pte, oldpte, ptent);
+ 			pages++;
+-- 
+2.26.2
+
diff --git a/0016-mm-Add-guard-pages-around-a-shadow-stack.patch b/0016-mm-Add-guard-pages-around-a-shadow-stack.patch
new file mode 100644
index 000000000..b21ad2e91
--- /dev/null
+++ b/0016-mm-Add-guard-pages-around-a-shadow-stack.patch
@@ -0,0 +1,98 @@
+From 2cc77f65bd353f057d7c80d1fccfb42889af86d6 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Fri, 4 Oct 2019 14:00:58 -0700
+Subject: [PATCH 16/40] mm: Add guard pages around a shadow stack.
+
+INCSSP(Q/D) increments shadow stack pointer and 'pops and discards' the
+first and the last elements in the range, effectively touches those memory
+areas.
+
+The maximum moving distance by INCSSPQ is 255 * 8 = 2040 bytes and
+255 * 4 = 1020 bytes by INCSSPD.  Both ranges are far from PAGE_SIZE.
+Thus, putting a gap page on both ends of a shadow stack prevents INCSSP,
+CALL, and RET from going beyond.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Define ARCH_SHADOW_STACK_GUARD_GAP.
+---
+ arch/x86/include/asm/processor.h | 10 ++++++++++
+ include/linux/mm.h               | 24 ++++++++++++++++++++----
+ 2 files changed, 30 insertions(+), 4 deletions(-)
+
+diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h
+index 03b7c4ca425a..ae18f1820795 100644
+--- a/arch/x86/include/asm/processor.h
++++ b/arch/x86/include/asm/processor.h
+@@ -906,6 +906,16 @@ static inline void spin_lock_prefetch(const void *x)
+ #define STACK_TOP		TASK_SIZE_LOW
+ #define STACK_TOP_MAX		TASK_SIZE_MAX
+ 
++/*
++ * Shadow stack pointer is moved by CALL, JMP, and INCSSP(Q/D).  INCSSPQ
++ * moves shadow stack pointer up to 255 * 8 = ~2 KB (~1KB for INCSSPD) and
++ * touches the first and the last element in the range, which triggers a
++ * page fault if the range is not in a shadow stack.  Because of this,
++ * creating 4-KB guard pages around a shadow stack prevents these
++ * instructions from going beyond.
++ */
++#define ARCH_SHADOW_STACK_GUARD_GAP PAGE_SIZE
++
+ #define INIT_THREAD  {						\
+ 	.addr_limit		= KERNEL_DS,			\
+ }
+diff --git a/include/linux/mm.h b/include/linux/mm.h
+index 81d7a65fa208..9f86af53e889 100644
+--- a/include/linux/mm.h
++++ b/include/linux/mm.h
+@@ -2654,6 +2654,10 @@ extern vm_fault_t filemap_page_mkwrite(struct vm_fault *vmf);
+ int __must_check write_one_page(struct page *page);
+ void task_dirty_inc(struct task_struct *tsk);
+ 
++#ifndef ARCH_SHADOW_STACK_GUARD_GAP
++#define ARCH_SHADOW_STACK_GUARD_GAP 0
++#endif
++
+ extern unsigned long stack_guard_gap;
+ /* Generic expand stack which grows the stack according to GROWS{UP,DOWN} */
+ extern int expand_stack(struct vm_area_struct *vma, unsigned long address);
+@@ -2686,9 +2690,15 @@ static inline struct vm_area_struct * find_vma_intersection(struct mm_struct * m
+ static inline unsigned long vm_start_gap(struct vm_area_struct *vma)
+ {
+ 	unsigned long vm_start = vma->vm_start;
++	unsigned long gap = 0;
+ 
+-	if (vma->vm_flags & VM_GROWSDOWN) {
+-		vm_start -= stack_guard_gap;
++	if (vma->vm_flags & VM_GROWSDOWN)
++		gap = stack_guard_gap;
++	else if (vma->vm_flags & VM_SHSTK)
++		gap = ARCH_SHADOW_STACK_GUARD_GAP;
++
++	if (gap != 0) {
++		vm_start -= gap;
+ 		if (vm_start > vma->vm_start)
+ 			vm_start = 0;
+ 	}
+@@ -2698,9 +2708,15 @@ static inline unsigned long vm_start_gap(struct vm_area_struct *vma)
+ static inline unsigned long vm_end_gap(struct vm_area_struct *vma)
+ {
+ 	unsigned long vm_end = vma->vm_end;
++	unsigned long gap = 0;
++
++	if (vma->vm_flags & VM_GROWSUP)
++		gap = stack_guard_gap;
++	else if (vma->vm_flags & VM_SHSTK)
++		gap = ARCH_SHADOW_STACK_GUARD_GAP;
+ 
+-	if (vma->vm_flags & VM_GROWSUP) {
+-		vm_end += stack_guard_gap;
++	if (gap != 0) {
++		vm_end += gap;
+ 		if (vm_end < vma->vm_end)
+ 			vm_end = -PAGE_SIZE;
+ 	}
+-- 
+2.26.2
+
diff --git a/0017-mm-mmap-Add-shadow-stack-pages-to-memory-accounting.patch b/0017-mm-mmap-Add-shadow-stack-pages-to-memory-accounting.patch
new file mode 100644
index 000000000..fa028201b
--- /dev/null
+++ b/0017-mm-mmap-Add-shadow-stack-pages-to-memory-accounting.patch
@@ -0,0 +1,83 @@
+From 205ed97b5062749a3fefb7af681357129a4b115f Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 13 Sep 2018 12:36:48 -0700
+Subject: [PATCH 17/40] mm/mmap: Add shadow stack pages to memory accounting
+
+Account shadow stack pages to stack memory.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Use arch_shadow_stack_mapping() to make meaning clear.
+
+v8:
+- Change shadow stake pages from data_vm to stack_vm.
+---
+ arch/x86/mm/pgtable.c   |  7 +++++++
+ include/linux/pgtable.h | 11 +++++++++++
+ mm/mmap.c               |  5 +++++
+ 3 files changed, 23 insertions(+)
+
+diff --git a/arch/x86/mm/pgtable.c b/arch/x86/mm/pgtable.c
+index a9666b64bc05..68e98f70298b 100644
+--- a/arch/x86/mm/pgtable.c
++++ b/arch/x86/mm/pgtable.c
+@@ -893,3 +893,10 @@ int pmd_free_pte_page(pmd_t *pmd, unsigned long addr)
+ 
+ #endif /* CONFIG_X86_64 */
+ #endif	/* CONFIG_HAVE_ARCH_HUGE_VMAP */
++
++#ifdef CONFIG_ARCH_HAS_SHADOW_STACK
++bool arch_shadow_stack_mapping(vm_flags_t vm_flags)
++{
++	return (vm_flags & VM_SHSTK);
++}
++#endif
+diff --git a/include/linux/pgtable.h b/include/linux/pgtable.h
+index 03a0815c49e6..19422c0fed2c 100644
+--- a/include/linux/pgtable.h
++++ b/include/linux/pgtable.h
+@@ -1375,6 +1375,17 @@ static inline pmd_t arch_maybe_pmd_mkwrite(pmd_t pmd, struct vm_area_struct *vma
+ #endif /* CONFIG_ARCH_MAYBE_MKWRITE */
+ #endif /* CONFIG_MMU */
+ 
++#ifdef CONFIG_MMU
++#ifdef CONFIG_ARCH_HAS_SHADOW_STACK
++bool arch_shadow_stack_mapping(vm_flags_t vm_flags);
++#else
++static inline bool arch_shadow_stack_mapping(vm_flags_t vm_flags)
++{
++	return false;
++}
++#endif /* CONFIG_ARCH_HAS_SHADOW_STACK */
++#endif /* CONFIG_MMU */
++
+ /*
+  * Architecture PAGE_KERNEL_* fallbacks
+  *
+diff --git a/mm/mmap.c b/mm/mmap.c
+index 8c7ca737a19b..01eac2df1ea0 100644
+--- a/mm/mmap.c
++++ b/mm/mmap.c
+@@ -1681,6 +1681,9 @@ static inline int accountable_mapping(struct file *file, vm_flags_t vm_flags)
+ 	if (file && is_file_hugepages(file))
+ 		return 0;
+ 
++	if (arch_shadow_stack_mapping(vm_flags))
++		return 1;
++
+ 	return (vm_flags & (VM_NORESERVE | VM_SHARED | VM_WRITE)) == VM_WRITE;
+ }
+ 
+@@ -3330,6 +3333,8 @@ void vm_stat_account(struct mm_struct *mm, vm_flags_t flags, long npages)
+ 		mm->stack_vm += npages;
+ 	else if (is_data_mapping(flags))
+ 		mm->data_vm += npages;
++	else if (arch_shadow_stack_mapping(flags))
++		mm->stack_vm += npages;
+ }
+ 
+ static vm_fault_t special_mapping_fault(struct vm_fault *vmf);
+-- 
+2.26.2
+
diff --git a/0018-mm-Update-can_follow_write_pte-for-shadow-stack.patch b/0018-mm-Update-can_follow_write_pte-for-shadow-stack.patch
new file mode 100644
index 000000000..98da62466
--- /dev/null
+++ b/0018-mm-Update-can_follow_write_pte-for-shadow-stack.patch
@@ -0,0 +1,80 @@
+From 9d5b15a6b076c41c1173aeef8de6aeaf637f7842 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 3 Jul 2018 13:07:12 -0700
+Subject: [PATCH 18/40] mm: Update can_follow_write_pte() for shadow stack
+
+Can_follow_write_pte() ensures a read-only page is COWed by checking the
+FOLL_COW flag, and uses pte_dirty() to validate the flag is still valid.
+
+Like a writable data page, a shadow stack page is writable, and becomes
+read-only during copy-on-write, but it is always dirty.  Thus, in the
+can_follow_write_pte() check, it belongs to the writable page case and
+should be excluded from the read-only page pte_dirty() check.  Apply
+the same changes to can_follow_write_pmd().
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Reverse name changes to can_follow_write_*().
+---
+ mm/gup.c         | 8 +++++---
+ mm/huge_memory.c | 8 +++++---
+ 2 files changed, 10 insertions(+), 6 deletions(-)
+
+diff --git a/mm/gup.c b/mm/gup.c
+index 6f47697f8fb0..194dda81de7b 100644
+--- a/mm/gup.c
++++ b/mm/gup.c
+@@ -384,9 +384,11 @@ static int follow_pfn_pte(struct vm_area_struct *vma, unsigned long address,
+  * FOLL_FORCE or a forced COW break can write even to unwritable pte's,
+  * but only after we've gone through a COW cycle and they are dirty.
+  */
+-static inline bool can_follow_write_pte(pte_t pte, unsigned int flags)
++static inline bool can_follow_write_pte(pte_t pte, unsigned int flags,
++					struct vm_area_struct *vma)
+ {
+-	return pte_write(pte) || ((flags & FOLL_COW) && pte_dirty(pte));
++	return pte_write(pte) || ((flags & FOLL_COW) && pte_dirty(pte) &&
++				  !arch_shadow_stack_mapping(vma->vm_flags));
+ }
+ 
+ /*
+@@ -439,7 +441,7 @@ static struct page *follow_page_pte(struct vm_area_struct *vma,
+ 	}
+ 	if ((flags & FOLL_NUMA) && pte_protnone(pte))
+ 		goto no_page;
+-	if ((flags & FOLL_WRITE) && !can_follow_write_pte(pte, flags)) {
++	if ((flags & FOLL_WRITE) && !can_follow_write_pte(pte, flags, vma)) {
+ 		pte_unmap_unlock(ptep, ptl);
+ 		return NULL;
+ 	}
+diff --git a/mm/huge_memory.c b/mm/huge_memory.c
+index 6b1512961f32..f8c9e5d569d8 100644
+--- a/mm/huge_memory.c
++++ b/mm/huge_memory.c
+@@ -1317,9 +1317,11 @@ vm_fault_t do_huge_pmd_wp_page(struct vm_fault *vmf, pmd_t orig_pmd)
+  * FOLL_FORCE or a forced COW break can write even to unwritable pmd's,
+  * but only after we've gone through a COW cycle and they are dirty.
+  */
+-static inline bool can_follow_write_pmd(pmd_t pmd, unsigned int flags)
++static inline bool can_follow_write_pmd(pmd_t pmd, unsigned int flags,
++					struct vm_area_struct *vma)
+ {
+-	return pmd_write(pmd) || ((flags & FOLL_COW) && pmd_dirty(pmd));
++	return pmd_write(pmd) || ((flags & FOLL_COW) && pmd_dirty(pmd) &&
++				  !arch_shadow_stack_mapping(vma->vm_flags));
+ }
+ 
+ struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,
+@@ -1332,7 +1334,7 @@ struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,
+ 
+ 	assert_spin_locked(pmd_lockptr(mm, pmd));
+ 
+-	if (flags & FOLL_WRITE && !can_follow_write_pmd(*pmd, flags))
++	if (flags & FOLL_WRITE && !can_follow_write_pmd(*pmd, flags, vma))
+ 		goto out;
+ 
+ 	/* Avoid dumping huge zero page */
+-- 
+2.26.2
+
diff --git a/0019-x86-cet-shstk-User-mode-shadow-stack-support.patch b/0019-x86-cet-shstk-User-mode-shadow-stack-support.patch
new file mode 100644
index 000000000..87de7dded
--- /dev/null
+++ b/0019-x86-cet-shstk-User-mode-shadow-stack-support.patch
@@ -0,0 +1,378 @@
+From 844e0c15e87fa8c0a1a21b2a0b88b78c93b9c143 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 22 Aug 2019 10:06:11 -0700
+Subject: [PATCH 19/40] x86/cet/shstk: User-mode shadow stack support
+
+This patch adds basic shadow stack enabling/disabling routines.  A task's
+shadow stack is allocated from memory with VM_SHSTK flag and has a fixed
+size of min(RLIMIT_STACK, 4GB).
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v11:
+- Modify alloc_shstk() to take address and flags and pass to do_mmap().
+  This is to be used by an arch_prctl() introduced later.
+
+v10:
+- Change no_cet_shstk to no_user_shstk.
+- Limit shadow stack size to 4 GB, and round_up to PAGE_SIZE.
+- Replace checking shstk_enabled with shstk_size being zero.
+- WARN_ON_ONCE() when vm_munmap() fails.
+
+v9:
+- Change cpu_feature_enabled() to static_cpu_has().
+- Merge cet_disable_shstk to cet_disable_free_shstk.
+- Remove the empty slot at the top of the shadow stack, as it is not
+  needed.
+- Move do_mmap_locked() to alloc_shstk(), which is a static function.
+
+v6:
+- Create a function do_mmap_locked() for shadow stack allocation.
+
+v2:
+- Change noshstk to no_cet_shstk.
+---
+ arch/x86/include/asm/cet.h                    |  26 ++++
+ arch/x86/include/asm/disabled-features.h      |   8 +-
+ arch/x86/include/asm/processor.h              |   5 +
+ arch/x86/kernel/Makefile                      |   2 +
+ arch/x86/kernel/cet.c                         | 138 ++++++++++++++++++
+ arch/x86/kernel/cpu/common.c                  |  28 ++++
+ arch/x86/kernel/process.c                     |   1 +
+ .../arch/x86/include/asm/disabled-features.h  |   8 +-
+ 8 files changed, 214 insertions(+), 2 deletions(-)
+ create mode 100644 arch/x86/include/asm/cet.h
+ create mode 100644 arch/x86/kernel/cet.c
+
+diff --git a/arch/x86/include/asm/cet.h b/arch/x86/include/asm/cet.h
+new file mode 100644
+index 000000000000..caac0687c8e4
+--- /dev/null
++++ b/arch/x86/include/asm/cet.h
+@@ -0,0 +1,26 @@
++/* SPDX-License-Identifier: GPL-2.0 */
++#ifndef _ASM_X86_CET_H
++#define _ASM_X86_CET_H
++
++#ifndef __ASSEMBLY__
++#include <linux/types.h>
++
++struct task_struct;
++/*
++ * Per-thread CET status
++ */
++struct cet_status {
++	unsigned long	shstk_base;
++	unsigned long	shstk_size;
++};
++
++#ifdef CONFIG_X86_INTEL_CET
++int cet_setup_shstk(void);
++void cet_disable_free_shstk(struct task_struct *p);
++#else
++static inline void cet_disable_free_shstk(struct task_struct *p) {}
++#endif
++
++#endif /* __ASSEMBLY__ */
++
++#endif /* _ASM_X86_CET_H */
+diff --git a/arch/x86/include/asm/disabled-features.h b/arch/x86/include/asm/disabled-features.h
+index 4ea8584682f9..a0e1b24cfa02 100644
+--- a/arch/x86/include/asm/disabled-features.h
++++ b/arch/x86/include/asm/disabled-features.h
+@@ -56,6 +56,12 @@
+ # define DISABLE_PTI		(1 << (X86_FEATURE_PTI & 31))
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++#define DISABLE_SHSTK	0
++#else
++#define DISABLE_SHSTK	(1<<(X86_FEATURE_SHSTK & 31))
++#endif
++
+ /*
+  * Make sure to add features to the correct mask
+  */
+@@ -75,7 +81,7 @@
+ #define DISABLED_MASK13	0
+ #define DISABLED_MASK14	0
+ #define DISABLED_MASK15	0
+-#define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP)
++#define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP|DISABLE_SHSTK)
+ #define DISABLED_MASK17	0
+ #define DISABLED_MASK18	0
+ #define DISABLED_MASK_CHECK BUILD_BUG_ON_ZERO(NCAPINTS != 19)
+diff --git a/arch/x86/include/asm/processor.h b/arch/x86/include/asm/processor.h
+index ae18f1820795..2243ff247e9a 100644
+--- a/arch/x86/include/asm/processor.h
++++ b/arch/x86/include/asm/processor.h
+@@ -27,6 +27,7 @@ struct vm86;
+ #include <asm/unwind_hints.h>
+ #include <asm/vmxfeatures.h>
+ #include <asm/vdso/processor.h>
++#include <asm/cet.h>
+ 
+ #include <linux/personality.h>
+ #include <linux/cache.h>
+@@ -544,6 +545,10 @@ struct thread_struct {
+ 
+ 	unsigned int		sig_on_uaccess_err:1;
+ 
++#ifdef CONFIG_X86_INTEL_CET
++	struct cet_status	cet;
++#endif
++
+ 	/* Floating point and extended processor state */
+ 	struct fpu		fpu;
+ 	/*
+diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
+index e77261db2391..76f27f518266 100644
+--- a/arch/x86/kernel/Makefile
++++ b/arch/x86/kernel/Makefile
+@@ -145,6 +145,8 @@ obj-$(CONFIG_UNWINDER_ORC)		+= unwind_orc.o
+ obj-$(CONFIG_UNWINDER_FRAME_POINTER)	+= unwind_frame.o
+ obj-$(CONFIG_UNWINDER_GUESS)		+= unwind_guess.o
+ 
++obj-$(CONFIG_X86_INTEL_CET)		+= cet.o
++
+ ###
+ # 64 bit specific files
+ ifeq ($(CONFIG_X86_64),y)
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+new file mode 100644
+index 000000000000..f261eabdf66b
+--- /dev/null
++++ b/arch/x86/kernel/cet.c
+@@ -0,0 +1,138 @@
++/* SPDX-License-Identifier: GPL-2.0 */
++/*
++ * cet.c - Control-flow Enforcement (CET)
++ *
++ * Copyright (c) 2019, Intel Corporation.
++ * Yu-cheng Yu <yu-cheng.yu@intel.com>
++ */
++
++#include <linux/types.h>
++#include <linux/mm.h>
++#include <linux/mman.h>
++#include <linux/slab.h>
++#include <linux/uaccess.h>
++#include <linux/sched/signal.h>
++#include <linux/compat.h>
++#include <asm/msr.h>
++#include <asm/user.h>
++#include <asm/fpu/internal.h>
++#include <asm/fpu/xstate.h>
++#include <asm/fpu/types.h>
++#include <asm/cet.h>
++
++static void start_update_msrs(void)
++{
++	fpregs_lock();
++	if (test_thread_flag(TIF_NEED_FPU_LOAD))
++		__fpregs_load_activate();
++}
++
++static void end_update_msrs(void)
++{
++	fpregs_unlock();
++}
++
++static unsigned long cet_get_shstk_addr(void)
++{
++	struct fpu *fpu = &current->thread.fpu;
++	unsigned long ssp = 0;
++
++	fpregs_lock();
++
++	if (fpregs_state_valid(fpu, smp_processor_id())) {
++		rdmsrl(MSR_IA32_PL3_SSP, ssp);
++	} else {
++		struct cet_user_state *p;
++
++		p = get_xsave_addr(&fpu->state.xsave, XFEATURE_CET_USER);
++		if (p)
++			ssp = p->user_ssp;
++	}
++
++	fpregs_unlock();
++	return ssp;
++}
++
++static unsigned long alloc_shstk(unsigned long addr, unsigned long size, int flags)
++{
++	struct mm_struct *mm = current->mm;
++	unsigned long populate;
++
++	/* VM_SHSTK requires MAP_ANONYMOUS, MAP_PRIVATE */
++	flags |= MAP_ANONYMOUS | MAP_PRIVATE;
++
++	mmap_write_lock(mm);
++	addr = do_mmap(NULL, addr, size, PROT_READ, flags, VM_SHSTK, 0,
++		       &populate, NULL);
++	mmap_write_unlock(mm);
++
++	if (populate)
++		mm_populate(addr, populate);
++
++	return addr;
++}
++
++int cet_setup_shstk(void)
++{
++	unsigned long addr, size;
++	struct cet_status *cet = &current->thread.cet;
++
++	if (!static_cpu_has(X86_FEATURE_SHSTK))
++		return -EOPNOTSUPP;
++
++	size = round_up(min(rlimit(RLIMIT_STACK), 1UL << 32), PAGE_SIZE);
++	addr = alloc_shstk(0, size, 0);
++
++	if (IS_ERR_VALUE(addr))
++		return PTR_ERR((void *)addr);
++
++	cet->shstk_base = addr;
++	cet->shstk_size = size;
++
++	start_update_msrs();
++	wrmsrl(MSR_IA32_PL3_SSP, addr + size);
++	wrmsrl(MSR_IA32_U_CET, CET_SHSTK_EN);
++	end_update_msrs();
++	return 0;
++}
++
++void cet_disable_free_shstk(struct task_struct *tsk)
++{
++	struct cet_status *cet = &tsk->thread.cet;
++
++	if (!static_cpu_has(X86_FEATURE_SHSTK) ||
++	    !cet->shstk_size || !cet->shstk_base)
++		return;
++
++	if (!tsk->mm || (tsk->mm != current->mm))
++		return;
++
++	if (tsk == current) {
++		u64 msr_val;
++
++		start_update_msrs();
++		rdmsrl(MSR_IA32_U_CET, msr_val);
++		wrmsrl(MSR_IA32_U_CET, msr_val & ~CET_SHSTK_EN);
++		wrmsrl(MSR_IA32_PL3_SSP, 0);
++		end_update_msrs();
++	}
++
++	while (1) {
++		int r;
++
++		r = vm_munmap(cet->shstk_base, cet->shstk_size);
++
++		/*
++		 * Retry if mmap_lock is not available.
++		 */
++		if (r == -EINTR) {
++			cond_resched();
++			continue;
++		}
++
++		WARN_ON_ONCE(r);
++		break;
++	}
++	cet->shstk_base = 0;
++	cet->shstk_size = 0;
++}
+diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
+index 95c090a45b4b..44d51d8008cc 100644
+--- a/arch/x86/kernel/cpu/common.c
++++ b/arch/x86/kernel/cpu/common.c
+@@ -55,6 +55,7 @@
+ #include <asm/microcode_intel.h>
+ #include <asm/intel-family.h>
+ #include <asm/cpu_device_id.h>
++#include <asm/cet.h>
+ #include <asm/uv/uv.h>
+ 
+ #include "cpu.h"
+@@ -492,6 +493,32 @@ static __init int setup_disable_pku(char *arg)
+ __setup("nopku", setup_disable_pku);
+ #endif /* CONFIG_X86_64 */
+ 
++static __always_inline void setup_cet(struct cpuinfo_x86 *c)
++{
++	if (!cpu_feature_enabled(X86_FEATURE_SHSTK) &&
++	    !cpu_feature_enabled(X86_FEATURE_IBT))
++		return;
++
++	cr4_set_bits(X86_CR4_CET);
++}
++
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++static __init int setup_disable_shstk(char *s)
++{
++	/* require an exact match without trailing characters */
++	if (s[0] != '\0')
++		return 0;
++
++	if (!boot_cpu_has(X86_FEATURE_SHSTK))
++		return 1;
++
++	setup_clear_cpu_cap(X86_FEATURE_SHSTK);
++	pr_info("x86: 'no_user_shstk' specified, disabling user Shadow Stack\n");
++	return 1;
++}
++__setup("no_user_shstk", setup_disable_shstk);
++#endif
++
+ /*
+  * Some CPU features depend on higher CPUID levels, which may not always
+  * be available due to CPUID level capping or broken virtualization
+@@ -1521,6 +1548,7 @@ static void identify_cpu(struct cpuinfo_x86 *c)
+ 
+ 	x86_init_rdrand(c);
+ 	setup_pku(c);
++	setup_cet(c);
+ 
+ 	/*
+ 	 * Clear/Set all flags overridden by options, need do it
+diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
+index fe67dbd76e51..9b2c84cbf805 100644
+--- a/arch/x86/kernel/process.c
++++ b/arch/x86/kernel/process.c
+@@ -42,6 +42,7 @@
+ #include <asm/spec-ctrl.h>
+ #include <asm/io_bitmap.h>
+ #include <asm/proto.h>
++#include <asm/cet.h>
+ 
+ #include "process.h"
+ 
+diff --git a/tools/arch/x86/include/asm/disabled-features.h b/tools/arch/x86/include/asm/disabled-features.h
+index 4ea8584682f9..a0e1b24cfa02 100644
+--- a/tools/arch/x86/include/asm/disabled-features.h
++++ b/tools/arch/x86/include/asm/disabled-features.h
+@@ -56,6 +56,12 @@
+ # define DISABLE_PTI		(1 << (X86_FEATURE_PTI & 31))
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_SHADOW_STACK_USER
++#define DISABLE_SHSTK	0
++#else
++#define DISABLE_SHSTK	(1<<(X86_FEATURE_SHSTK & 31))
++#endif
++
+ /*
+  * Make sure to add features to the correct mask
+  */
+@@ -75,7 +81,7 @@
+ #define DISABLED_MASK13	0
+ #define DISABLED_MASK14	0
+ #define DISABLED_MASK15	0
+-#define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP)
++#define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP|DISABLE_SHSTK)
+ #define DISABLED_MASK17	0
+ #define DISABLED_MASK18	0
+ #define DISABLED_MASK_CHECK BUILD_BUG_ON_ZERO(NCAPINTS != 19)
+-- 
+2.26.2
+
diff --git a/0020-x86-cet-shstk-Handle-signals-for-shadow-stack.patch b/0020-x86-cet-shstk-Handle-signals-for-shadow-stack.patch
new file mode 100644
index 000000000..c9eeaab8b
--- /dev/null
+++ b/0020-x86-cet-shstk-Handle-signals-for-shadow-stack.patch
@@ -0,0 +1,569 @@
+From 82ebc16e41da8abe8e886e3f147a5b1ab9078d3d Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 5 Jan 2017 13:48:31 -0800
+Subject: [PATCH 20/40] x86/cet/shstk: Handle signals for shadow stack
+
+To deliver a signal, create a shadow stack restore token and put a restore
+token and the signal restorer address on the shadow stack.  For sigreturn,
+verify the token and restore the shadow stack pointer.
+
+Introduce WRUSS, which is a kernel-mode instruction but writes directly to
+user shadow stack.  It is used to construct the user signal stack as
+described above.
+
+Introduce a signal context extension struct 'sc_ext', which is used to save
+shadow stack restore token address and WAIT_ENDBR status.  WAIT_ENDBR will
+be introduced later in the Indirect Branch Tracking (IBT) series, but add
+that into sc_ext now to keep the struct stable in case the IBT series is
+applied later.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Combine with WRUSS instruction patch, since it is used only here.
+- Revise signal restore code to the latest supervisor states handling.
+  Move shadow stack restore token checking out of the fast path.
+
+v9:
+- Update CET MSR access according to XSAVES supervisor state changes.
+- Add 'wait_endbr' to struct 'sc_ext'.
+- Update and simplify signal frame allocation, setup, and restoration.
+- Update commit log text.
+
+v2:
+- Move CET status from sigcontext to a separate struct sc_ext, which is
+  located above the fpstate on the signal frame.
+- Add a restore token for sigreturn address.
+---
+ arch/x86/ia32/ia32_signal.c            |  17 +++
+ arch/x86/include/asm/cet.h             |   8 ++
+ arch/x86/include/asm/fpu/internal.h    |  10 ++
+ arch/x86/include/asm/special_insns.h   |  32 +++++
+ arch/x86/include/uapi/asm/sigcontext.h |   9 ++
+ arch/x86/kernel/cet.c                  | 154 +++++++++++++++++++++++++
+ arch/x86/kernel/fpu/signal.c           | 100 ++++++++++++++++
+ arch/x86/kernel/signal.c               |  10 ++
+ 8 files changed, 340 insertions(+)
+
+diff --git a/arch/x86/ia32/ia32_signal.c b/arch/x86/ia32/ia32_signal.c
+index 81cf22398cd1..cec9cf0a00cf 100644
+--- a/arch/x86/ia32/ia32_signal.c
++++ b/arch/x86/ia32/ia32_signal.c
+@@ -35,6 +35,7 @@
+ #include <asm/sigframe.h>
+ #include <asm/sighandling.h>
+ #include <asm/smap.h>
++#include <asm/cet.h>
+ 
+ static inline void reload_segments(struct sigcontext_32 *sc)
+ {
+@@ -205,6 +206,7 @@ static void __user *get_sigframe(struct ksignal *ksig, struct pt_regs *regs,
+ 				 void __user **fpstate)
+ {
+ 	unsigned long sp, fx_aligned, math_size;
++	void __user *restorer = NULL;
+ 
+ 	/* Default to using normal stack */
+ 	sp = regs->sp;
+@@ -218,8 +220,23 @@ static void __user *get_sigframe(struct ksignal *ksig, struct pt_regs *regs,
+ 		 ksig->ka.sa.sa_restorer)
+ 		sp = (unsigned long) ksig->ka.sa.sa_restorer;
+ 
++	if (ksig->ka.sa.sa_flags & SA_RESTORER) {
++		restorer = ksig->ka.sa.sa_restorer;
++	} else if (current->mm->context.vdso) {
++		if (ksig->ka.sa.sa_flags & SA_SIGINFO)
++			restorer = current->mm->context.vdso +
++				vdso_image_32.sym___kernel_rt_sigreturn;
++		else
++			restorer = current->mm->context.vdso +
++				vdso_image_32.sym___kernel_sigreturn;
++	}
++
+ 	sp = fpu__alloc_mathframe(sp, 1, &fx_aligned, &math_size);
+ 	*fpstate = (struct _fpstate_32 __user *) sp;
++
++	if (save_cet_to_sigframe(1, *fpstate, (unsigned long)restorer))
++		return (void __user *) -1L;
++
+ 	if (copy_fpstate_to_sigframe(*fpstate, (void __user *)fx_aligned,
+ 				     math_size) < 0)
+ 		return (void __user *) -1L;
+diff --git a/arch/x86/include/asm/cet.h b/arch/x86/include/asm/cet.h
+index caac0687c8e4..56fe08eebae6 100644
+--- a/arch/x86/include/asm/cet.h
++++ b/arch/x86/include/asm/cet.h
+@@ -6,6 +6,8 @@
+ #include <linux/types.h>
+ 
+ struct task_struct;
++struct sc_ext;
++
+ /*
+  * Per-thread CET status
+  */
+@@ -17,8 +19,14 @@ struct cet_status {
+ #ifdef CONFIG_X86_INTEL_CET
+ int cet_setup_shstk(void);
+ void cet_disable_free_shstk(struct task_struct *p);
++int cet_verify_rstor_token(bool ia32, unsigned long ssp, unsigned long *new_ssp);
++void cet_restore_signal(struct sc_ext *sc);
++int cet_setup_signal(bool ia32, unsigned long rstor, struct sc_ext *sc);
+ #else
+ static inline void cet_disable_free_shstk(struct task_struct *p) {}
++static inline void cet_restore_signal(struct sc_ext *sc) { return; }
++static inline int cet_setup_signal(bool ia32, unsigned long rstor,
++				   struct sc_ext *sc) { return -EINVAL; }
+ #endif
+ 
+ #endif /* __ASSEMBLY__ */
+diff --git a/arch/x86/include/asm/fpu/internal.h b/arch/x86/include/asm/fpu/internal.h
+index 845e7481ab77..8bf59b5b82b7 100644
+--- a/arch/x86/include/asm/fpu/internal.h
++++ b/arch/x86/include/asm/fpu/internal.h
+@@ -476,6 +476,16 @@ static inline void copy_kernel_to_fpregs(union fpregs_state *fpstate)
+ 	__copy_kernel_to_fpregs(fpstate, -1);
+ }
+ 
++#ifdef CONFIG_X86_INTEL_CET
++extern int save_cet_to_sigframe(int ia32, void __user *fp,
++				unsigned long restorer);
++#else
++static inline int save_cet_to_sigframe(int ia32, void __user *fp,
++				unsigned long restorer)
++{
++	return 0;
++}
++#endif
+ extern int copy_fpstate_to_sigframe(void __user *buf, void __user *fp, int size);
+ 
+ /*
+diff --git a/arch/x86/include/asm/special_insns.h b/arch/x86/include/asm/special_insns.h
+index eb8e781c4353..46e06bd1d0be 100644
+--- a/arch/x86/include/asm/special_insns.h
++++ b/arch/x86/include/asm/special_insns.h
+@@ -232,6 +232,38 @@ static inline void clwb(volatile void *__p)
+ 		: [pax] "a" (p));
+ }
+ 
++#ifdef CONFIG_X86_INTEL_CET
++#if defined(CONFIG_IA32_EMULATION) || defined(CONFIG_X86_X32)
++static inline int write_user_shstk_32(unsigned long addr, unsigned int val)
++{
++	asm_volatile_goto("1: wrussd %1, (%0)\n"
++			  _ASM_EXTABLE(1b, %l[fail])
++			  :: "r" (addr), "r" (val)
++			  :: fail);
++	return 0;
++fail:
++	return -EPERM;
++}
++#else
++static inline int write_user_shstk_32(unsigned long addr, unsigned int val)
++{
++	WARN_ONCE(1, "%s used but not supported.\n", __func__);
++	return -EFAULT;
++}
++#endif
++
++static inline int write_user_shstk_64(unsigned long addr, unsigned long val)
++{
++	asm_volatile_goto("1: wrussq %1, (%0)\n"
++			  _ASM_EXTABLE(1b, %l[fail])
++			  :: "r" (addr), "r" (val)
++			  :: fail);
++	return 0;
++fail:
++	return -EPERM;
++}
++#endif /* CONFIG_X86_INTEL_CET */
++
+ #define nop() asm volatile ("nop")
+ 
+ 
+diff --git a/arch/x86/include/uapi/asm/sigcontext.h b/arch/x86/include/uapi/asm/sigcontext.h
+index 844d60eb1882..cf2d55db3be4 100644
+--- a/arch/x86/include/uapi/asm/sigcontext.h
++++ b/arch/x86/include/uapi/asm/sigcontext.h
+@@ -196,6 +196,15 @@ struct _xstate {
+ 	/* New processor state extensions go here: */
+ };
+ 
++/*
++ * Located at the end of sigcontext->fpstate, aligned to 8.
++ */
++struct sc_ext {
++	unsigned long total_size;
++	unsigned long ssp;
++	unsigned long wait_endbr;
++};
++
+ /*
+  * The 32-bit signal frame:
+  */
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+index f261eabdf66b..7e8dc7ffd5a9 100644
+--- a/arch/x86/kernel/cet.c
++++ b/arch/x86/kernel/cet.c
+@@ -19,6 +19,8 @@
+ #include <asm/fpu/xstate.h>
+ #include <asm/fpu/types.h>
+ #include <asm/cet.h>
++#include <asm/special_insns.h>
++#include <uapi/asm/sigcontext.h>
+ 
+ static void start_update_msrs(void)
+ {
+@@ -72,6 +74,80 @@ static unsigned long alloc_shstk(unsigned long addr, unsigned long size, int fla
+ 	return addr;
+ }
+ 
++#define TOKEN_MODE_MASK	3UL
++#define TOKEN_MODE_64	1UL
++#define IS_TOKEN_64(token) ((token & TOKEN_MODE_MASK) == TOKEN_MODE_64)
++#define IS_TOKEN_32(token) ((token & TOKEN_MODE_MASK) == 0)
++
++/*
++ * Verify the restore token at the address of 'ssp' is
++ * valid and then set shadow stack pointer according to the
++ * token.
++ */
++int cet_verify_rstor_token(bool ia32, unsigned long ssp,
++			   unsigned long *new_ssp)
++{
++	unsigned long token;
++
++	*new_ssp = 0;
++
++	if (!IS_ALIGNED(ssp, 8))
++		return -EINVAL;
++
++	if (get_user(token, (unsigned long __user *)ssp))
++		return -EFAULT;
++
++	/* Is 64-bit mode flag correct? */
++	if (!ia32 && !IS_TOKEN_64(token))
++		return -EINVAL;
++	else if (ia32 && !IS_TOKEN_32(token))
++		return -EINVAL;
++
++	token &= ~TOKEN_MODE_MASK;
++
++	/*
++	 * Restore address properly aligned?
++	 */
++	if ((!ia32 && !IS_ALIGNED(token, 8)) || !IS_ALIGNED(token, 4))
++		return -EINVAL;
++
++	/*
++	 * Token was placed properly?
++	 */
++	if ((ALIGN_DOWN(token, 8) - 8) != ssp)
++		return -EINVAL;
++
++	*new_ssp = token;
++	return 0;
++}
++
++/*
++ * Create a restore token on the shadow stack.
++ * A token is always 8-byte and aligned to 8.
++ */
++static int create_rstor_token(bool ia32, unsigned long ssp,
++			      unsigned long *new_ssp)
++{
++	unsigned long addr;
++
++	*new_ssp = 0;
++
++	if ((!ia32 && !IS_ALIGNED(ssp, 8)) || !IS_ALIGNED(ssp, 4))
++		return -EINVAL;
++
++	addr = ALIGN_DOWN(ssp, 8) - 8;
++
++	/* Is the token for 64-bit? */
++	if (!ia32)
++		ssp |= TOKEN_MODE_64;
++
++	if (write_user_shstk_64(addr, ssp))
++		return -EFAULT;
++
++	*new_ssp = addr;
++	return 0;
++}
++
+ int cet_setup_shstk(void)
+ {
+ 	unsigned long addr, size;
+@@ -136,3 +212,81 @@ void cet_disable_free_shstk(struct task_struct *tsk)
+ 	cet->shstk_base = 0;
+ 	cet->shstk_size = 0;
+ }
++
++/*
++ * Called from __fpu__restore_sig() and XSAVES buffer is protected by
++ * set_thread_flag(TIF_NEED_FPU_LOAD) in the slow path.
++ */
++void cet_restore_signal(struct sc_ext *sc_ext)
++{
++	struct cet_user_state *cet_user_state;
++	struct cet_status *cet = &current->thread.cet;
++	u64 msr_val = 0;
++
++	if (!static_cpu_has(X86_FEATURE_SHSTK))
++		return;
++
++	cet_user_state = get_xsave_addr(&current->thread.fpu.state.xsave,
++					XFEATURE_CET_USER);
++	if (!cet_user_state)
++		return;
++
++	if (cet->shstk_size) {
++		if (test_thread_flag(TIF_NEED_FPU_LOAD))
++			cet_user_state->user_ssp = sc_ext->ssp;
++		else
++			wrmsrl(MSR_IA32_PL3_SSP, sc_ext->ssp);
++
++		msr_val |= CET_SHSTK_EN;
++	}
++
++	if (test_thread_flag(TIF_NEED_FPU_LOAD))
++		cet_user_state->user_cet = msr_val;
++	else
++		wrmsrl(MSR_IA32_U_CET, msr_val);
++
++	return;
++}
++
++/*
++ * Setup the shadow stack for the signal handler: first,
++ * create a restore token to keep track of the current ssp,
++ * and then the return address of the signal handler.
++ */
++int cet_setup_signal(bool ia32, unsigned long rstor_addr, struct sc_ext *sc_ext)
++{
++	struct cet_status *cet = &current->thread.cet;
++	unsigned long ssp = 0, new_ssp = 0;
++	int err;
++
++	if (cet->shstk_size) {
++		if (!rstor_addr)
++			return -EINVAL;
++
++		ssp = cet_get_shstk_addr();
++		err = create_rstor_token(ia32, ssp, &new_ssp);
++		if (err)
++			return err;
++
++		if (ia32) {
++			ssp = new_ssp - sizeof(u32);
++			err = write_user_shstk_32(ssp, (unsigned int)rstor_addr);
++		} else {
++			ssp = new_ssp - sizeof(u64);
++			err = write_user_shstk_64(ssp, rstor_addr);
++		}
++
++		if (err)
++			return err;
++
++		sc_ext->ssp = new_ssp;
++	}
++
++	if (ssp) {
++		start_update_msrs();
++		wrmsrl(MSR_IA32_PL3_SSP, ssp);
++		end_update_msrs();
++	}
++
++	return 0;
++}
+diff --git a/arch/x86/kernel/fpu/signal.c b/arch/x86/kernel/fpu/signal.c
+index 9393a445d73c..c58b9ba0e29b 100644
+--- a/arch/x86/kernel/fpu/signal.c
++++ b/arch/x86/kernel/fpu/signal.c
+@@ -52,6 +52,74 @@ static inline int check_for_xstate(struct fxregs_state __user *buf,
+ 	return 0;
+ }
+ 
++#ifdef CONFIG_X86_INTEL_CET
++int save_cet_to_sigframe(int ia32, void __user *fp, unsigned long restorer)
++{
++	int err = 0;
++
++	if (!current->thread.cet.shstk_size)
++		return 0;
++
++	if (fp) {
++		struct sc_ext ext = {0, 0, 0};
++
++		err = cet_setup_signal(ia32, restorer, &ext);
++		if (!err) {
++			void __user *p = fp;
++
++			ext.total_size = sizeof(ext);
++
++			if (ia32)
++				p += sizeof(struct fregs_state);
++
++			p += fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE;
++			p = (void __user *)ALIGN((unsigned long)p, 8);
++
++			if (copy_to_user(p, &ext, sizeof(ext)))
++				return -EFAULT;
++		}
++	}
++
++	return err;
++}
++
++static int get_cet_from_sigframe(int ia32, void __user *fp, struct sc_ext *ext)
++{
++	int err = 0;
++
++	memset(ext, 0, sizeof(*ext));
++
++	if (!current->thread.cet.shstk_size)
++		return 0;
++
++	if (fp) {
++		void __user *p = fp;
++
++		if (ia32)
++			p += sizeof(struct fregs_state);
++
++		p += fpu_user_xstate_size + FP_XSTATE_MAGIC2_SIZE;
++		p = (void __user *)ALIGN((unsigned long)p, 8);
++
++		if (copy_from_user(ext, p, sizeof(*ext)))
++			return -EFAULT;
++
++		if (ext->total_size != sizeof(*ext))
++			return -EFAULT;
++
++		if (current->thread.cet.shstk_size)
++			err = cet_verify_rstor_token(ia32, ext->ssp, &ext->ssp);
++	}
++
++	return err;
++}
++#else
++static int get_cet_from_sigframe(int ia32, void __user *fp, struct sc_ext *ext)
++{
++	return 0;
++}
++#endif
++
+ /*
+  * Signal frame handlers.
+  */
+@@ -294,6 +362,7 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
+ 	struct task_struct *tsk = current;
+ 	struct fpu *fpu = &tsk->thread.fpu;
+ 	struct user_i387_ia32_struct env;
++	struct sc_ext sc_ext;
+ 	u64 user_xfeatures = 0;
+ 	int fx_only = 0;
+ 	int ret = 0;
+@@ -334,6 +403,10 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
+ 	if ((unsigned long)buf_fx % 64)
+ 		fx_only = 1;
+ 
++	ret = get_cet_from_sigframe(ia32_fxstate, buf, &sc_ext);
++	if (ret)
++		return ret;
++
+ 	if (!ia32_fxstate) {
+ 		/*
+ 		 * Attempt to restore the FPU registers directly from user
+@@ -348,6 +421,8 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
+ 		pagefault_enable();
+ 		if (!ret) {
+ 
++			cet_restore_signal(&sc_ext);
++
+ 			/*
+ 			 * Restore supervisor states: previous context switch
+ 			 * etc has done XSAVES and saved the supervisor states
+@@ -422,6 +497,8 @@ static int __fpu__restore_sig(void __user *buf, void __user *buf_fx, int size)
+ 		if (unlikely(init_bv))
+ 			copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
+ 
++		cet_restore_signal(&sc_ext);
++
+ 		/*
+ 		 * Restore previously saved supervisor xstates along with
+ 		 * copied-in user xstates.
+@@ -490,12 +567,35 @@ int fpu__restore_sig(void __user *buf, int ia32_frame)
+ 	return __fpu__restore_sig(buf, buf_fx, size);
+ }
+ 
++#ifdef CONFIG_X86_INTEL_CET
++static unsigned long fpu__alloc_sigcontext_ext(unsigned long sp)
++{
++	struct cet_status *cet = &current->thread.cet;
++
++	/*
++	 * sigcontext_ext is at: fpu + fpu_user_xstate_size +
++	 * FP_XSTATE_MAGIC2_SIZE, then aligned to 8.
++	 */
++	if (cet->shstk_size)
++		sp -= (sizeof(struct sc_ext) + 8);
++
++	return sp;
++}
++#else
++static unsigned long fpu__alloc_sigcontext_ext(unsigned long sp)
++{
++	return sp;
++}
++#endif
++
+ unsigned long
+ fpu__alloc_mathframe(unsigned long sp, int ia32_frame,
+ 		     unsigned long *buf_fx, unsigned long *size)
+ {
+ 	unsigned long frame_size = xstate_sigframe_size();
+ 
++	sp = fpu__alloc_sigcontext_ext(sp);
++
+ 	*buf_fx = sp = round_down(sp - frame_size, 64);
+ 	if (ia32_frame && use_fxsr()) {
+ 		frame_size += sizeof(struct fregs_state);
+diff --git a/arch/x86/kernel/signal.c b/arch/x86/kernel/signal.c
+index 399f97abee02..29dcdd82c2b9 100644
+--- a/arch/x86/kernel/signal.c
++++ b/arch/x86/kernel/signal.c
+@@ -45,6 +45,7 @@
+ #include <asm/syscall.h>
+ #include <asm/sigframe.h>
+ #include <asm/signal.h>
++#include <asm/cet.h>
+ 
+ #ifdef CONFIG_X86_64
+ /*
+@@ -238,6 +239,9 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
+ 	unsigned long buf_fx = 0;
+ 	int onsigstack = on_sig_stack(sp);
+ 	int ret;
++#ifdef CONFIG_X86_64
++	void __user *restorer = NULL;
++#endif
+ 
+ 	/* redzone */
+ 	if (IS_ENABLED(CONFIG_X86_64))
+@@ -269,6 +273,12 @@ get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size,
+ 	if (onsigstack && !likely(on_sig_stack(sp)))
+ 		return (void __user *)-1L;
+ 
++#ifdef CONFIG_X86_64
++	if (ka->sa.sa_flags & SA_RESTORER)
++		restorer = ka->sa.sa_restorer;
++	ret = save_cet_to_sigframe(0, *fpstate, (unsigned long)restorer);
++#endif
++
+ 	/* save i387 and extended state */
+ 	ret = copy_fpstate_to_sigframe(*fpstate, (void __user *)buf_fx, math_size);
+ 	if (ret < 0)
+-- 
+2.26.2
+
diff --git a/0021-binfmt_elf-Define-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch b/0021-binfmt_elf-Define-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch
new file mode 100644
index 000000000..a390a09b1
--- /dev/null
+++ b/0021-binfmt_elf-Define-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch
@@ -0,0 +1,36 @@
+From 62a008aeec046b28c0ac66d3ef3e21e8ea471135 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Fri, 18 Oct 2019 18:25:34 +0100
+Subject: [PATCH 21/40] binfmt_elf: Define GNU_PROPERTY_X86_FEATURE_1_AND
+ properties
+
+An ELF file's .note.gnu.property indicates architecture features of the
+file.. Introduce feature definitions for Shadow Stack and Indirect Branch
+Tracking.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ include/uapi/linux/elf.h | 9 +++++++++
+ 1 file changed, 9 insertions(+)
+
+diff --git a/include/uapi/linux/elf.h b/include/uapi/linux/elf.h
+index c6dd0215482e..e294a5ac98aa 100644
+--- a/include/uapi/linux/elf.h
++++ b/include/uapi/linux/elf.h
+@@ -454,4 +454,13 @@ typedef struct elf64_note {
+ /* Bits for GNU_PROPERTY_AARCH64_FEATURE_1_BTI */
+ #define GNU_PROPERTY_AARCH64_FEATURE_1_BTI	(1U << 0)
+ 
++/* .note.gnu.property types for x86: */
++#define GNU_PROPERTY_X86_FEATURE_1_AND		0xc0000002
++
++/* Bits for GNU_PROPERTY_X86_FEATURE_1_AND */
++#define GNU_PROPERTY_X86_FEATURE_1_IBT		0x00000001
++#define GNU_PROPERTY_X86_FEATURE_1_SHSTK	0x00000002
++#define GNU_PROPERTY_X86_FEATURE_1_INVAL ~(GNU_PROPERTY_X86_FEATURE_1_IBT | \
++					    GNU_PROPERTY_X86_FEATURE_1_SHSTK)
++
+ #endif /* _UAPI_LINUX_ELF_H */
+-- 
+2.26.2
+
diff --git a/0022-ELF-Introduce-arch_setup_elf_property.patch b/0022-ELF-Introduce-arch_setup_elf_property.patch
new file mode 100644
index 000000000..9ee2a6283
--- /dev/null
+++ b/0022-ELF-Introduce-arch_setup_elf_property.patch
@@ -0,0 +1,55 @@
+From b6134942aba035bffa76e21da50952900455fad4 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 20 Aug 2019 13:20:37 -0700
+Subject: [PATCH 22/40] ELF: Introduce arch_setup_elf_property()
+
+An ELF file's .note.gnu.property indicates architecture features of the
+file.  These features are extracted by parse_elf_property() and stored in
+the struct 'arch_elf_state'.  Introduce arch_setup_elf_property() to setup
+and enable these features.  The first use-case of this function is shadow
+stack.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ fs/binfmt_elf.c     | 4 ++++
+ include/linux/elf.h | 6 ++++++
+ 2 files changed, 10 insertions(+)
+
+diff --git a/fs/binfmt_elf.c b/fs/binfmt_elf.c
+index 9fe3b51c116a..e9b43b65e619 100644
+--- a/fs/binfmt_elf.c
++++ b/fs/binfmt_elf.c
+@@ -1217,6 +1217,10 @@ static int load_elf_binary(struct linux_binprm *bprm)
+ 
+ 	set_binfmt(&elf_format);
+ 
++	retval = arch_setup_elf_property(&arch_state);
++	if (retval < 0)
++		goto out;
++
+ #ifdef ARCH_HAS_SETUP_ADDITIONAL_PAGES
+ 	retval = arch_setup_additional_pages(bprm, !!interpreter);
+ 	if (retval < 0)
+diff --git a/include/linux/elf.h b/include/linux/elf.h
+index 5d5b0321da0b..4827695ca415 100644
+--- a/include/linux/elf.h
++++ b/include/linux/elf.h
+@@ -82,9 +82,15 @@ static inline int arch_parse_elf_property(u32 type, const void *data,
+ {
+ 	return 0;
+ }
++
++static inline int arch_setup_elf_property(struct arch_elf_state *arch)
++{
++	return 0;
++}
+ #else
+ extern int arch_parse_elf_property(u32 type, const void *data, size_t datasz,
+ 				   bool compat, struct arch_elf_state *arch);
++extern int arch_setup_elf_property(struct arch_elf_state *arch);
+ #endif
+ 
+ #ifdef CONFIG_ARCH_HAVE_ELF_PROT
+-- 
+2.26.2
+
diff --git a/0023-x86-cet-shstk-ELF-header-parsing-for-shadow-stack.patch b/0023-x86-cet-shstk-ELF-header-parsing-for-shadow-stack.patch
new file mode 100644
index 000000000..a1c29b1aa
--- /dev/null
+++ b/0023-x86-cet-shstk-ELF-header-parsing-for-shadow-stack.patch
@@ -0,0 +1,98 @@
+From f0e047792806dbb8153d643e5e0541a810817424 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 3 Oct 2017 16:07:12 -0700
+Subject: [PATCH 23/40] x86/cet/shstk: ELF header parsing for shadow stack
+
+Check an ELF file's .note.gnu.property, and setup shadow stack if the
+application supports it.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v9:
+- Change cpu_feature_enabled() to static_cpu_has().
+---
+ arch/x86/Kconfig             |  2 ++
+ arch/x86/include/asm/elf.h   | 13 +++++++++++++
+ arch/x86/kernel/process_64.c | 32 ++++++++++++++++++++++++++++++++
+ 3 files changed, 47 insertions(+)
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index 7c0493c41420..93dd52a8eecc 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1949,6 +1949,8 @@ config X86_INTEL_SHADOW_STACK_USER
+ 	select X86_INTEL_CET
+ 	select ARCH_MAYBE_MKWRITE
+ 	select ARCH_HAS_SHADOW_STACK
++	select ARCH_USE_GNU_PROPERTY
++	select ARCH_BINFMT_ELF_STATE
+ 	help
+ 	  Shadow Stacks provides protection against program stack
+ 	  corruption.  It's a hardware feature.  This only matters
+diff --git a/arch/x86/include/asm/elf.h b/arch/x86/include/asm/elf.h
+index 452beed7892b..14ce5dc116c8 100644
+--- a/arch/x86/include/asm/elf.h
++++ b/arch/x86/include/asm/elf.h
+@@ -387,6 +387,19 @@ extern int compat_arch_setup_additional_pages(struct linux_binprm *bprm,
+ 					      int uses_interp);
+ #define compat_arch_setup_additional_pages compat_arch_setup_additional_pages
+ 
++#ifdef CONFIG_ARCH_BINFMT_ELF_STATE
++struct arch_elf_state {
++	unsigned int gnu_property;
++};
++
++#define INIT_ARCH_ELF_STATE {	\
++	.gnu_property = 0,	\
++}
++
++#define arch_elf_pt_proc(ehdr, phdr, elf, interp, state) (0)
++#define arch_check_elf(ehdr, interp, interp_ehdr, state) (0)
++#endif
++
+ /* Do not change the values. See get_align_mask() */
+ enum align_flags {
+ 	ALIGN_VA_32	= BIT(0),
+diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
+index 9a97415b2139..d7f85e8a3223 100644
+--- a/arch/x86/kernel/process_64.c
++++ b/arch/x86/kernel/process_64.c
+@@ -729,3 +729,35 @@ unsigned long KSTK_ESP(struct task_struct *task)
+ {
+ 	return task_pt_regs(task)->sp;
+ }
++
++#ifdef CONFIG_ARCH_USE_GNU_PROPERTY
++int arch_parse_elf_property(u32 type, const void *data, size_t datasz,
++			     bool compat, struct arch_elf_state *state)
++{
++	if (type != GNU_PROPERTY_X86_FEATURE_1_AND)
++		return 0;
++
++	if (datasz != sizeof(unsigned int))
++		return -ENOEXEC;
++
++	state->gnu_property = *(unsigned int *)data;
++	return 0;
++}
++
++int arch_setup_elf_property(struct arch_elf_state *state)
++{
++	int r = 0;
++
++	if (!IS_ENABLED(CONFIG_X86_INTEL_CET))
++		return r;
++
++	memset(&current->thread.cet, 0, sizeof(struct cet_status));
++
++	if (static_cpu_has(X86_FEATURE_SHSTK)) {
++		if (state->gnu_property & GNU_PROPERTY_X86_FEATURE_1_SHSTK)
++			r = cet_setup_shstk();
++	}
++
++	return r;
++}
++#endif
+-- 
+2.26.2
+
diff --git a/0024-x86-cet-shstk-Handle-thread-shadow-stack.patch b/0024-x86-cet-shstk-Handle-thread-shadow-stack.patch
new file mode 100644
index 000000000..3f8141a11
--- /dev/null
+++ b/0024-x86-cet-shstk-Handle-thread-shadow-stack.patch
@@ -0,0 +1,149 @@
+From 398576718bd7efb62119c035bad85bf2e047a566 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 3 May 2018 12:40:57 -0700
+Subject: [PATCH 24/40] x86/cet/shstk: Handle thread shadow stack
+
+The kernel allocates (and frees on thread exit) a new shadow stack for a
+pthread child.
+
+    It is possible for the kernel to complete the clone syscall and set the
+    child's shadow stack pointer to NULL and let the child thread allocate
+    a shadow stack for itself.  There are two issues in this approach: It
+    is not compatible with existing code that does inline syscall and it
+    cannot handle signals before the child can successfully allocate a
+    shadow stack.
+
+A 64-bit shadow stack has a size of min(RLIMIT_STACK, 4 GB).  A compat-mode
+thread shadow stack has a size of 1/4 min(RLIMIT_STACK, 4 GB).  This allows
+more threads to run in a 32-bit address space.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Limit shadow stack size to 4 GB.
+---
+ arch/x86/include/asm/cet.h         |  2 ++
+ arch/x86/include/asm/mmu_context.h |  3 +++
+ arch/x86/kernel/cet.c              | 41 ++++++++++++++++++++++++++++++
+ arch/x86/kernel/process.c          |  7 +++++
+ 4 files changed, 53 insertions(+)
+
+diff --git a/arch/x86/include/asm/cet.h b/arch/x86/include/asm/cet.h
+index 56fe08eebae6..71dc92acd2f2 100644
+--- a/arch/x86/include/asm/cet.h
++++ b/arch/x86/include/asm/cet.h
+@@ -18,11 +18,13 @@ struct cet_status {
+ 
+ #ifdef CONFIG_X86_INTEL_CET
+ int cet_setup_shstk(void);
++int cet_setup_thread_shstk(struct task_struct *p);
+ void cet_disable_free_shstk(struct task_struct *p);
+ int cet_verify_rstor_token(bool ia32, unsigned long ssp, unsigned long *new_ssp);
+ void cet_restore_signal(struct sc_ext *sc);
+ int cet_setup_signal(bool ia32, unsigned long rstor, struct sc_ext *sc);
+ #else
++static inline int cet_setup_thread_shstk(struct task_struct *p) { return 0; }
+ static inline void cet_disable_free_shstk(struct task_struct *p) {}
+ static inline void cet_restore_signal(struct sc_ext *sc) { return; }
+ static inline int cet_setup_signal(bool ia32, unsigned long rstor,
+diff --git a/arch/x86/include/asm/mmu_context.h b/arch/x86/include/asm/mmu_context.h
+index 47562147e70b..dbbbab947a0d 100644
+--- a/arch/x86/include/asm/mmu_context.h
++++ b/arch/x86/include/asm/mmu_context.h
+@@ -12,6 +12,7 @@
+ #include <asm/pgalloc.h>
+ #include <asm/tlbflush.h>
+ #include <asm/paravirt.h>
++#include <asm/cet.h>
+ #include <asm/debugreg.h>
+ 
+ extern atomic64_t last_mm_ctx_id;
+@@ -143,6 +144,8 @@ do {						\
+ #else
+ #define deactivate_mm(tsk, mm)			\
+ do {						\
++	if (!tsk->vfork_done)			\
++		cet_disable_free_shstk(tsk);	\
+ 	load_gs_index(0);			\
+ 	loadsegment(fs, 0);			\
+ } while (0)
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+index 7e8dc7ffd5a9..268a0be04464 100644
+--- a/arch/x86/kernel/cet.c
++++ b/arch/x86/kernel/cet.c
+@@ -172,6 +172,47 @@ int cet_setup_shstk(void)
+ 	return 0;
+ }
+ 
++int cet_setup_thread_shstk(struct task_struct *tsk)
++{
++	unsigned long addr, size;
++	struct cet_user_state *state;
++	struct cet_status *cet = &tsk->thread.cet;
++
++	if (!cet->shstk_size)
++		return 0;
++
++	state = get_xsave_addr(&tsk->thread.fpu.state.xsave,
++			       XFEATURE_CET_USER);
++
++	if (!state)
++		return -EINVAL;
++
++	/* Cap shadow stack size to 4 GB */
++	size = min(rlimit(RLIMIT_STACK), 1UL << 32);
++
++	/*
++	 * Compat-mode pthreads share a limited address space.
++	 * If each function call takes an average of four slots
++	 * stack space, we need 1/4 of stack size for shadow stack.
++	 */
++	if (in_compat_syscall())
++		size /= 4;
++	size = round_up(size, PAGE_SIZE);
++	addr = alloc_shstk(0, size, 0);
++
++	if (IS_ERR_VALUE(addr)) {
++		cet->shstk_base = 0;
++		cet->shstk_size = 0;
++		return PTR_ERR((void *)addr);
++	}
++
++	fpu__prepare_write(&tsk->thread.fpu);
++	state->user_ssp = (u64)(addr + size);
++	cet->shstk_base = addr;
++	cet->shstk_size = size;
++	return 0;
++}
++
+ void cet_disable_free_shstk(struct task_struct *tsk)
+ {
+ 	struct cet_status *cet = &tsk->thread.cet;
+diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
+index 9b2c84cbf805..abc27ed0f502 100644
+--- a/arch/x86/kernel/process.c
++++ b/arch/x86/kernel/process.c
+@@ -109,6 +109,7 @@ void exit_thread(struct task_struct *tsk)
+ 
+ 	free_vm86(t);
+ 
++	cet_disable_free_shstk(tsk);
+ 	fpu__drop(fpu);
+ }
+ 
+@@ -179,6 +180,12 @@ int copy_thread_tls(unsigned long clone_flags, unsigned long sp,
+ 	if (clone_flags & CLONE_SETTLS)
+ 		ret = set_new_tls(p, tls);
+ 
++#ifdef CONFIG_X86_64
++	/* Allocate a new shadow stack for pthread */
++	if (!ret && (clone_flags & (CLONE_VFORK | CLONE_VM)) == CLONE_VM)
++		ret = cet_setup_thread_shstk(p);
++#endif
++
+ 	if (!ret && unlikely(test_tsk_thread_flag(current, TIF_IO_BITMAP)))
+ 		io_bitmap_share(p);
+ 
+-- 
+2.26.2
+
diff --git a/0025-x86-cet-shstk-Add-arch_prctl-functions-for-shadow-st.patch b/0025-x86-cet-shstk-Add-arch_prctl-functions-for-shadow-st.patch
new file mode 100644
index 000000000..f1756c0ea
--- /dev/null
+++ b/0025-x86-cet-shstk-Add-arch_prctl-functions-for-shadow-st.patch
@@ -0,0 +1,324 @@
+From 6a70fbacde94a04c70cdda450d303142504b5557 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 3 May 2018 13:04:29 -0700
+Subject: [PATCH 25/40] x86/cet/shstk: Add arch_prctl functions for shadow
+ stack
+
+arch_prctl(ARCH_X86_CET_STATUS, u64 *args)
+    Get CET feature status.
+
+    The parameter 'args' is a pointer to a user buffer.  The kernel returns
+    the following information:
+
+    *args = shadow stack/IBT status
+    *(args + 1) = shadow stack base address
+    *(args + 2) = shadow stack size
+
+arch_prctl(ARCH_X86_CET_DISABLE, u64 features)
+    Disable CET features specified in 'features'.  Return -EPERM if CET is
+    locked.
+
+arch_prctl(ARCH_X86_CET_LOCK)
+    Lock in CET features.
+
+arch_prctl(ARCH_X86_CET_ALLOC_SHSTK, u64 *args)
+    Allocate a new shadow stack.
+
+    The parameter 'args' is a pointer to a user buffer containing the
+    desired size to allocate.  The kernel returns the allocated shadow
+    stack address in *args.
+
+arch_prctl(ARCH_X86_CET_MMAP_SHSTK, u64 *args)
+    Allocate a new shadow stack.
+
+    The parameter 'args' is a pointer to a user buffer.
+
+    *args = allocated shadow stack address
+    *(args + 1) = desired size
+    *(args + 2) = MAP_32BIT or MAP_POPULATE
+
+Also change do_arch_prctl_common()'s parameter 'cpuid_enabled' to
+'arg2', as it is now also passed to prctl_cet().
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v11:
+- Check input for invalid features.
+- Fix prctl_cet() return values.
+- Introduce ARCH_X86_CET_MMAP_SHSTK.
+
+v10:
+- Verify CET is enabled before handling arch_prctl.
+- Change input parameters from unsigned long to u64, to make it clear they
+  are 64-bit.
+---
+ arch/x86/include/asm/cet.h              |   4 +
+ arch/x86/include/uapi/asm/prctl.h       |   6 ++
+ arch/x86/kernel/Makefile                |   2 +-
+ arch/x86/kernel/cet.c                   |  26 +++++
+ arch/x86/kernel/cet_prctl.c             | 124 ++++++++++++++++++++++++
+ arch/x86/kernel/process.c               |   6 +-
+ tools/arch/x86/include/uapi/asm/prctl.h |   6 ++
+ 7 files changed, 170 insertions(+), 4 deletions(-)
+ create mode 100644 arch/x86/kernel/cet_prctl.c
+
+diff --git a/arch/x86/include/asm/cet.h b/arch/x86/include/asm/cet.h
+index 71dc92acd2f2..07d2ed6378f7 100644
+--- a/arch/x86/include/asm/cet.h
++++ b/arch/x86/include/asm/cet.h
+@@ -14,16 +14,20 @@ struct sc_ext;
+ struct cet_status {
+ 	unsigned long	shstk_base;
+ 	unsigned long	shstk_size;
++	unsigned int	locked:1;
+ };
+ 
+ #ifdef CONFIG_X86_INTEL_CET
++int prctl_cet(int option, u64 arg2);
+ int cet_setup_shstk(void);
+ int cet_setup_thread_shstk(struct task_struct *p);
++unsigned long cet_alloc_shstk(unsigned long addr, unsigned long size, int flags);
+ void cet_disable_free_shstk(struct task_struct *p);
+ int cet_verify_rstor_token(bool ia32, unsigned long ssp, unsigned long *new_ssp);
+ void cet_restore_signal(struct sc_ext *sc);
+ int cet_setup_signal(bool ia32, unsigned long rstor, struct sc_ext *sc);
+ #else
++static inline int prctl_cet(int option, u64 arg2) { return -EINVAL; }
+ static inline int cet_setup_thread_shstk(struct task_struct *p) { return 0; }
+ static inline void cet_disable_free_shstk(struct task_struct *p) {}
+ static inline void cet_restore_signal(struct sc_ext *sc) { return; }
+diff --git a/arch/x86/include/uapi/asm/prctl.h b/arch/x86/include/uapi/asm/prctl.h
+index 5a6aac9fa41f..ae4761566f4b 100644
+--- a/arch/x86/include/uapi/asm/prctl.h
++++ b/arch/x86/include/uapi/asm/prctl.h
+@@ -14,4 +14,10 @@
+ #define ARCH_MAP_VDSO_32	0x2002
+ #define ARCH_MAP_VDSO_64	0x2003
+ 
++#define ARCH_X86_CET_STATUS		0x3001
++#define ARCH_X86_CET_DISABLE		0x3002
++#define ARCH_X86_CET_LOCK		0x3003
++#define ARCH_X86_CET_ALLOC_SHSTK	0x3004
++#define ARCH_X86_CET_MMAP_SHSTK		0x3005
++
+ #endif /* _ASM_X86_PRCTL_H */
+diff --git a/arch/x86/kernel/Makefile b/arch/x86/kernel/Makefile
+index 76f27f518266..97556e4204d6 100644
+--- a/arch/x86/kernel/Makefile
++++ b/arch/x86/kernel/Makefile
+@@ -145,7 +145,7 @@ obj-$(CONFIG_UNWINDER_ORC)		+= unwind_orc.o
+ obj-$(CONFIG_UNWINDER_FRAME_POINTER)	+= unwind_frame.o
+ obj-$(CONFIG_UNWINDER_GUESS)		+= unwind_guess.o
+ 
+-obj-$(CONFIG_X86_INTEL_CET)		+= cet.o
++obj-$(CONFIG_X86_INTEL_CET)		+= cet.o cet_prctl.o
+ 
+ ###
+ # 64 bit specific files
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+index 268a0be04464..c6d8a5c9d4b2 100644
+--- a/arch/x86/kernel/cet.c
++++ b/arch/x86/kernel/cet.c
+@@ -148,6 +148,32 @@ static int create_rstor_token(bool ia32, unsigned long ssp,
+ 	return 0;
+ }
+ 
++unsigned long cet_alloc_shstk(unsigned long addr, unsigned long len, int flags)
++{
++	unsigned long token;
++	unsigned long ssp;
++
++	addr = alloc_shstk(addr, round_up(len, PAGE_SIZE), flags);
++
++	if (IS_ERR_VALUE(addr))
++		return addr;
++
++	/* Restore token is 8 bytes and aligned to 8 bytes */
++	ssp = addr + len;
++	token = ssp;
++
++	if (!in_ia32_syscall())
++		token |= TOKEN_MODE_64;
++	ssp -= 8;
++
++	if (write_user_shstk_64(ssp, token)) {
++		vm_munmap(addr, len);
++		return -EINVAL;
++	}
++
++	return addr;
++}
++
+ int cet_setup_shstk(void)
+ {
+ 	unsigned long addr, size;
+diff --git a/arch/x86/kernel/cet_prctl.c b/arch/x86/kernel/cet_prctl.c
+new file mode 100644
+index 000000000000..5a8939d48ff2
+--- /dev/null
++++ b/arch/x86/kernel/cet_prctl.c
+@@ -0,0 +1,124 @@
++/* SPDX-License-Identifier: GPL-2.0 */
++
++#include <linux/errno.h>
++#include <linux/uaccess.h>
++#include <linux/prctl.h>
++#include <linux/compat.h>
++#include <linux/mman.h>
++#include <linux/elfcore.h>
++#include <asm/processor.h>
++#include <asm/prctl.h>
++#include <asm/cet.h>
++
++/* See Documentation/x86/intel_cet.rst. */
++
++static int copy_status_to_user(struct cet_status *cet, u64 arg2)
++{
++	u64 buf[3] = {0, 0, 0};
++
++	if (cet->shstk_size) {
++		buf[0] |= GNU_PROPERTY_X86_FEATURE_1_SHSTK;
++		buf[1] = (u64)cet->shstk_base;
++		buf[2] = (u64)cet->shstk_size;
++	}
++
++	return copy_to_user((u64 __user *)arg2, buf, sizeof(buf));
++}
++
++static int handle_alloc_shstk(u64 arg2)
++{
++	unsigned long addr, size;
++
++	if (get_user(size, (unsigned long __user *)arg2))
++		return -EFAULT;
++
++	addr = cet_alloc_shstk(0, size, 0);
++	if (IS_ERR_VALUE(addr))
++		return PTR_ERR((void *)addr);
++
++	if (put_user((u64)addr, (u64 __user *)arg2)) {
++		vm_munmap(addr, size);
++		return -EFAULT;
++	}
++
++	return 0;
++}
++
++static int handle_mmap_shstk(u64 arg2)
++{
++	u64 buf[3];
++	unsigned long addr, size;
++	int allowed_flags;
++
++	if (copy_from_user(buf, (unsigned long __user *)arg2, sizeof(buf)))
++		return -EFAULT;
++
++	addr = buf[0];
++	size = buf[1];
++
++	/*
++	 * Check invalid flags
++	 */
++	allowed_flags = MAP_ANONYMOUS | MAP_PRIVATE | MAP_32BIT | MAP_POPULATE;
++
++	if (buf[2] & ~allowed_flags)
++		return -EINVAL;
++
++	if (!addr && (buf[2] & MAP_FIXED))
++		return -EINVAL;
++
++	addr = cet_alloc_shstk(addr, size, buf[2]);
++	if (IS_ERR_VALUE(addr))
++		return PTR_ERR((void *)addr);
++
++	if (put_user(addr, (u64 __user *)arg2)) {
++		vm_munmap(addr, size);
++		return -EFAULT;
++	}
++
++	return 0;
++}
++
++int prctl_cet(int option, u64 arg2)
++{
++	struct cet_status *cet;
++
++	/*
++	 * GLIBC's ENOTSUPP == EOPNOTSUPP == 95, and it does not recognize
++	 * the kernel's ENOTSUPP (524).  So return EOPNOTSUPP here.
++	 */
++	if (!IS_ENABLED(CONFIG_X86_INTEL_CET))
++		return -EOPNOTSUPP;
++
++	cet = &current->thread.cet;
++
++	if (option == ARCH_X86_CET_STATUS)
++		return copy_status_to_user(cet, arg2);
++
++	if (!static_cpu_has(X86_FEATURE_SHSTK))
++		return -EOPNOTSUPP;
++
++	switch (option) {
++	case ARCH_X86_CET_DISABLE:
++		if (cet->locked)
++			return -EPERM;
++		if (arg2 & GNU_PROPERTY_X86_FEATURE_1_INVAL)
++			return -EINVAL;
++		if (arg2 & GNU_PROPERTY_X86_FEATURE_1_SHSTK)
++			cet_disable_free_shstk(current);
++		return 0;
++
++	case ARCH_X86_CET_LOCK:
++		cet->locked = 1;
++		return 0;
++
++	case ARCH_X86_CET_ALLOC_SHSTK:
++		return handle_alloc_shstk(arg2);
++
++	case ARCH_X86_CET_MMAP_SHSTK:
++		return handle_mmap_shstk(arg2);
++
++	default:
++		return -ENOSYS;
++	}
++}
+diff --git a/arch/x86/kernel/process.c b/arch/x86/kernel/process.c
+index abc27ed0f502..426557c89b21 100644
+--- a/arch/x86/kernel/process.c
++++ b/arch/x86/kernel/process.c
+@@ -978,14 +978,14 @@ unsigned long get_wchan(struct task_struct *p)
+ }
+ 
+ long do_arch_prctl_common(struct task_struct *task, int option,
+-			  unsigned long cpuid_enabled)
++			  unsigned long arg2)
+ {
+ 	switch (option) {
+ 	case ARCH_GET_CPUID:
+ 		return get_cpuid_mode();
+ 	case ARCH_SET_CPUID:
+-		return set_cpuid_mode(task, cpuid_enabled);
++		return set_cpuid_mode(task, arg2);
+ 	}
+ 
+-	return -EINVAL;
++	return prctl_cet(option, arg2);
+ }
+diff --git a/tools/arch/x86/include/uapi/asm/prctl.h b/tools/arch/x86/include/uapi/asm/prctl.h
+index 5a6aac9fa41f..ae4761566f4b 100644
+--- a/tools/arch/x86/include/uapi/asm/prctl.h
++++ b/tools/arch/x86/include/uapi/asm/prctl.h
+@@ -14,4 +14,10 @@
+ #define ARCH_MAP_VDSO_32	0x2002
+ #define ARCH_MAP_VDSO_64	0x2003
+ 
++#define ARCH_X86_CET_STATUS		0x3001
++#define ARCH_X86_CET_DISABLE		0x3002
++#define ARCH_X86_CET_LOCK		0x3003
++#define ARCH_X86_CET_ALLOC_SHSTK	0x3004
++#define ARCH_X86_CET_MMAP_SHSTK		0x3005
++
+ #endif /* _ASM_X86_PRCTL_H */
+-- 
+2.26.2
+
diff --git a/0026-x86-cet-ibt-Add-Kconfig-option-for-user-mode-Indirec.patch b/0026-x86-cet-ibt-Add-Kconfig-option-for-user-mode-Indirec.patch
new file mode 100644
index 000000000..d49217792
--- /dev/null
+++ b/0026-x86-cet-ibt-Add-Kconfig-option-for-user-mode-Indirec.patch
@@ -0,0 +1,52 @@
+From 851cf03480300f2b11196187ee7117844b8a7ed4 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Wed, 4 Oct 2017 12:35:32 -0700
+Subject: [PATCH 26/40] x86/cet/ibt: Add Kconfig option for user-mode Indirect
+ Branch Tracking
+
+Introduce Kconfig option X86_INTEL_BRANCH_TRACKING_USER.
+
+Indirect Branch Tracking (IBT) provides protection against CALL-/JMP-
+oriented programming attacks.  It is active when the kernel has this
+feature enabled, and the processor and the application support it.
+When this feature is enabled, legacy non-IBT applications continue to
+work, but without IBT protection.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Change build-time CET check to config depends on.
+---
+ arch/x86/Kconfig | 16 ++++++++++++++++
+ 1 file changed, 16 insertions(+)
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index 93dd52a8eecc..1ea6015a26d1 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1962,6 +1962,22 @@ config X86_INTEL_SHADOW_STACK_USER
+ 
+ 	  If unsure, say y.
+ 
++config X86_INTEL_BRANCH_TRACKING_USER
++	prompt "Intel Indirect Branch Tracking for user-mode"
++	def_bool n
++	depends on CPU_SUP_INTEL && X86_64
++	depends on $(cc-option,-fcf-protection)
++	select X86_INTEL_CET
++	help
++	  Indirect Branch Tracking (IBT) provides protection against
++	  CALL-/JMP-oriented programming attacks.  It is active when
++	  the kernel has this feature enabled, and the processor and
++	  the application support it.  When this feature is enabled,
++	  legacy non-IBT applications continue to work, but without
++	  IBT protection.
++
++	  If unsure, say y
++
+ config EFI
+ 	bool "EFI runtime service support"
+ 	depends on ACPI
+-- 
+2.26.2
+
diff --git a/0027-x86-cet-ibt-User-mode-Indirect-Branch-Tracking-suppo.patch b/0027-x86-cet-ibt-User-mode-Indirect-Branch-Tracking-suppo.patch
new file mode 100644
index 000000000..7bf4d29e4
--- /dev/null
+++ b/0027-x86-cet-ibt-User-mode-Indirect-Branch-Tracking-suppo.patch
@@ -0,0 +1,178 @@
+From eabf563fdd784f185b027d45e0d68e72c4f79d85 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Thu, 3 May 2018 13:30:56 -0700
+Subject: [PATCH 27/40] x86/cet/ibt: User-mode Indirect Branch Tracking support
+
+Introduce user-mode Indirect Branch Tracking (IBT) support.  Update setup
+routines to include IBT.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v10:
+- Change no_cet_ibt to no_user_ibt.
+
+v9:
+- Change cpu_feature_enabled() to static_cpu_has().
+
+v2:
+- Change noibt to no_cet_ibt.
+---
+ arch/x86/include/asm/cet.h                    |  3 ++
+ arch/x86/include/asm/disabled-features.h      |  8 ++++-
+ arch/x86/kernel/cet.c                         | 33 +++++++++++++++++++
+ arch/x86/kernel/cpu/common.c                  | 17 ++++++++++
+ .../arch/x86/include/asm/disabled-features.h  |  8 ++++-
+ 5 files changed, 67 insertions(+), 2 deletions(-)
+
+diff --git a/arch/x86/include/asm/cet.h b/arch/x86/include/asm/cet.h
+index 07d2ed6378f7..96372eda0c63 100644
+--- a/arch/x86/include/asm/cet.h
++++ b/arch/x86/include/asm/cet.h
+@@ -15,6 +15,7 @@ struct cet_status {
+ 	unsigned long	shstk_base;
+ 	unsigned long	shstk_size;
+ 	unsigned int	locked:1;
++	unsigned int	ibt_enabled:1;
+ };
+ 
+ #ifdef CONFIG_X86_INTEL_CET
+@@ -26,6 +27,8 @@ void cet_disable_free_shstk(struct task_struct *p);
+ int cet_verify_rstor_token(bool ia32, unsigned long ssp, unsigned long *new_ssp);
+ void cet_restore_signal(struct sc_ext *sc);
+ int cet_setup_signal(bool ia32, unsigned long rstor, struct sc_ext *sc);
++int cet_setup_ibt(void);
++void cet_disable_ibt(void);
+ #else
+ static inline int prctl_cet(int option, u64 arg2) { return -EINVAL; }
+ static inline int cet_setup_thread_shstk(struct task_struct *p) { return 0; }
+diff --git a/arch/x86/include/asm/disabled-features.h b/arch/x86/include/asm/disabled-features.h
+index a0e1b24cfa02..52c9c07cfacc 100644
+--- a/arch/x86/include/asm/disabled-features.h
++++ b/arch/x86/include/asm/disabled-features.h
+@@ -62,6 +62,12 @@
+ #define DISABLE_SHSTK	(1<<(X86_FEATURE_SHSTK & 31))
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_BRANCH_TRACKING_USER
++#define DISABLE_IBT	0
++#else
++#define DISABLE_IBT	(1<<(X86_FEATURE_IBT & 31))
++#endif
++
+ /*
+  * Make sure to add features to the correct mask
+  */
+@@ -83,7 +89,7 @@
+ #define DISABLED_MASK15	0
+ #define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP|DISABLE_SHSTK)
+ #define DISABLED_MASK17	0
+-#define DISABLED_MASK18	0
++#define DISABLED_MASK18	(DISABLE_IBT)
+ #define DISABLED_MASK_CHECK BUILD_BUG_ON_ZERO(NCAPINTS != 19)
+ 
+ #endif /* _ASM_X86_DISABLED_FEATURES_H */
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+index c6d8a5c9d4b2..fde7972a245c 100644
+--- a/arch/x86/kernel/cet.c
++++ b/arch/x86/kernel/cet.c
+@@ -13,6 +13,8 @@
+ #include <linux/uaccess.h>
+ #include <linux/sched/signal.h>
+ #include <linux/compat.h>
++#include <linux/vmalloc.h>
++#include <linux/bitops.h>
+ #include <asm/msr.h>
+ #include <asm/user.h>
+ #include <asm/fpu/internal.h>
+@@ -357,3 +359,34 @@ int cet_setup_signal(bool ia32, unsigned long rstor_addr, struct sc_ext *sc_ext)
+ 
+ 	return 0;
+ }
++
++int cet_setup_ibt(void)
++{
++	u64 msr_val;
++
++	if (!static_cpu_has(X86_FEATURE_IBT))
++		return -EOPNOTSUPP;
++
++	start_update_msrs();
++	rdmsrl(MSR_IA32_U_CET, msr_val);
++	msr_val |= (CET_ENDBR_EN | CET_NO_TRACK_EN);
++	wrmsrl(MSR_IA32_U_CET, msr_val);
++	end_update_msrs();
++	current->thread.cet.ibt_enabled = 1;
++	return 0;
++}
++
++void cet_disable_ibt(void)
++{
++	u64 msr_val;
++
++	if (!static_cpu_has(X86_FEATURE_IBT))
++		return;
++
++	start_update_msrs();
++	rdmsrl(MSR_IA32_U_CET, msr_val);
++	msr_val &= CET_SHSTK_EN;
++	wrmsrl(MSR_IA32_U_CET, msr_val);
++	end_update_msrs();
++	current->thread.cet.ibt_enabled = 0;
++}
+diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
+index 44d51d8008cc..dd36f1ad8950 100644
+--- a/arch/x86/kernel/cpu/common.c
++++ b/arch/x86/kernel/cpu/common.c
+@@ -519,6 +519,23 @@ static __init int setup_disable_shstk(char *s)
+ __setup("no_user_shstk", setup_disable_shstk);
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_BRANCH_TRACKING_USER
++static __init int setup_disable_ibt(char *s)
++{
++	/* require an exact match without trailing characters */
++	if (s[0] != '\0')
++		return 0;
++
++	if (!boot_cpu_has(X86_FEATURE_IBT))
++		return 1;
++
++	setup_clear_cpu_cap(X86_FEATURE_IBT);
++	pr_info("x86: 'no_user_ibt' specified, disabling user Branch Tracking\n");
++	return 1;
++}
++__setup("no_user_ibt", setup_disable_ibt);
++#endif
++
+ /*
+  * Some CPU features depend on higher CPUID levels, which may not always
+  * be available due to CPUID level capping or broken virtualization
+diff --git a/tools/arch/x86/include/asm/disabled-features.h b/tools/arch/x86/include/asm/disabled-features.h
+index a0e1b24cfa02..52c9c07cfacc 100644
+--- a/tools/arch/x86/include/asm/disabled-features.h
++++ b/tools/arch/x86/include/asm/disabled-features.h
+@@ -62,6 +62,12 @@
+ #define DISABLE_SHSTK	(1<<(X86_FEATURE_SHSTK & 31))
+ #endif
+ 
++#ifdef CONFIG_X86_INTEL_BRANCH_TRACKING_USER
++#define DISABLE_IBT	0
++#else
++#define DISABLE_IBT	(1<<(X86_FEATURE_IBT & 31))
++#endif
++
+ /*
+  * Make sure to add features to the correct mask
+  */
+@@ -83,7 +89,7 @@
+ #define DISABLED_MASK15	0
+ #define DISABLED_MASK16	(DISABLE_PKU|DISABLE_OSPKE|DISABLE_LA57|DISABLE_UMIP|DISABLE_SHSTK)
+ #define DISABLED_MASK17	0
+-#define DISABLED_MASK18	0
++#define DISABLED_MASK18	(DISABLE_IBT)
+ #define DISABLED_MASK_CHECK BUILD_BUG_ON_ZERO(NCAPINTS != 19)
+ 
+ #endif /* _ASM_X86_DISABLED_FEATURES_H */
+-- 
+2.26.2
+
diff --git a/0028-x86-cet-ibt-Handle-signals-for-Indirect-Branch-Track.patch b/0028-x86-cet-ibt-Handle-signals-for-Indirect-Branch-Track.patch
new file mode 100644
index 000000000..88775bced
--- /dev/null
+++ b/0028-x86-cet-ibt-Handle-signals-for-Indirect-Branch-Track.patch
@@ -0,0 +1,105 @@
+From 4afaeac2dea969397aac4c672fb8f229a235f77c Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 28 May 2019 12:29:14 -0700
+Subject: [PATCH 28/40] x86/cet/ibt: Handle signals for Indirect Branch
+ Tracking
+
+Indirect Branch Tracking setting does not change in signal delivering or
+sigreturn; except the WAIT_ENDBR status.  In general, a task is in
+WAIT_ENDBR after an indirect CALL/JMP and before the next instruction
+starts.
+
+WAIT_ENDBR status can be read from MSR_IA32_U_CET.  It is reset for signal
+delivering, but preserved on a task's stack and restored for sigreturn.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v9:
+- Fix missing WAIT_ENDBR in signal handling.
+---
+ arch/x86/kernel/cet.c        | 27 +++++++++++++++++++++++++--
+ arch/x86/kernel/fpu/signal.c |  8 +++++---
+ 2 files changed, 30 insertions(+), 5 deletions(-)
+
+diff --git a/arch/x86/kernel/cet.c b/arch/x86/kernel/cet.c
+index fde7972a245c..73e156c6f65f 100644
+--- a/arch/x86/kernel/cet.c
++++ b/arch/x86/kernel/cet.c
+@@ -309,6 +309,13 @@ void cet_restore_signal(struct sc_ext *sc_ext)
+ 		msr_val |= CET_SHSTK_EN;
+ 	}
+ 
++	if (cet->ibt_enabled) {
++		msr_val |= (CET_ENDBR_EN | CET_NO_TRACK_EN);
++
++		if (sc_ext->wait_endbr)
++			msr_val |= CET_WAIT_ENDBR;
++	}
++
+ 	if (test_thread_flag(TIF_NEED_FPU_LOAD))
+ 		cet_user_state->user_cet = msr_val;
+ 	else
+@@ -351,9 +358,25 @@ int cet_setup_signal(bool ia32, unsigned long rstor_addr, struct sc_ext *sc_ext)
+ 		sc_ext->ssp = new_ssp;
+ 	}
+ 
+-	if (ssp) {
++	if (ssp || cet->ibt_enabled) {
++
+ 		start_update_msrs();
+-		wrmsrl(MSR_IA32_PL3_SSP, ssp);
++
++		if (ssp)
++			wrmsrl(MSR_IA32_PL3_SSP, ssp);
++
++		if (cet->ibt_enabled) {
++			u64 r;
++
++			rdmsrl(MSR_IA32_U_CET, r);
++
++			if (r & CET_WAIT_ENDBR) {
++				sc_ext->wait_endbr = 1;
++				r &= ~CET_WAIT_ENDBR;
++				wrmsrl(MSR_IA32_U_CET, r);
++			}
++		}
++
+ 		end_update_msrs();
+ 	}
+ 
+diff --git a/arch/x86/kernel/fpu/signal.c b/arch/x86/kernel/fpu/signal.c
+index c58b9ba0e29b..ffd34a9f5e67 100644
+--- a/arch/x86/kernel/fpu/signal.c
++++ b/arch/x86/kernel/fpu/signal.c
+@@ -57,7 +57,8 @@ int save_cet_to_sigframe(int ia32, void __user *fp, unsigned long restorer)
+ {
+ 	int err = 0;
+ 
+-	if (!current->thread.cet.shstk_size)
++	if (!current->thread.cet.shstk_size &&
++	    !current->thread.cet.ibt_enabled)
+ 		return 0;
+ 
+ 	if (fp) {
+@@ -89,7 +90,8 @@ static int get_cet_from_sigframe(int ia32, void __user *fp, struct sc_ext *ext)
+ 
+ 	memset(ext, 0, sizeof(*ext));
+ 
+-	if (!current->thread.cet.shstk_size)
++	if (!current->thread.cet.shstk_size &&
++	    !current->thread.cet.ibt_enabled)
+ 		return 0;
+ 
+ 	if (fp) {
+@@ -576,7 +578,7 @@ static unsigned long fpu__alloc_sigcontext_ext(unsigned long sp)
+ 	 * sigcontext_ext is at: fpu + fpu_user_xstate_size +
+ 	 * FP_XSTATE_MAGIC2_SIZE, then aligned to 8.
+ 	 */
+-	if (cet->shstk_size)
++	if (cet->shstk_size || cet->ibt_enabled)
+ 		sp -= (sizeof(struct sc_ext) + 8);
+ 
+ 	return sp;
+-- 
+2.26.2
+
diff --git a/0029-x86-cet-ibt-ELF-header-parsing-for-Indirect-Branch-T.patch b/0029-x86-cet-ibt-ELF-header-parsing-for-Indirect-Branch-T.patch
new file mode 100644
index 000000000..fdf234a9a
--- /dev/null
+++ b/0029-x86-cet-ibt-ELF-header-parsing-for-Indirect-Branch-T.patch
@@ -0,0 +1,52 @@
+From bfb60c5d34e201492e10bee322ae14aa9196b76a Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 30 Apr 2019 15:16:22 -0700
+Subject: [PATCH 29/40] x86/cet/ibt: ELF header parsing for Indirect Branch
+ Tracking
+
+Update arch_setup_elf_property() for Indirect Branch Tracking.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v9:
+- Change cpu_feature_enabled() to static_cpu_has().
+---
+ arch/x86/Kconfig             | 2 ++
+ arch/x86/kernel/process_64.c | 8 ++++++++
+ 2 files changed, 10 insertions(+)
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index 1ea6015a26d1..dd642d6ff14b 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1968,6 +1968,8 @@ config X86_INTEL_BRANCH_TRACKING_USER
+ 	depends on CPU_SUP_INTEL && X86_64
+ 	depends on $(cc-option,-fcf-protection)
+ 	select X86_INTEL_CET
++	select ARCH_USE_GNU_PROPERTY
++	select ARCH_BINFMT_ELF_STATE
+ 	help
+ 	  Indirect Branch Tracking (IBT) provides protection against
+ 	  CALL-/JMP-oriented programming attacks.  It is active when
+diff --git a/arch/x86/kernel/process_64.c b/arch/x86/kernel/process_64.c
+index d7f85e8a3223..1cc74eaa61ba 100644
+--- a/arch/x86/kernel/process_64.c
++++ b/arch/x86/kernel/process_64.c
+@@ -758,6 +758,14 @@ int arch_setup_elf_property(struct arch_elf_state *state)
+ 			r = cet_setup_shstk();
+ 	}
+ 
++	if (r < 0)
++		return r;
++
++	if (static_cpu_has(X86_FEATURE_IBT)) {
++		if (state->gnu_property & GNU_PROPERTY_X86_FEATURE_1_IBT)
++			r = cet_setup_ibt();
++	}
++
+ 	return r;
+ }
+ #endif
+-- 
+2.26.2
+
diff --git a/0030-x86-cet-ibt-Add-arch_prctl-functions-for-Indirect-Br.patch b/0030-x86-cet-ibt-Add-arch_prctl-functions-for-Indirect-Br.patch
new file mode 100644
index 000000000..eb09bc2da
--- /dev/null
+++ b/0030-x86-cet-ibt-Add-arch_prctl-functions-for-Indirect-Br.patch
@@ -0,0 +1,51 @@
+From f6adf06dde24d968a7d9990f8c115630eb7dfa42 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Tue, 21 Aug 2018 14:13:05 -0700
+Subject: [PATCH 30/40] x86/cet/ibt: Add arch_prctl functions for Indirect
+ Branch Tracking
+
+Update ARCH_X86_CET_STATUS and ARCH_X86_CET_DISABLE for Indirect Branch
+Tracking.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/kernel/cet_prctl.c | 8 +++++++-
+ 1 file changed, 7 insertions(+), 1 deletion(-)
+
+diff --git a/arch/x86/kernel/cet_prctl.c b/arch/x86/kernel/cet_prctl.c
+index 5a8939d48ff2..d4688dda3d0c 100644
+--- a/arch/x86/kernel/cet_prctl.c
++++ b/arch/x86/kernel/cet_prctl.c
+@@ -22,6 +22,9 @@ static int copy_status_to_user(struct cet_status *cet, u64 arg2)
+ 		buf[2] = (u64)cet->shstk_size;
+ 	}
+ 
++	if (cet->ibt_enabled)
++		buf[0] |= GNU_PROPERTY_X86_FEATURE_1_IBT;
++
+ 	return copy_to_user((u64 __user *)arg2, buf, sizeof(buf));
+ }
+ 
+@@ -95,7 +98,8 @@ int prctl_cet(int option, u64 arg2)
+ 	if (option == ARCH_X86_CET_STATUS)
+ 		return copy_status_to_user(cet, arg2);
+ 
+-	if (!static_cpu_has(X86_FEATURE_SHSTK))
++	if (!static_cpu_has(X86_FEATURE_SHSTK) &&
++	    !static_cpu_has(X86_FEATURE_IBT))
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (option) {
+@@ -106,6 +110,8 @@ int prctl_cet(int option, u64 arg2)
+ 			return -EINVAL;
+ 		if (arg2 & GNU_PROPERTY_X86_FEATURE_1_SHSTK)
+ 			cet_disable_free_shstk(current);
++		if (arg2 & GNU_PROPERTY_X86_FEATURE_1_IBT)
++			cet_disable_ibt();
+ 		return 0;
+ 
+ 	case ARCH_X86_CET_LOCK:
+-- 
+2.26.2
+
diff --git a/0031-x86-cet-Add-PTRACE-interface-for-CET.patch b/0031-x86-cet-Add-PTRACE-interface-for-CET.patch
new file mode 100644
index 000000000..5cf041f4c
--- /dev/null
+++ b/0031-x86-cet-Add-PTRACE-interface-for-CET.patch
@@ -0,0 +1,151 @@
+From 474b55fd91e80f49c338affac772f439174a1c92 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Mon, 23 Apr 2018 12:55:13 -0700
+Subject: [PATCH 31/40] x86/cet: Add PTRACE interface for CET
+
+Add REGSET_CET64/REGSET_CET32 to get/set CET MSRs:
+
+    IA32_U_CET (user-mode CET settings) and
+    IA32_PL3_SSP (user-mode Shadow Stack)
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/include/asm/fpu/regset.h |  7 ++---
+ arch/x86/kernel/fpu/regset.c      | 45 +++++++++++++++++++++++++++++++
+ arch/x86/kernel/ptrace.c          | 16 +++++++++++
+ include/uapi/linux/elf.h          |  1 +
+ 4 files changed, 66 insertions(+), 3 deletions(-)
+
+diff --git a/arch/x86/include/asm/fpu/regset.h b/arch/x86/include/asm/fpu/regset.h
+index d5bdffb9d27f..edad0d889084 100644
+--- a/arch/x86/include/asm/fpu/regset.h
++++ b/arch/x86/include/asm/fpu/regset.h
+@@ -7,11 +7,12 @@
+ 
+ #include <linux/regset.h>
+ 
+-extern user_regset_active_fn regset_fpregs_active, regset_xregset_fpregs_active;
++extern user_regset_active_fn regset_fpregs_active, regset_xregset_fpregs_active,
++				cetregs_active;
+ extern user_regset_get_fn fpregs_get, xfpregs_get, fpregs_soft_get,
+-				xstateregs_get;
++				xstateregs_get, cetregs_get;
+ extern user_regset_set_fn fpregs_set, xfpregs_set, fpregs_soft_set,
+-				 xstateregs_set;
++				 xstateregs_set, cetregs_set;
+ 
+ /*
+  * xstateregs_active == regset_fpregs_active. Please refer to the comment
+diff --git a/arch/x86/kernel/fpu/regset.c b/arch/x86/kernel/fpu/regset.c
+index bd1d0649f8ce..dcb86ccd2b7e 100644
+--- a/arch/x86/kernel/fpu/regset.c
++++ b/arch/x86/kernel/fpu/regset.c
+@@ -156,6 +156,51 @@ int xstateregs_set(struct task_struct *target, const struct user_regset *regset,
+ 	return ret;
+ }
+ 
++int cetregs_active(struct task_struct *target, const struct user_regset *regset)
++{
++#ifdef CONFIG_X86_INTEL_CET
++	if (target->thread.cet.shstk_size || target->thread.cet.ibt_enabled)
++		return regset->n;
++#endif
++	return 0;
++}
++
++int cetregs_get(struct task_struct *target, const struct user_regset *regset,
++		unsigned int pos, unsigned int count,
++		void *kbuf, void __user *ubuf)
++{
++	struct fpu *fpu = &target->thread.fpu;
++	struct cet_user_state *cetregs;
++
++	if (!boot_cpu_has(X86_FEATURE_SHSTK))
++		return -ENODEV;
++
++	fpu__prepare_read(fpu);
++	cetregs = get_xsave_addr(&fpu->state.xsave, XFEATURE_CET_USER);
++	if (!cetregs)
++		return -EFAULT;
++
++	return user_regset_copyout(&pos, &count, &kbuf, &ubuf, cetregs, 0, -1);
++}
++
++int cetregs_set(struct task_struct *target, const struct user_regset *regset,
++		  unsigned int pos, unsigned int count,
++		  const void *kbuf, const void __user *ubuf)
++{
++	struct fpu *fpu = &target->thread.fpu;
++	struct cet_user_state *cetregs;
++
++	if (!boot_cpu_has(X86_FEATURE_SHSTK))
++		return -ENODEV;
++
++	fpu__prepare_write(fpu);
++	cetregs = get_xsave_addr(&fpu->state.xsave, XFEATURE_CET_USER);
++	if (!cetregs)
++		return -EFAULT;
++
++	return user_regset_copyin(&pos, &count, &kbuf, &ubuf, cetregs, 0, -1);
++}
++
+ #if defined CONFIG_X86_32 || defined CONFIG_IA32_EMULATION
+ 
+ /*
+diff --git a/arch/x86/kernel/ptrace.c b/arch/x86/kernel/ptrace.c
+index 44130588987f..064c0fbe0ef8 100644
+--- a/arch/x86/kernel/ptrace.c
++++ b/arch/x86/kernel/ptrace.c
+@@ -52,7 +52,9 @@ enum x86_regset {
+ 	REGSET_IOPERM64 = REGSET_XFP,
+ 	REGSET_XSTATE,
+ 	REGSET_TLS,
++	REGSET_CET64 = REGSET_TLS,
+ 	REGSET_IOPERM32,
++	REGSET_CET32,
+ };
+ 
+ struct pt_regs_offset {
+@@ -1254,6 +1256,13 @@ static struct user_regset x86_64_regsets[] __ro_after_init = {
+ 		.size = sizeof(long), .align = sizeof(long),
+ 		.active = ioperm_active, .get = ioperm_get
+ 	},
++	[REGSET_CET64] = {
++		.core_note_type = NT_X86_CET,
++		.n = sizeof(struct cet_user_state) / sizeof(u64),
++		.size = sizeof(u64), .align = sizeof(u64),
++		.active = cetregs_active, .get = cetregs_get,
++		.set = cetregs_set
++	},
+ };
+ 
+ static const struct user_regset_view user_x86_64_view = {
+@@ -1309,6 +1318,13 @@ static struct user_regset x86_32_regsets[] __ro_after_init = {
+ 		.size = sizeof(u32), .align = sizeof(u32),
+ 		.active = ioperm_active, .get = ioperm_get
+ 	},
++	[REGSET_CET32] = {
++		.core_note_type = NT_X86_CET,
++		.n = sizeof(struct cet_user_state) / sizeof(u64),
++		.size = sizeof(u64), .align = sizeof(u64),
++		.active = cetregs_active, .get = cetregs_get,
++		.set = cetregs_set
++	},
+ };
+ 
+ static const struct user_regset_view user_x86_32_view = {
+diff --git a/include/uapi/linux/elf.h b/include/uapi/linux/elf.h
+index e294a5ac98aa..641b5cff3467 100644
+--- a/include/uapi/linux/elf.h
++++ b/include/uapi/linux/elf.h
+@@ -402,6 +402,7 @@ typedef struct elf64_shdr {
+ #define NT_386_TLS	0x200		/* i386 TLS slots (struct user_desc) */
+ #define NT_386_IOPERM	0x201		/* x86 io permission bitmap (1=deny) */
+ #define NT_X86_XSTATE	0x202		/* x86 extended state using xsave */
++#define NT_X86_CET	0x203		/* x86 cet state */
+ #define NT_S390_HIGH_GPRS	0x300	/* s390 upper register halves */
+ #define NT_S390_TIMER	0x301		/* s390 timer register */
+ #define NT_S390_TODCMP	0x302		/* s390 TOD clock comparator register */
+-- 
+2.26.2
+
diff --git a/0032-x86-vdso-32-Add-ENDBR32-to-__kernel_vsyscall-entry-p.patch b/0032-x86-vdso-32-Add-ENDBR32-to-__kernel_vsyscall-entry-p.patch
new file mode 100644
index 000000000..540530d63
--- /dev/null
+++ b/0032-x86-vdso-32-Add-ENDBR32-to-__kernel_vsyscall-entry-p.patch
@@ -0,0 +1,31 @@
+From 79f0c7ee6b3709027532eaf2583efa271678b487 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Fri, 28 Sep 2018 06:21:50 -0700
+Subject: [PATCH 32/40] x86/vdso/32: Add ENDBR32 to __kernel_vsyscall entry
+ point
+
+Add ENDBR32 to __kernel_vsyscall entry point.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/entry/vdso/vdso32/system_call.S | 3 +++
+ 1 file changed, 3 insertions(+)
+
+diff --git a/arch/x86/entry/vdso/vdso32/system_call.S b/arch/x86/entry/vdso/vdso32/system_call.S
+index de1fff7188aa..5cf74ebd4746 100644
+--- a/arch/x86/entry/vdso/vdso32/system_call.S
++++ b/arch/x86/entry/vdso/vdso32/system_call.S
+@@ -14,6 +14,9 @@
+ 	ALIGN
+ __kernel_vsyscall:
+ 	CFI_STARTPROC
++#ifdef CONFIG_X86_INTEL_BRANCH_TRACKING_USER
++	endbr32
++#endif
+ 	/*
+ 	 * Reshuffle regs so that all of any of the entry instructions
+ 	 * will preserve enough state.
+-- 
+2.26.2
+
diff --git a/0033-x86-vdso-Insert-endbr32-endbr64-to-vDSO.patch b/0033-x86-vdso-Insert-endbr32-endbr64-to-vDSO.patch
new file mode 100644
index 000000000..6a453d715
--- /dev/null
+++ b/0033-x86-vdso-Insert-endbr32-endbr64-to-vDSO.patch
@@ -0,0 +1,34 @@
+From bd6ed276cff59a2567a497b928bbfe40529de953 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Fri, 16 Mar 2018 04:18:48 -0700
+Subject: [PATCH 33/40] x86/vdso: Insert endbr32/endbr64 to vDSO
+
+When Indirect Branch Tracking (IBT) is enabled, vDSO functions may be
+called indirectly, and must have ENDBR32 or ENDBR64 as the first
+instruction.  The compiler must support -fcf-protection=branch so that it
+can be used to compile vDSO.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/entry/vdso/Makefile | 4 ++++
+ 1 file changed, 4 insertions(+)
+
+diff --git a/arch/x86/entry/vdso/Makefile b/arch/x86/entry/vdso/Makefile
+index 04e65f0698f6..240530b58457 100644
+--- a/arch/x86/entry/vdso/Makefile
++++ b/arch/x86/entry/vdso/Makefile
+@@ -130,6 +130,10 @@ $(obj)/%-x32.o: $(obj)/%.o FORCE
+ 
+ targets += vdsox32.lds $(vobjx32s-y)
+ 
++ifdef CONFIG_X86_INTEL_BRANCH_TRACKING_USER
++    $(obj)/vclock_gettime.o $(obj)/vgetcpu.o $(obj)/vdso32/vclock_gettime.o: KBUILD_CFLAGS += -fcf-protection=branch
++endif
++
+ $(obj)/%.so: OBJCOPYFLAGS := -S
+ $(obj)/%.so: $(obj)/%.so.dbg FORCE
+ 	$(call if_changed,objcopy)
+-- 
+2.26.2
+
diff --git a/0034-x86-Disallow-vsyscall-emulation-when-CET-is-enabled.patch b/0034-x86-Disallow-vsyscall-emulation-when-CET-is-enabled.patch
new file mode 100644
index 000000000..68b19533b
--- /dev/null
+++ b/0034-x86-Disallow-vsyscall-emulation-when-CET-is-enabled.patch
@@ -0,0 +1,59 @@
+From 2a0abf7fc7b425920e95589229161e18b0964333 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Wed, 29 Jan 2020 08:44:11 -0800
+Subject: [PATCH 34/40] x86: Disallow vsyscall emulation when CET is enabled
+
+Emulation of the legacy vsyscall page is required by some programs built
+before 2013.  Newer programs after 2013 don't use it.  Disallow vsyscall
+emulation when Control-flow Enforcement (CET) is enabled to enhance
+security.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ arch/x86/Kconfig | 8 ++++++--
+ 1 file changed, 6 insertions(+), 2 deletions(-)
+
+diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
+index dd642d6ff14b..3e8f5a66dc5a 100644
+--- a/arch/x86/Kconfig
++++ b/arch/x86/Kconfig
+@@ -1206,7 +1206,7 @@ config X86_ESPFIX64
+ config X86_VSYSCALL_EMULATION
+ 	bool "Enable vsyscall emulation" if EXPERT
+ 	default y
+-	depends on X86_64
++	depends on X86_64 && !X86_INTEL_CET
+ 	help
+ 	 This enables emulation of the legacy vsyscall page.  Disabling
+ 	 it is roughly equivalent to booting with vsyscall=none, except
+@@ -1221,6 +1221,8 @@ config X86_VSYSCALL_EMULATION
+ 	 Disabling this option saves about 7K of kernel size and
+ 	 possibly 4K of additional runtime pagetable memory.
+ 
++	 This option is disabled when Intel CET is enabled.
++
+ config X86_IOPL_IOPERM
+ 	bool "IOPERM and IOPL Emulation"
+ 	default y
+@@ -2360,7 +2362,7 @@ config COMPAT_VDSO
+ 
+ choice
+ 	prompt "vsyscall table for legacy applications"
+-	depends on X86_64
++	depends on X86_64 && !X86_INTEL_CET
+ 	default LEGACY_VSYSCALL_XONLY
+ 	help
+ 	  Legacy user code that does not know how to find the vDSO expects
+@@ -2377,6 +2379,8 @@ choice
+ 
+ 	  If unsure, select "Emulate execution only".
+ 
++	  This option is not enabled when Intel CET is enabled.
++
+ 	config LEGACY_VSYSCALL_EMULATE
+ 		bool "Full emulation"
+ 		help
+-- 
+2.26.2
+
diff --git a/0035-powerpc-Keep-.rela-sections-when-CONFIG_RELOCATABLE-.patch b/0035-powerpc-Keep-.rela-sections-when-CONFIG_RELOCATABLE-.patch
new file mode 100644
index 000000000..2f9f1be04
--- /dev/null
+++ b/0035-powerpc-Keep-.rela-sections-when-CONFIG_RELOCATABLE-.patch
@@ -0,0 +1,56 @@
+From 9b666dbe3a582f76fee031cb9ec2f3fc8d168f5a Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Mon, 27 Apr 2020 14:04:48 -0700
+Subject: [PATCH 35/40] powerpc: Keep .rela* sections when CONFIG_RELOCATABLE
+ is defined
+
+arch/powerpc/kernel/vmlinux.lds.S has
+
+ #ifdef CONFIG_RELOCATABLE
+ ...
+        .rela.dyn : AT(ADDR(.rela.dyn) - LOAD_OFFSET)
+        {
+                __rela_dyn_start = .;
+                *(.rela*)
+        }
+ #endif
+ ...
+        DISCARDS
+        /DISCARD/ : {
+                *(*.EMB.apuinfo)
+                *(.glink .iplt .plt .rela* .comment)
+                *(.gnu.version*)
+                *(.gnu.attributes)
+                *(.eh_frame)
+        }
+
+Since .rela* sections are needed when CONFIG_RELOCATABLE is defined,
+don't discard .rela* sections if CONFIG_RELOCATABLE is defined.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Acked-by: Michael Ellerman <mpe@ellerman.id.au> (powerpc)
+---
+ arch/powerpc/kernel/vmlinux.lds.S | 5 ++++-
+ 1 file changed, 4 insertions(+), 1 deletion(-)
+
+diff --git a/arch/powerpc/kernel/vmlinux.lds.S b/arch/powerpc/kernel/vmlinux.lds.S
+index 326e113d2e45..7f839c30619e 100644
+--- a/arch/powerpc/kernel/vmlinux.lds.S
++++ b/arch/powerpc/kernel/vmlinux.lds.S
+@@ -366,9 +366,12 @@ SECTIONS
+ 	DISCARDS
+ 	/DISCARD/ : {
+ 		*(*.EMB.apuinfo)
+-		*(.glink .iplt .plt .rela* .comment)
++		*(.glink .iplt .plt .comment)
+ 		*(.gnu.version*)
+ 		*(.gnu.attributes)
+ 		*(.eh_frame)
++#ifndef CONFIG_RELOCATABLE
++		*(.rela*)
++#endif
+ 	}
+ }
+-- 
+2.26.2
+
diff --git a/0036-Discard-.note.gnu.property-sections-in-generic-NOTES.patch b/0036-Discard-.note.gnu.property-sections-in-generic-NOTES.patch
new file mode 100644
index 000000000..cc9e43096
--- /dev/null
+++ b/0036-Discard-.note.gnu.property-sections-in-generic-NOTES.patch
@@ -0,0 +1,81 @@
+From 80d436746749bc46f62613e4f2f397f53b01864d Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 12:39:09 -0800
+Subject: [PATCH 36/40] Discard .note.gnu.property sections in generic NOTES
+
+With the command-line option, -mx86-used-note=yes, the x86 assembler
+in binutils 2.32 and above generates a program property note in a note
+section, .note.gnu.property, to encode used x86 ISAs and features.  But
+kernel linker script only contains a single NOTE segment:
+
+PHDRS {
+ text PT_LOAD FLAGS(5);
+ data PT_LOAD FLAGS(6);
+ percpu PT_LOAD FLAGS(6);
+ init PT_LOAD FLAGS(7);
+ note PT_NOTE FLAGS(0);
+}
+SECTIONS
+{
+...
+ .notes : AT(ADDR(.notes) - 0xffffffff80000000) { __start_notes = .; KEEP(*(.not
+e.*)) __stop_notes = .; } :text :note
+...
+}
+
+The NOTE segment generated by kernel linker script is aligned to 4 bytes.
+But .note.gnu.property section must be aligned to 8 bytes on x86-64 and
+we get
+
+[hjl@gnu-skx-1 linux]$ readelf -n vmlinux
+
+Displaying notes found in: .notes
+  Owner                Data size Description
+  Xen                  0x00000006 Unknown note type: (0x00000006)
+   description data: 6c 69 6e 75 78 00
+  Xen                  0x00000004 Unknown note type: (0x00000007)
+   description data: 32 2e 36 00
+  xen-3.0              0x00000005 Unknown note type: (0x006e6558)
+   description data: 08 00 00 00 03
+readelf: Warning: note with invalid namesz and/or descsz found at offset 0x50
+readelf: Warning:  type: 0xffffffff, namesize: 0x006e6558, descsize:
+0x80000000, alignment: 8
+[hjl@gnu-skx-1 linux]$
+
+Since note.gnu.property section in kernel image is never used, this patch
+discards .note.gnu.property sections in kernel linker script by adding
+
+/DISCARD/ : {
+  *(.note.gnu.property)
+}
+
+before kernel NOTE segment in generic NOTES.
+
+Signed-off-by: H.J. Lu <hjl.tools@gmail.com>
+Reviewed-by: Kees Cook <keescook@chromium.org>
+---
+ include/asm-generic/vmlinux.lds.h | 7 +++++++
+ 1 file changed, 7 insertions(+)
+
+diff --git a/include/asm-generic/vmlinux.lds.h b/include/asm-generic/vmlinux.lds.h
+index 052e0f05a984..2a7034da4e12 100644
+--- a/include/asm-generic/vmlinux.lds.h
++++ b/include/asm-generic/vmlinux.lds.h
+@@ -846,7 +846,14 @@
+ #define TRACEDATA
+ #endif
+ 
++/*
++ * Discard .note.gnu.property sections which are unused and have
++ * different alignment requirement from kernel note sections.
++ */
+ #define NOTES								\
++	/DISCARD/ : {							\
++		*(.note.gnu.property)					\
++	}								\
+ 	.notes : AT(ADDR(.notes) - LOAD_OFFSET) {			\
+ 		__start_notes = .;					\
+ 		KEEP(*(.note.*))					\
+-- 
+2.26.2
+
diff --git a/0037-selftest-x86-Enable-CET-for-selftests-x86.patch b/0037-selftest-x86-Enable-CET-for-selftests-x86.patch
new file mode 100644
index 000000000..81d2934ab
--- /dev/null
+++ b/0037-selftest-x86-Enable-CET-for-selftests-x86.patch
@@ -0,0 +1,54 @@
+From fa88801777012bc0e5223ded8ac7a21a58c917ca Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 2 Oct 2018 10:38:38 -0700
+Subject: [PATCH 37/40] selftest/x86: Enable CET for selftests/x86
+
+To build a shadow stack-enabled application written in C language, only the
+latest linker (ld) is necessary for marking .note.gnu.property in the ELF
+header.  If a shadow stack-enabled application contains assembly code, the
+latest assembler is also needed.  It is possible to hard-code shadow stack
+instructions and build the application without assembler support.
+
+To build an indirect branch tracking application, the latest toolchain,
+including compiler, assembler, and linker, is needed.  This is because
+branch targets are evaluated and labeled by the compiler.
+
+Shadow stack and indirect branch tracking complement each other, and are
+most effective when both are enabled.  An updated toolchain can build both
+without additional efforts.  Update makefile to detect and enable CET build
+for x86 selftest.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v2:
+- Export CAN_BUILD_CET to source code.
+---
+ tools/testing/selftests/x86/Makefile | 5 +++++
+ 1 file changed, 5 insertions(+)
+
+diff --git a/tools/testing/selftests/x86/Makefile b/tools/testing/selftests/x86/Makefile
+index d2796ea98c5a..018518737e47 100644
+--- a/tools/testing/selftests/x86/Makefile
++++ b/tools/testing/selftests/x86/Makefile
+@@ -9,6 +9,7 @@ UNAME_M := $(shell uname -m)
+ CAN_BUILD_I386 := $(shell ./check_cc.sh $(CC) trivial_32bit_program.c -m32)
+ CAN_BUILD_X86_64 := $(shell ./check_cc.sh $(CC) trivial_64bit_program.c)
+ CAN_BUILD_WITH_NOPIE := $(shell ./check_cc.sh $(CC) trivial_program.c -no-pie)
++CAN_BUILD_CET := $(shell ./check_cc.sh $(CC) trivial_program.c -fcf-protection)
+ 
+ TARGETS_C_BOTHBITS := single_step_syscall sysret_ss_attrs syscall_nt test_mremap_vdso \
+ 			check_initial_reg_state sigreturn iopl ioperm \
+@@ -35,6 +36,10 @@ BINARIES_64 := $(patsubst %,$(OUTPUT)/%,$(BINARIES_64))
+ 
+ CFLAGS := -O2 -g -std=gnu99 -pthread -Wall
+ 
++ifeq ($(CAN_BUILD_CET),1)
++CFLAGS += -fcf-protection -mshstk -DCAN_BUILD_CET
++endif
++
+ # call32_from_64 in thunks.S uses absolute addresses.
+ ifeq ($(CAN_BUILD_WITH_NOPIE),1)
+ CFLAGS += -no-pie
+-- 
+2.26.2
+
diff --git a/0038-selftest-x86-Fix-sigreturn_64-test.patch b/0038-selftest-x86-Fix-sigreturn_64-test.patch
new file mode 100644
index 000000000..a7f891216
--- /dev/null
+++ b/0038-selftest-x86-Fix-sigreturn_64-test.patch
@@ -0,0 +1,93 @@
+From 32ea3682e2e778a2f49feb118d8bd735d0d2b613 Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Wed, 20 May 2020 10:47:47 -0700
+Subject: [PATCH 38/40] selftest/x86: Fix sigreturn_64 test.
+
+When shadow stack is enabled, x86/sigreturn_64 triggers a fault upon doing
+sigreturn to 32-bit context with a 64-bit shadow stack pointer.
+
+Fix it by:
+- Allocate a small shadow stack within 32-bit address range,
+- Switch to the new shadow stack,
+- Run tests,
+- Switch back to the original 64-bit shadow stack.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v2:
+- Test CAN_BUILD_CET before including shadow stack instructions.
+- Pull ARCH_X86_CET_ALLOC_SHSTK definition from the header file.
+- Add more comments.
+---
+ tools/testing/selftests/x86/sigreturn.c | 41 +++++++++++++++++++++++++
+ 1 file changed, 41 insertions(+)
+
+diff --git a/tools/testing/selftests/x86/sigreturn.c b/tools/testing/selftests/x86/sigreturn.c
+index 57c4f67f16ef..b6af4ecd2ca2 100644
+--- a/tools/testing/selftests/x86/sigreturn.c
++++ b/tools/testing/selftests/x86/sigreturn.c
+@@ -45,6 +45,12 @@
+ #include <stdbool.h>
+ #include <sys/ptrace.h>
+ #include <sys/user.h>
++#include <sys/mman.h>
++#include <x86intrin.h>
++
++/* Pull in ARCH_X86_CET_MMAP_SHSTK */
++#include "../../../../arch/x86/include/uapi/asm/prctl.h"
++int arch_prctl(int code, unsigned long *addr);
+ 
+ /* Pull in AR_xyz defines. */
+ typedef unsigned int u32;
+@@ -766,6 +772,31 @@ int main()
+ 	int total_nerrs = 0;
+ 	unsigned short my_cs, my_ss;
+ 
++#if defined(__x86_64__) && defined(CAN_BUILD_CET)
++	unsigned long arg[3], ssp_64, ssp_32;
++
++	ssp_64 = _get_ssp();
++
++	if (ssp_64 != 0) {
++		/* Alloc a shadow stack within 32-bit address range */
++		arg[0] = 0x0;
++		arg[1] = 0x1000;
++		arg[2] = MAP_32BIT;
++		if (arch_prctl(ARCH_X86_CET_MMAP_SHSTK, arg)) {
++			printf("[FAIL]\tCannot allocate shadow stack\n");
++			return 1;
++		}
++
++		/*
++		 * The top of shadow stack is an 8-byte token, point ssp_32
++		 * to the token.
++		 */
++		ssp_32 = arg[0] + 0x1000 - 8;
++		asm volatile("rstorssp (%0)\n":: "r" (ssp_32));
++		asm volatile("saveprevssp");
++	}
++#endif
++
+ 	asm volatile ("mov %%cs,%0" : "=r" (my_cs));
+ 	asm volatile ("mov %%ss,%0" : "=r" (my_ss));
+ 	setup_ldt();
+@@ -870,6 +901,16 @@ int main()
+ 
+ #ifdef __x86_64__
+ 	total_nerrs += test_nonstrict_ss();
++
++#ifdef CAN_BUILD_CET
++	if (ssp_64 != 0) {
++		/* Point ssp_64 to the restore token */
++		ssp_64 -= 8;
++		asm volatile("rstorssp (%0)\n":: "r" (ssp_64));
++		asm volatile("saveprevssp");
++		munmap((void *)arg[0], 0x1000);
++	}
++#endif
+ #endif
+ 
+ 	return total_nerrs ? 1 : 0;
+-- 
+2.26.2
+
diff --git a/0039-selftest-x86-Fix-sysret_rip-with-ENDBR.patch b/0039-selftest-x86-Fix-sysret_rip-with-ENDBR.patch
new file mode 100644
index 000000000..7ef45e87c
--- /dev/null
+++ b/0039-selftest-x86-Fix-sysret_rip-with-ENDBR.patch
@@ -0,0 +1,46 @@
+From ada51744e8de56435208092e8805303f65e5835c Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Tue, 2 Oct 2018 10:38:38 -0700
+Subject: [PATCH 39/40] selftest/x86: Fix sysret_rip with ENDBR
+
+When indirect branch tracking is enabled, an indirect near CALL/JMP,
+without the 'notrack' prefix, must land at an ENDBR instruction, otherwise
+a control-protection fault is triggered.
+
+The compiler inserts ENDBR's for C code, but assembly code must be updated
+manually.  Fix that for x86/sysret_rip.
+
+When CET is not enabled, ENDBR is a nop and has no effect.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+---
+ tools/testing/selftests/x86/sysret_rip.c | 5 +++--
+ 1 file changed, 3 insertions(+), 2 deletions(-)
+
+diff --git a/tools/testing/selftests/x86/sysret_rip.c b/tools/testing/selftests/x86/sysret_rip.c
+index 84d74be1d902..027682a0f377 100644
+--- a/tools/testing/selftests/x86/sysret_rip.c
++++ b/tools/testing/selftests/x86/sysret_rip.c
+@@ -27,8 +27,9 @@ asm (
+ 	".pushsection \".text\", \"ax\"\n\t"
+ 	".balign 4096\n\t"
+ 	"test_page: .globl test_page\n\t"
+-	".fill 4094,1,0xcc\n\t"
++	".fill 4090,1,0xcc\n\t"
+ 	"test_syscall_insn:\n\t"
++	"endbr64\n\t"
+ 	"syscall\n\t"
+ 	".ifne . - test_page - 4096\n\t"
+ 	".error \"test page is not one page long\"\n\t"
+@@ -151,7 +152,7 @@ static void test_syscall_fallthrough_to(unsigned long ip)
+ 
+ 	if (sigsetjmp(jmpbuf, 1) == 0) {
+ 		asm volatile ("call *%[syscall_insn]" :: "a" (SYS_getpid),
+-			      [syscall_insn] "rm" (ip - 2));
++			      [syscall_insn] "rm" (ip - 6));
+ 		errx(1, "[FAIL]\tSyscall trampoline returned");
+ 	}
+ 
+-- 
+2.26.2
+
diff --git a/0040-selftest-x86-Add-CET-quick-test.patch b/0040-selftest-x86-Add-CET-quick-test.patch
new file mode 100644
index 000000000..63a312b11
--- /dev/null
+++ b/0040-selftest-x86-Add-CET-quick-test.patch
@@ -0,0 +1,191 @@
+From d01814c5f0810f6bba256a8f10636ea487469c6e Mon Sep 17 00:00:00 2001
+From: Yu-cheng Yu <yu-cheng.yu@intel.com>
+Date: Wed, 20 May 2020 15:38:29 -0700
+Subject: [PATCH 40/40] selftest/x86: Add CET quick test
+
+Introduce a quick test to verify shadow stack and IBT are working.
+
+Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
+
+v2:
+- Rewrite assembly code and remove compiler conditionals.
+- Update return code to include 'not_tested'.
+- Verify in segv_handler the fault is a control-protection fault, otherwise
+  exit the test.
+- Use only one user signal SIGUSR1.
+---
+ tools/testing/selftests/x86/Makefile         |   2 +-
+ tools/testing/selftests/x86/cet_quick_test.c | 148 +++++++++++++++++++
+ 2 files changed, 149 insertions(+), 1 deletion(-)
+ create mode 100644 tools/testing/selftests/x86/cet_quick_test.c
+
+diff --git a/tools/testing/selftests/x86/Makefile b/tools/testing/selftests/x86/Makefile
+index 018518737e47..61f1639f3ab0 100644
+--- a/tools/testing/selftests/x86/Makefile
++++ b/tools/testing/selftests/x86/Makefile
+@@ -14,7 +14,7 @@ CAN_BUILD_CET := $(shell ./check_cc.sh $(CC) trivial_program.c -fcf-protection)
+ TARGETS_C_BOTHBITS := single_step_syscall sysret_ss_attrs syscall_nt test_mremap_vdso \
+ 			check_initial_reg_state sigreturn iopl ioperm \
+ 			test_vdso test_vsyscall mov_ss_trap \
+-			syscall_arg_fault
++			syscall_arg_fault cet_quick_test
+ TARGETS_C_32BIT_ONLY := entry_from_vm86 test_syscall_vdso unwind_vdso \
+ 			test_FCMOV test_FCOMI test_FISTTP \
+ 			vdso_restorer
+diff --git a/tools/testing/selftests/x86/cet_quick_test.c b/tools/testing/selftests/x86/cet_quick_test.c
+new file mode 100644
+index 000000000000..8480cf303a3b
+--- /dev/null
++++ b/tools/testing/selftests/x86/cet_quick_test.c
+@@ -0,0 +1,148 @@
++// SPDX-License-Identifier: GPL-2.0-only
++/* Quick tests to verify Shadow Stack and IBT are working */
++
++#include <stdio.h>
++#include <stdlib.h>
++#include <signal.h>
++#include <string.h>
++#include <ucontext.h>
++
++ucontext_t ucp;
++
++enum {
++	r_not_tested = -1,
++	r_fail = 0,
++	r_ok = 1,
++};
++
++int result[4] = {r_not_tested, r_not_tested, r_not_tested, r_not_tested};
++int test_id;
++
++/* Defined in include/uapi/asm-generic/siginfo.h */
++#define SEGV_CPERR 8
++
++/*
++ * Do an indirect jmp to a location without endbr to trigger a control
++ * protection fault.  Verify in segv_handler that ibt is working.
++ */
++void ibt_violation(void)
++{
++	void *ptr;
++
++	asm volatile("lea 1f, %0\n\t"
++		     "jmp *%0\n\t"
++		     "1:" : "=r"(ptr));
++
++	result[test_id] = r_fail;
++	test_id++;
++	setcontext(&ucp);
++}
++
++/*
++ * Do a push and ret to cause shadow stack mismatch and trigger a control
++ * protection fault.  Verify in segv_handler that shadow stack is working.
++ */
++void shstk_violation(void)
++{
++	void *ptr;
++
++	asm volatile("lea 1f, %0\n\t"
++		     "push %0\n\t"
++		     "ret\n\t"
++		     "1:" : "=r"(ptr));
++
++	result[test_id] = r_fail;
++	test_id++;
++	setcontext(&ucp);
++}
++
++void segv_handler(int signum, siginfo_t *si, void *uc)
++{
++	if (si->si_code == SEGV_CPERR) {
++		result[test_id] = r_ok;
++		test_id++;
++	} else {
++		printf("Unexpected seg fault\n");
++		exit(1);
++	}
++
++	setcontext(&ucp);
++}
++
++/*
++ * Verify shadow stack and ibt are working in a signal handler.
++ */
++void user1_handler(int signum, siginfo_t *si, void *uc)
++{
++	if (test_id == 2)
++		shstk_violation();
++
++	if (test_id == 3)
++		ibt_violation();
++}
++
++int main(int argc, char *argv[])
++{
++	struct sigaction sa;
++	int r;
++
++	r = sigemptyset(&sa.sa_mask);
++	if (r)
++		return -1;
++
++	sa.sa_flags = SA_SIGINFO;
++
++	/*
++	 * Control protection fault handler
++	 */
++	sa.sa_sigaction = segv_handler;
++	r = sigaction(SIGSEGV, &sa, NULL);
++	if (r)
++		return -1;
++
++	/*
++	 * Test shadow stack/ibt in signal handler
++	 */
++	sa.sa_sigaction = user1_handler;
++	r = sigaction(SIGUSR1, &sa, NULL);
++	if (r)
++		return -1;
++
++	test_id = 0;
++
++	/*
++	 * Pass or fail, each test returns here with test_id incremented to
++	 * the next test.
++	 */
++	r = getcontext(&ucp);
++	if (r)
++		return -1;
++
++	if (test_id == 0)
++		shstk_violation();
++	else if (test_id == 1)
++		ibt_violation();
++	else if (test_id == 2)
++		raise(SIGUSR1);
++	else if (test_id == 3)
++		raise(SIGUSR1);
++
++	r = 0;
++	printf("[%s]\tShadow stack\n", result[0] == -1 ? "untested" :
++	       (result[0] ? "OK" : "FAIL"));
++	r += result[0];
++
++	printf("[%s]\tIBT\n", result[1] == -1 ? "untested" :
++	       (result[1] ? "OK" : "FAIL"));
++	r += result[1];
++
++	printf("[%s]\tShadow stack in signal\n", result[2] == -1 ? "untested" :
++	       (result[2] ? "OK" : "FAIL"));
++	r += result[2];
++
++	printf("[%s]\tIBT in signal\n", result[3] == -1 ? "untested" :
++	       (result[3] ? "OK" : "FAIL"));
++	r += result[3];
++
++	return r;
++}
+-- 
+2.26.2
+
diff --git a/kernel.spec b/kernel.spec
index 303b5820b..2dca0e2c0 100644
--- a/kernel.spec
+++ b/kernel.spec
@@ -1,3 +1,44 @@
+Patch200001: 0001-Documentation-x86-Add-CET-description.patch
+Patch200002: 0002-x86-cpufeatures-Add-CET-CPU-feature-flags-for-Contro.patch
+Patch200003: 0003-x86-fpu-xstate-Introduce-CET-MSR-XSAVES-supervisor-s.patch
+Patch200004: 0004-x86-cet-Add-control-protection-fault-handler.patch
+Patch200005: 0005-x86-cet-shstk-Add-Kconfig-option-for-user-mode-Shado.patch
+Patch200006: 0006-x86-mm-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_HW.patch
+Patch200007: 0007-x86-mm-Remove-_PAGE_DIRTY_HW-from-kernel-RO-pages.patch
+Patch200008: 0008-x86-mm-Introduce-_PAGE_COW.patch
+Patch200009: 0009-drm-i915-gvt-Change-_PAGE_DIRTY-to-_PAGE_DIRTY_BITS.patch
+Patch200010: 0010-x86-mm-Update-pte_modify-for-_PAGE_COW.patch
+Patch200011: 0011-x86-mm-Update-ptep_set_wrprotect-and-pmdp_set_wrprot.patch
+Patch200012: 0012-mm-Introduce-VM_SHSTK-for-shadow-stack-memory.patch
+Patch200013: 0013-x86-mm-Shadow-Stack-page-fault-error-checking.patch
+Patch200014: 0014-x86-mm-Update-maybe_mkwrite-for-shadow-stack.patch
+Patch200015: 0015-mm-Fixup-places-that-call-pte_mkwrite-directly.patch
+Patch200016: 0016-mm-Add-guard-pages-around-a-shadow-stack.patch
+Patch200017: 0017-mm-mmap-Add-shadow-stack-pages-to-memory-accounting.patch
+Patch200018: 0018-mm-Update-can_follow_write_pte-for-shadow-stack.patch
+Patch200019: 0019-x86-cet-shstk-User-mode-shadow-stack-support.patch
+Patch200020: 0020-x86-cet-shstk-Handle-signals-for-shadow-stack.patch
+Patch200021: 0021-binfmt_elf-Define-GNU_PROPERTY_X86_FEATURE_1_AND-pro.patch
+Patch200022: 0022-ELF-Introduce-arch_setup_elf_property.patch
+Patch200023: 0023-x86-cet-shstk-ELF-header-parsing-for-shadow-stack.patch
+Patch200024: 0024-x86-cet-shstk-Handle-thread-shadow-stack.patch
+Patch200025: 0025-x86-cet-shstk-Add-arch_prctl-functions-for-shadow-st.patch
+Patch200026: 0026-x86-cet-ibt-Add-Kconfig-option-for-user-mode-Indirec.patch
+Patch200027: 0027-x86-cet-ibt-User-mode-Indirect-Branch-Tracking-suppo.patch
+Patch200028: 0028-x86-cet-ibt-Handle-signals-for-Indirect-Branch-Track.patch
+Patch200029: 0029-x86-cet-ibt-ELF-header-parsing-for-Indirect-Branch-T.patch
+Patch200030: 0030-x86-cet-ibt-Add-arch_prctl-functions-for-Indirect-Br.patch
+Patch200031: 0031-x86-cet-Add-PTRACE-interface-for-CET.patch
+Patch200032: 0032-x86-vdso-32-Add-ENDBR32-to-__kernel_vsyscall-entry-p.patch
+Patch200033: 0033-x86-vdso-Insert-endbr32-endbr64-to-vDSO.patch
+Patch200034: 0034-x86-Disallow-vsyscall-emulation-when-CET-is-enabled.patch
+Patch200035: 0035-powerpc-Keep-.rela-sections-when-CONFIG_RELOCATABLE-.patch
+Patch200036: 0036-Discard-.note.gnu.property-sections-in-generic-NOTES.patch
+Patch200037: 0037-selftest-x86-Enable-CET-for-selftests-x86.patch
+Patch200038: 0038-selftest-x86-Fix-sigreturn_64-test.patch
+Patch200039: 0039-selftest-x86-Fix-sysret_rip-with-ENDBR.patch
+Patch200040: 0040-selftest-x86-Add-CET-quick-test.patch
+
 # We have to override the new %%install behavior because, well... the kernel is special.
 %global __spec_install_pre %{___build_pre}
 
-- 
2.26.2

