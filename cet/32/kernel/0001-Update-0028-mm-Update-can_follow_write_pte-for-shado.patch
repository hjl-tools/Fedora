From bf3a97d7fc2930bc206d60000ff9cfa5048cdf0e Mon Sep 17 00:00:00 2001
From: "H.J. Lu" <hjl.tools@gmail.com>
Date: Wed, 17 Jun 2020 10:16:37 -0700
Subject: [PATCH] Update
 0028-mm-Update-can_follow_write_pte-for-shadow-stack.patch for 5.7.3

---
 ...an_follow_write_pte-for-shadow-stack.patch | 46 +++++++++----------
 1 file changed, 23 insertions(+), 23 deletions(-)

diff --git a/0028-mm-Update-can_follow_write_pte-for-shadow-stack.patch b/0028-mm-Update-can_follow_write_pte-for-shadow-stack.patch
index 2f7ac3742..bd9701684 100644
--- a/0028-mm-Update-can_follow_write_pte-for-shadow-stack.patch
+++ b/0028-mm-Update-can_follow_write_pte-for-shadow-stack.patch
@@ -1,4 +1,4 @@
-From 3b9f89fdc05ebb1861d163cb52c7d7a9c21a2055 Mon Sep 17 00:00:00 2001
+From f14edafa82c18e1a36777ce096007a08cbc15c02 Mon Sep 17 00:00:00 2001
 From: Yu-cheng Yu <yu-cheng.yu@intel.com>
 Date: Tue, 3 Jul 2018 13:07:12 -0700
 Subject: [PATCH 28/47] mm: Update can_follow_write_pte() for shadow stack
@@ -17,30 +17,30 @@ Signed-off-by: Yu-cheng Yu <yu-cheng.yu@intel.com>
 v10:
 - Reverse name changes to can_follow_write_*().
 ---
- mm/gup.c         | 8 +++++---
- mm/huge_memory.c | 8 +++++---
- 2 files changed, 10 insertions(+), 6 deletions(-)
+ mm/gup.c         | 9 ++++++---
+ mm/huge_memory.c | 9 ++++++---
+ 2 files changed, 12 insertions(+), 6 deletions(-)
 
 diff --git a/mm/gup.c b/mm/gup.c
-index 87a6a59fe667..304366ba141e 100644
+index 43cce23aea89..501f3ecac306 100644
 --- a/mm/gup.c
 +++ b/mm/gup.c
-@@ -385,10 +385,12 @@ static int follow_pfn_pte(struct vm_area_struct *vma, unsigned long address,
-  * FOLL_FORCE can write to even unwritable pte's, but only
-  * after we've gone through a COW cycle and they are dirty.
+@@ -385,9 +385,12 @@ static int follow_pfn_pte(struct vm_area_struct *vma, unsigned long address,
+  * FOLL_FORCE or a forced COW break can write even to unwritable pte's,
+  * but only after we've gone through a COW cycle and they are dirty.
   */
 -static inline bool can_follow_write_pte(pte_t pte, unsigned int flags)
 +static inline bool can_follow_write_pte(pte_t pte, unsigned int flags,
 +					struct vm_area_struct *vma)
  {
- 	return pte_write(pte) ||
--		((flags & FOLL_FORCE) && (flags & FOLL_COW) && pte_dirty(pte));
-+		((flags & FOLL_FORCE) && (flags & FOLL_COW) &&
-+		 !arch_shadow_stack_mapping(vma->vm_flags) && pte_dirty(pte));
+-	return pte_write(pte) || ((flags & FOLL_COW) && pte_dirty(pte));
++	return pte_write(pte) || ((flags & FOLL_COW) &&
++				  !arch_shadow_stack_mapping(vma->vm_flags) &&
++				  pte_dirty(pte));
  }
  
- static struct page *follow_page_pte(struct vm_area_struct *vma,
-@@ -431,7 +433,7 @@ static struct page *follow_page_pte(struct vm_area_struct *vma,
+ /*
+@@ -440,7 +443,7 @@ static struct page *follow_page_pte(struct vm_area_struct *vma,
  	}
  	if ((flags & FOLL_NUMA) && pte_protnone(pte))
  		goto no_page;
@@ -50,25 +50,25 @@ index 87a6a59fe667..304366ba141e 100644
  		return NULL;
  	}
 diff --git a/mm/huge_memory.c b/mm/huge_memory.c
-index 608746bb9d19..cb1b0cb4b4eb 100644
+index 8e5148e138d1..bc93ad0448e9 100644
 --- a/mm/huge_memory.c
 +++ b/mm/huge_memory.c
-@@ -1520,10 +1520,12 @@ vm_fault_t do_huge_pmd_wp_page(struct vm_fault *vmf, pmd_t orig_pmd)
-  * FOLL_FORCE can write to even unwritable pmd's, but only
-  * after we've gone through a COW cycle and they are dirty.
+@@ -1520,9 +1520,12 @@ vm_fault_t do_huge_pmd_wp_page(struct vm_fault *vmf, pmd_t orig_pmd)
+  * FOLL_FORCE or a forced COW break can write even to unwritable pmd's,
+  * but only after we've gone through a COW cycle and they are dirty.
   */
 -static inline bool can_follow_write_pmd(pmd_t pmd, unsigned int flags)
 +static inline bool can_follow_write_pmd(pmd_t pmd, unsigned int flags,
 +					struct vm_area_struct *vma)
  {
- 	return pmd_write(pmd) ||
--	       ((flags & FOLL_FORCE) && (flags & FOLL_COW) && pmd_dirty(pmd));
-+	       ((flags & FOLL_FORCE) && (flags & FOLL_COW) &&
-+		!arch_shadow_stack_mapping(vma->vm_flags) && pmd_dirty(pmd));
+-	return pmd_write(pmd) || ((flags & FOLL_COW) && pmd_dirty(pmd));
++	return pmd_write(pmd) || ((flags & FOLL_COW) &&
++				  !arch_shadow_stack_mapping(vma->vm_flags) &&
++				  pmd_dirty(pmd));
  }
  
  struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,
-@@ -1536,7 +1538,7 @@ struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,
+@@ -1535,7 +1538,7 @@ struct page *follow_trans_huge_pmd(struct vm_area_struct *vma,
  
  	assert_spin_locked(pmd_lockptr(mm, pmd));
  
-- 
2.26.2

