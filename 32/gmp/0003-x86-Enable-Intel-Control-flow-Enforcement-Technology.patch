From bf5ae35e98ad14f2121058f9a138eb55c33ab818 Mon Sep 17 00:00:00 2001
From: "H.J. Lu" <hjl.tools@gmail.com>
Date: Thu, 30 Jan 2020 06:46:20 -0800
Subject: [PATCH 3/4] x86: Enable Intel Control-flow Enforcement Technology
 (CET)

---
 ...P_ASM_X86_CET_MACROS-to-acinclude.m4.patch |  148 ++
 ...4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch |   41 +
 ...6-ppend-missing-ASM_END-to-asm-files.patch | 1038 +++++++++++++
 ...4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch |   39 +
 ..._64-Append-ASM_END-to-assembly-codes.patch | 1368 +++++++++++++++++
 ...unt.asm-Prepend-X86_NOTRACK-to-jmp-r.patch |   41 +
 ...X86_ENDBR-to-indirect-branch-targets.patch |  851 ++++++++++
 ...dd-X86_ENDBR-to-indirect-jump-target.patch |  130 ++
 ...86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch |   90 ++
 ...86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch |   60 +
 ...end-X86_NOTRACK-to-indirect-branches.patch |   90 ++
 gmp.spec                                      |   12 +
 12 files changed, 3908 insertions(+)
 create mode 100644 0001-x86-Add-GMP_ASM_X86_CET_MACROS-to-acinclude.m4.patch
 create mode 100644 0002-x86-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
 create mode 100644 0003-x86-ppend-missing-ASM_END-to-asm-files.patch
 create mode 100644 0004-x86_64-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
 create mode 100644 0005-x86_64-Append-ASM_END-to-assembly-codes.patch
 create mode 100644 0006-x86_64-k10-popcount.asm-Prepend-X86_NOTRACK-to-jmp-r.patch
 create mode 100644 0007-mpn-x86_64-Add-X86_ENDBR-to-indirect-branch-targets.patch
 create mode 100644 0008-x86-aors_n.asm-Add-X86_ENDBR-to-indirect-jump-target.patch
 create mode 100644 0009-x86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch
 create mode 100644 0010-x86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch
 create mode 100644 0011-x86-k7-Prepend-X86_NOTRACK-to-indirect-branches.patch

diff --git a/0001-x86-Add-GMP_ASM_X86_CET_MACROS-to-acinclude.m4.patch b/0001-x86-Add-GMP_ASM_X86_CET_MACROS-to-acinclude.m4.patch
new file mode 100644
index 0000000..2526cd6
--- /dev/null
+++ b/0001-x86-Add-GMP_ASM_X86_CET_MACROS-to-acinclude.m4.patch
@@ -0,0 +1,148 @@
+From a304904f3f05d430fbbe2b61344fd8e245c4c350 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Tue, 28 Jan 2020 14:55:55 -0800
+Subject: [PATCH 01/11] x86: Add GMP_ASM_X86_CET_MACROS to acinclude.m4
+
+Add GMP_ASM_X86_CET_MACROS to acinclude.m4 to define
+
+1. X86_ENDBR.  Defined as endbr32/endbr64 if CET is enabled.
+2. X86_NOTRACK.  Defined as notrack prefix if CET is enabled.
+3. X86_GNU_PROPERTY.  Add a .note.gnu.property section to mark Intel
+CET support if needed.
+
+and use it in configure.ac.
+
+	* acinclude.m4 (GMP_ASM_X86_CET_MACROS): New.
+	* configure.ac: Use GMP_ASM_X86_CET_MACROS for x86 targets.
+---
+ acinclude.m4 | 101 +++++++++++++++++++++++++++++++++++++++++++++++++++
+ configure.ac |   1 +
+ 2 files changed, 102 insertions(+)
+
+diff --git a/acinclude.m4 b/acinclude.m4
+index 3c3ecf528..856953345 100644
+--- a/acinclude.m4
++++ b/acinclude.m4
+@@ -3173,6 +3173,107 @@ GMP_DEFINE_RAW(["define(<HAVE_SHARED_THUNKS>,<$gmp_cv_asm_sparc_shared_thunks>)"
+ ])
+ 
+ 
++dnl  GMP_ASM_X86_CET_MACROS(ABI)
++dnl  ------------
++dnl  Define
++dnl  1. X86_ENDBR for endbr32/endbr64.
++dnl  2. X86_NOTRACK for notrack prefix.
++dnl  3. X86_GNU_PROPERTY to add a .note.gnu.property section to mark
++dnl  Intel CET support if needed.
++dnl	.section ".note.gnu.property", "a"
++dnl	.p2align POINTER-ALIGN
++dnl	.long 1f - 0f
++dnl	.long 4f - 1f
++dnl	.long 5
++dnl 0:
++dnl	.asciz "GNU"
++dnl 1:
++dnl	.p2align POINTER-ALIGN
++dnl	.long 0xc0000002
++dnl	.long 3f - 2f
++dnl 2:
++dnl	.long 3
++dnl 3:
++dnl	.p2align POINTER-ALIGN
++dnl 4:
++AC_DEFUN([GMP_ASM_X86_CET_MACROS],[
++dnl AC_REQUIRE([AC_PROG_CC]) GMP uses something else
++AC_CACHE_CHECK([if Intel CET is enabled],
++  gmp_cv_asm_x86_intel_cet, [dnl
++  cat > conftest.c <<EOF
++#ifndef __CET__
++#error Intel CET is not enabled
++#endif
++EOF
++  if AC_TRY_COMMAND([${CC} $CFLAGS $CPPFLAGS
++                     -S -o conftest.s conftest.c >/dev/null])
++  then
++    gmp_cv_asm_x86_intel_cet=yes
++  else
++    gmp_cv_asm_x86_intel_cet=no
++  fi
++  rm -f conftest*])
++  if test "$gmp_cv_asm_x86_intel_cet" = yes; then
++    case $1 in
++    32)
++      endbr=endbr32
++      p2align=2
++      ;;
++    64)
++      endbr=endbr64
++      p2align=3
++      ;;
++    x32)
++      endbr=endbr64
++      p2align=2
++      ;;
++    esac
++    AC_CACHE_CHECK([if .note.gnu.property section is needed],
++      gmp_cv_asm_x86_gnu_property, [dnl
++      cat > conftest.c <<EOF
++#if !defined __ELF__ || !defined __CET__
++#error GNU property is not needed
++#endif
++EOF
++      if AC_TRY_COMMAND([${CC} $CFLAGS $CPPFLAGS
++			-S -o conftest.s conftest.c >/dev/null])
++      then
++	gmp_cv_asm_x86_gnu_property=yes
++      else
++	gmp_cv_asm_x86_gnu_property=no
++      fi
++      rm -f conftest*])
++    echo ["define(<X86_ENDBR>,<$endbr>)"] >> $gmp_tmpconfigm4
++    echo ["define(<X86_NOTRACK>,<notrack>)"] >> $gmp_tmpconfigm4
++  else
++    gmp_cv_asm_x86_gnu_property=no
++    echo ["define(<X86_ENDBR>,<>)"] >> $gmp_tmpconfigm4
++    echo ["define(<X86_NOTRACK>,<>)"] >> $gmp_tmpconfigm4
++  fi
++  if test "$gmp_cv_asm_x86_gnu_property" = yes; then
++    echo ["define(<X86_GNU_PROPERTY>, <
++	.section \".note.gnu.property\", \"a\"
++	.p2align $p2align
++	.long 1f - 0f
++	.long 4f - 1f
++	.long 5
++0:
++	.asciz \"GNU\"
++1:
++	.p2align $p2align
++	.long 0xc0000002
++	.long 3f - 2f
++2:
++	.long 3
++3:
++	.p2align $p2align
++4:>)"] >> $gmp_tmpconfigm4
++  else
++    echo ["define(<X86_GNU_PROPERTY>,<>)"] >> $gmp_tmpconfigm4
++  fi
++])
++
++
+ dnl  GMP_C_ATTRIBUTE_CONST
+ dnl  ---------------------
+ 
+diff --git a/configure.ac b/configure.ac
+index c35d9f7ed..55dc050a9 100644
+--- a/configure.ac
++++ b/configure.ac
+@@ -3708,6 +3708,7 @@ yes
+ 	  esac
+           ;;
+       esac
++      GMP_ASM_X86_CET_MACROS($ABI)
+       ;;
+   esac
+ fi
+-- 
+2.24.1
+
diff --git a/0002-x86-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch b/0002-x86-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
new file mode 100644
index 0000000..2e3bb76
--- /dev/null
+++ b/0002-x86-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
@@ -0,0 +1,41 @@
+From 06cf8e43b7774a2b3cda91d67efd0fdaa64edb24 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Tue, 28 Jan 2020 15:03:59 -0800
+Subject: [PATCH 02/11] x86-defs.m4: Use X86_GNU_PROPERTY and X86_ENDBR
+
+1. Add X86_ENDBR to PROLOGUE_cpu to place "endbr32" at function entry.
+2. Add X86_GNU_PROPERTY to ASM_END for .note.gnu.property section.
+
+	* mpn/x86/x86-defs.m4 (PROLOGUE_cpu): Add X86_ENDBR.
+	(ASM_END): Add X86_GNU_PROPERTY.
+---
+ mpn/x86/x86-defs.m4 | 6 +++++-
+ 1 file changed, 5 insertions(+), 1 deletion(-)
+
+diff --git a/mpn/x86/x86-defs.m4 b/mpn/x86/x86-defs.m4
+index 56dfa03e6..78595d5de 100644
+--- a/mpn/x86/x86-defs.m4
++++ b/mpn/x86/x86-defs.m4
+@@ -123,6 +123,7 @@ m4_assert_defined(`WANT_PROFILING')
+ 	TYPE($1,`function')
+ 	COFF_TYPE($1)
+ $1:
++	X86_ENDBR
+ ifelse(WANT_PROFILING,`prof',      `	call_mcount')
+ ifelse(WANT_PROFILING,`gprof',     `	call_mcount')
+ ifelse(WANT_PROFILING,`instrument',`	call_instrument(enter)')
+@@ -992,7 +993,10 @@ L(movl_eip_`'substr($2,1)):
+ 
+ dnl ASM_END
+ 
+-define(`ASM_END',`load_eip')
++define(`ASM_END',
++`load_eip
++X86_GNU_PROPERTY
++')
+ 
+ define(`load_eip', `')		dnl updated in LEA/LEAL
+ 
+-- 
+2.24.1
+
diff --git a/0003-x86-ppend-missing-ASM_END-to-asm-files.patch b/0003-x86-ppend-missing-ASM_END-to-asm-files.patch
new file mode 100644
index 0000000..2b9eba8
--- /dev/null
+++ b/0003-x86-ppend-missing-ASM_END-to-asm-files.patch
@@ -0,0 +1,1038 @@
+From 406bdc750cb3f141d918c7d8af85fd75fe405dcd Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:26:22 -0800
+Subject: [PATCH 03/11] x86: ppend missing ASM_END to asm files
+
+Append missing ASM_END to x86 asm files to generate .note.gnu.property
+section.
+
+	* mpn/x86/aors_n.asm: Append ASM_END.
+	* mpn/x86/aorsmul_1.asm: Likewise.
+	* mpn/x86/atom/sse2/aorsmul_1.asm: Likewise.
+	* mpn/x86/atom/sse2/mul_basecase.asm: Likewise.
+	* mpn/x86/atom/sse2/sqr_basecase.asm: Likewise.
+	* mpn/x86/bdiv_dbm1c.asm: Likewise.
+	* mpn/x86/copyd.asm: Likewise.
+	* mpn/x86/copyi.asm: Likewise.
+	* mpn/x86/divrem_1.asm: Likewise.
+	* mpn/x86/divrem_2.asm: Likewise.
+	* mpn/x86/k6/aors_n.asm: Likewise.
+	* mpn/x86/k6/aorsmul_1.asm: Likewise.
+	* mpn/x86/k6/divrem_1.asm: Likewise.
+	* mpn/x86/k6/gcd_1.asm: Likewise.
+	* mpn/x86/k6/k62mmx/copyd.asm: Likewise.
+	* mpn/x86/k6/k62mmx/lshift.asm: Likewise.
+	* mpn/x86/k6/k62mmx/rshift.asm: Likewise.
+	* mpn/x86/k6/mmx/com.asm: Likewise.
+	* mpn/x86/k6/mmx/logops_n.asm: Likewise.
+	* mpn/x86/k6/mmx/lshift.asm: Likewise.
+	* mpn/x86/k6/mmx/popham.asm: Likewise.
+	* mpn/x86/k6/mmx/rshift.asm: Likewise.
+	* mpn/x86/k6/mod_34lsub1.asm: Likewise.
+	* mpn/x86/k6/mul_1.asm: Likewise.
+	* mpn/x86/k6/mul_basecase.asm: Likewise.
+	* mpn/x86/k6/pre_mod_1.asm: Likewise.
+	* mpn/x86/k6/sqr_basecase.asm: Likewise.
+	* mpn/x86/k7/aors_n.asm: Likewise.
+	* mpn/x86/k7/mmx/com.asm: Likewise.
+	* mpn/x86/k7/mmx/copyd.asm: Likewise.
+	* mpn/x86/k7/mmx/copyi.asm: Likewise.
+	* mpn/x86/k7/mmx/divrem_1.asm: Likewise.
+	* mpn/x86/k7/mmx/lshift.asm: Likewise.
+	* mpn/x86/k7/mmx/popham.asm: Likewise.
+	* mpn/x86/k7/mmx/rshift.asm: Likewise.
+	* mpn/x86/k7/mod_1_1.asm: Likewise.
+	* mpn/x86/k7/mod_1_4.asm: Likewise.
+	* mpn/x86/k7/mod_34lsub1.asm: Likewise.
+	* mpn/x86/k7/mul_basecase.asm: Likewise.
+	* mpn/x86/k7/sqr_basecase.asm: Likewise.
+	* mpn/x86/lshift.asm: Likewise.
+	* mpn/x86/mmx/sec_tabselect.asm: Likewise.
+	* mpn/x86/mod_34lsub1.asm: Likewise.
+	* mpn/x86/mul_1.asm: Likewise.
+	* mpn/x86/mul_basecase.asm: Likewise.
+	* mpn/x86/p6/aors_n.asm: Likewise.
+	* mpn/x86/p6/aorsmul_1.asm: Likewise.
+	* mpn/x86/p6/copyd.asm: Likewise.
+	* mpn/x86/p6/gcd_1.asm: Likewise.
+	* mpn/x86/p6/lshsub_n.asm: Likewise.
+	* mpn/x86/p6/mmx/divrem_1.asm: Likewise.
+	* mpn/x86/p6/mod_34lsub1.asm: Likewise.
+	* mpn/x86/p6/mul_basecase.asm: Likewise.
+	* mpn/x86/p6/sqr_basecase.asm: Likewise.
+	* mpn/x86/pentium/aors_n.asm: Likewise.
+	* mpn/x86/pentium/aorsmul_1.asm: Likewise.
+	* mpn/x86/pentium/com.asm: Likewise.
+	* mpn/x86/pentium/copyd.asm: Likewise.
+	* mpn/x86/pentium/copyi.asm: Likewise.
+	* mpn/x86/pentium/logops_n.asm: Likewise.
+	* mpn/x86/pentium/lshift.asm: Likewise.
+	* mpn/x86/pentium/mmx/lshift.asm: Likewise.
+	* mpn/x86/pentium/mmx/mul_1.asm: Likewise.
+	* mpn/x86/pentium/mmx/rshift.asm: Likewise.
+	* mpn/x86/pentium/mod_34lsub1.asm: Likewise.
+	* mpn/x86/pentium/mul_1.asm: Likewise.
+	* mpn/x86/pentium/mul_2.asm: Likewise.
+	* mpn/x86/pentium/mul_basecase.asm: Likewise.
+	* mpn/x86/pentium/rshift.asm: Likewise.
+	* mpn/x86/pentium/sqr_basecase.asm: Likewise.
+	* mpn/x86/pentium4/copyd.asm: Likewise.
+	* mpn/x86/pentium4/copyi.asm: Likewise.
+	* mpn/x86/pentium4/mmx/popham.asm: Likewise.
+	* mpn/x86/pentium4/sse2/add_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/addlsh1_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/addmul_1.asm: Likewise.
+	* mpn/x86/pentium4/sse2/cnd_add_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/cnd_sub_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/divrem_1.asm: Likewise.
+	* mpn/x86/pentium4/sse2/mod_1_1.asm: Likewise.
+	* mpn/x86/pentium4/sse2/mod_1_4.asm: Likewise.
+	* mpn/x86/pentium4/sse2/mod_34lsub1.asm: Likewise.
+	* mpn/x86/pentium4/sse2/mul_1.asm: Likewise.
+	* mpn/x86/pentium4/sse2/mul_basecase.asm: Likewise.
+	* mpn/x86/pentium4/sse2/rsh1add_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/sqr_basecase.asm: Likewise.
+	* mpn/x86/pentium4/sse2/sub_n.asm: Likewise.
+	* mpn/x86/pentium4/sse2/submul_1.asm: Likewise.
+	* mpn/x86/rshift.asm: Likewise.
+	* mpn/x86/sec_tabselect.asm: Likewise.
+	* mpn/x86/sqr_basecase.asm: Likewise.
+	* mpn/x86/udiv.asm: Likewise.
+	* mpn/x86/umul.asm: Likewise.
+---
+ mpn/x86/aors_n.asm                     | 1 +
+ mpn/x86/aorsmul_1.asm                  | 1 +
+ mpn/x86/atom/sse2/aorsmul_1.asm        | 1 +
+ mpn/x86/atom/sse2/mul_basecase.asm     | 1 +
+ mpn/x86/atom/sse2/sqr_basecase.asm     | 1 +
+ mpn/x86/bdiv_dbm1c.asm                 | 1 +
+ mpn/x86/copyd.asm                      | 1 +
+ mpn/x86/copyi.asm                      | 1 +
+ mpn/x86/divrem_1.asm                   | 1 +
+ mpn/x86/divrem_2.asm                   | 1 +
+ mpn/x86/k6/aors_n.asm                  | 1 +
+ mpn/x86/k6/aorsmul_1.asm               | 1 +
+ mpn/x86/k6/divrem_1.asm                | 1 +
+ mpn/x86/k6/gcd_1.asm                   | 1 +
+ mpn/x86/k6/k62mmx/copyd.asm            | 1 +
+ mpn/x86/k6/k62mmx/lshift.asm           | 1 +
+ mpn/x86/k6/k62mmx/rshift.asm           | 1 +
+ mpn/x86/k6/mmx/com.asm                 | 1 +
+ mpn/x86/k6/mmx/logops_n.asm            | 1 +
+ mpn/x86/k6/mmx/lshift.asm              | 1 +
+ mpn/x86/k6/mmx/popham.asm              | 1 +
+ mpn/x86/k6/mmx/rshift.asm              | 1 +
+ mpn/x86/k6/mod_34lsub1.asm             | 1 +
+ mpn/x86/k6/mul_1.asm                   | 1 +
+ mpn/x86/k6/mul_basecase.asm            | 1 +
+ mpn/x86/k6/pre_mod_1.asm               | 1 +
+ mpn/x86/k6/sqr_basecase.asm            | 1 +
+ mpn/x86/k7/aors_n.asm                  | 1 +
+ mpn/x86/k7/mmx/com.asm                 | 1 +
+ mpn/x86/k7/mmx/copyd.asm               | 1 +
+ mpn/x86/k7/mmx/copyi.asm               | 1 +
+ mpn/x86/k7/mmx/divrem_1.asm            | 1 +
+ mpn/x86/k7/mmx/lshift.asm              | 1 +
+ mpn/x86/k7/mmx/popham.asm              | 1 +
+ mpn/x86/k7/mmx/rshift.asm              | 1 +
+ mpn/x86/k7/mod_1_1.asm                 | 1 +
+ mpn/x86/k7/mod_1_4.asm                 | 1 +
+ mpn/x86/k7/mod_34lsub1.asm             | 1 +
+ mpn/x86/k7/mul_basecase.asm            | 1 +
+ mpn/x86/k7/sqr_basecase.asm            | 1 +
+ mpn/x86/lshift.asm                     | 1 +
+ mpn/x86/mmx/sec_tabselect.asm          | 1 +
+ mpn/x86/mod_34lsub1.asm                | 1 +
+ mpn/x86/mul_1.asm                      | 1 +
+ mpn/x86/mul_basecase.asm               | 1 +
+ mpn/x86/p6/aors_n.asm                  | 1 +
+ mpn/x86/p6/aorsmul_1.asm               | 1 +
+ mpn/x86/p6/copyd.asm                   | 1 +
+ mpn/x86/p6/gcd_1.asm                   | 1 +
+ mpn/x86/p6/lshsub_n.asm                | 1 +
+ mpn/x86/p6/mmx/divrem_1.asm            | 1 +
+ mpn/x86/p6/mod_34lsub1.asm             | 1 +
+ mpn/x86/p6/mul_basecase.asm            | 1 +
+ mpn/x86/p6/sqr_basecase.asm            | 1 +
+ mpn/x86/pentium/aors_n.asm             | 1 +
+ mpn/x86/pentium/aorsmul_1.asm          | 1 +
+ mpn/x86/pentium/com.asm                | 1 +
+ mpn/x86/pentium/copyd.asm              | 1 +
+ mpn/x86/pentium/copyi.asm              | 1 +
+ mpn/x86/pentium/logops_n.asm           | 1 +
+ mpn/x86/pentium/lshift.asm             | 1 +
+ mpn/x86/pentium/mmx/lshift.asm         | 1 +
+ mpn/x86/pentium/mmx/mul_1.asm          | 1 +
+ mpn/x86/pentium/mmx/rshift.asm         | 1 +
+ mpn/x86/pentium/mod_34lsub1.asm        | 1 +
+ mpn/x86/pentium/mul_1.asm              | 1 +
+ mpn/x86/pentium/mul_2.asm              | 1 +
+ mpn/x86/pentium/mul_basecase.asm       | 2 +-
+ mpn/x86/pentium/rshift.asm             | 1 +
+ mpn/x86/pentium/sqr_basecase.asm       | 1 +
+ mpn/x86/pentium4/copyd.asm             | 1 +
+ mpn/x86/pentium4/copyi.asm             | 1 +
+ mpn/x86/pentium4/mmx/popham.asm        | 1 +
+ mpn/x86/pentium4/sse2/add_n.asm        | 1 +
+ mpn/x86/pentium4/sse2/addlsh1_n.asm    | 1 +
+ mpn/x86/pentium4/sse2/addmul_1.asm     | 1 +
+ mpn/x86/pentium4/sse2/cnd_add_n.asm    | 1 +
+ mpn/x86/pentium4/sse2/cnd_sub_n.asm    | 1 +
+ mpn/x86/pentium4/sse2/divrem_1.asm     | 1 +
+ mpn/x86/pentium4/sse2/mod_1_1.asm      | 1 +
+ mpn/x86/pentium4/sse2/mod_1_4.asm      | 1 +
+ mpn/x86/pentium4/sse2/mod_34lsub1.asm  | 1 +
+ mpn/x86/pentium4/sse2/mul_1.asm        | 1 +
+ mpn/x86/pentium4/sse2/mul_basecase.asm | 1 +
+ mpn/x86/pentium4/sse2/rsh1add_n.asm    | 1 +
+ mpn/x86/pentium4/sse2/sqr_basecase.asm | 1 +
+ mpn/x86/pentium4/sse2/sub_n.asm        | 1 +
+ mpn/x86/pentium4/sse2/submul_1.asm     | 1 +
+ mpn/x86/rshift.asm                     | 1 +
+ mpn/x86/sec_tabselect.asm              | 1 +
+ mpn/x86/sqr_basecase.asm               | 1 +
+ mpn/x86/udiv.asm                       | 1 +
+ mpn/x86/umul.asm                       | 1 +
+ 93 files changed, 93 insertions(+), 1 deletion(-)
+
+diff --git a/mpn/x86/aors_n.asm b/mpn/x86/aors_n.asm
+index 5d359f59b..95d006a5a 100644
+--- a/mpn/x86/aors_n.asm
++++ b/mpn/x86/aors_n.asm
+@@ -200,3 +200,4 @@ L(oop):	movl	(%esi),%eax
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/aorsmul_1.asm b/mpn/x86/aorsmul_1.asm
+index 54a890544..0ab1e01f5 100644
+--- a/mpn/x86/aorsmul_1.asm
++++ b/mpn/x86/aorsmul_1.asm
+@@ -154,3 +154,4 @@ L(end):	movl	%ebx,%eax
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/atom/sse2/aorsmul_1.asm b/mpn/x86/atom/sse2/aorsmul_1.asm
+index 969a14a91..20658e170 100644
+--- a/mpn/x86/atom/sse2/aorsmul_1.asm
++++ b/mpn/x86/atom/sse2/aorsmul_1.asm
+@@ -172,3 +172,4 @@ PROLOGUE(func_1c)
+ 	mov	20(%esp), %edx		C carry
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/atom/sse2/mul_basecase.asm b/mpn/x86/atom/sse2/mul_basecase.asm
+index 97d3aeb5a..74171aa5a 100644
+--- a/mpn/x86/atom/sse2/mul_basecase.asm
++++ b/mpn/x86/atom/sse2/mul_basecase.asm
+@@ -499,3 +499,4 @@ L(done):
+ 	pop	%edi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/atom/sse2/sqr_basecase.asm b/mpn/x86/atom/sse2/sqr_basecase.asm
+index af19ed854..0031812f6 100644
+--- a/mpn/x86/atom/sse2/sqr_basecase.asm
++++ b/mpn/x86/atom/sse2/sqr_basecase.asm
+@@ -632,3 +632,4 @@ L(one):	pmuludq	%mm7, %mm7
+ 	pop	%edi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/bdiv_dbm1c.asm b/mpn/x86/bdiv_dbm1c.asm
+index 0288c475c..7a3b1a62c 100644
+--- a/mpn/x86/bdiv_dbm1c.asm
++++ b/mpn/x86/bdiv_dbm1c.asm
+@@ -127,3 +127,4 @@ L(b1):	add	$-4, %ebp
+ 	pop	%esi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/copyd.asm b/mpn/x86/copyd.asm
+index 51fa19568..0e588d997 100644
+--- a/mpn/x86/copyd.asm
++++ b/mpn/x86/copyd.asm
+@@ -89,3 +89,4 @@ PROLOGUE(mpn_copyd)
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/copyi.asm b/mpn/x86/copyi.asm
+index f6b0354b4..6efbb903e 100644
+--- a/mpn/x86/copyi.asm
++++ b/mpn/x86/copyi.asm
+@@ -97,3 +97,4 @@ PROLOGUE(mpn_copyi)
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/divrem_1.asm b/mpn/x86/divrem_1.asm
+index 255d4935c..b1af92042 100644
+--- a/mpn/x86/divrem_1.asm
++++ b/mpn/x86/divrem_1.asm
+@@ -231,3 +231,4 @@ deflit(`FRAME',8)
+ 	popl	%edi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/divrem_2.asm b/mpn/x86/divrem_2.asm
+index 4c38ad0ac..c2920c2d7 100644
+--- a/mpn/x86/divrem_2.asm
++++ b/mpn/x86/divrem_2.asm
+@@ -197,3 +197,4 @@ L(35):	sub	20(%esp), %ebp
+ 	movl	$1, 32(%esp)
+ 	jmp	L(8)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/aors_n.asm b/mpn/x86/k6/aors_n.asm
+index 168f9b4ae..257ba5987 100644
+--- a/mpn/x86/k6/aors_n.asm
++++ b/mpn/x86/k6/aors_n.asm
+@@ -335,3 +335,4 @@ L(inplace_done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/aorsmul_1.asm b/mpn/x86/k6/aorsmul_1.asm
+index eaa92ebb2..78be9d250 100644
+--- a/mpn/x86/k6/aorsmul_1.asm
++++ b/mpn/x86/k6/aorsmul_1.asm
+@@ -389,3 +389,4 @@ Zdisp(	M4_inst,%ecx, disp0,(%edi))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/divrem_1.asm b/mpn/x86/k6/divrem_1.asm
+index b4cea4fa2..ca41a3f4d 100644
+--- a/mpn/x86/k6/divrem_1.asm
++++ b/mpn/x86/k6/divrem_1.asm
+@@ -201,3 +201,4 @@ deflit(`FRAME',8)
+ 	popl	%edi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/gcd_1.asm b/mpn/x86/k6/gcd_1.asm
+index a45774d37..307ab6616 100644
+--- a/mpn/x86/k6/gcd_1.asm
++++ b/mpn/x86/k6/gcd_1.asm
+@@ -357,3 +357,4 @@ L(movl_eip_ebx):
+ ')
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/k62mmx/copyd.asm b/mpn/x86/k6/k62mmx/copyd.asm
+index f80a5a1cd..fc329f5b9 100644
+--- a/mpn/x86/k6/k62mmx/copyd.asm
++++ b/mpn/x86/k6/k62mmx/copyd.asm
+@@ -116,3 +116,4 @@ L(zero):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/k62mmx/lshift.asm b/mpn/x86/k6/k62mmx/lshift.asm
+index c86575fee..728fb5b15 100644
+--- a/mpn/x86/k6/k62mmx/lshift.asm
++++ b/mpn/x86/k6/k62mmx/lshift.asm
+@@ -292,3 +292,4 @@ deflit(`FRAME',4)
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/k62mmx/rshift.asm b/mpn/x86/k6/k62mmx/rshift.asm
+index f604a7bd5..bd673f303 100644
+--- a/mpn/x86/k6/k62mmx/rshift.asm
++++ b/mpn/x86/k6/k62mmx/rshift.asm
+@@ -291,3 +291,4 @@ L(finish_even):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mmx/com.asm b/mpn/x86/k6/mmx/com.asm
+index b74745462..646d16b02 100644
+--- a/mpn/x86/k6/mmx/com.asm
++++ b/mpn/x86/k6/mmx/com.asm
+@@ -101,3 +101,4 @@ L(no_extra):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mmx/logops_n.asm b/mpn/x86/k6/mmx/logops_n.asm
+index e17930bb2..acfd7df08 100644
+--- a/mpn/x86/k6/mmx/logops_n.asm
++++ b/mpn/x86/k6/mmx/logops_n.asm
+@@ -224,3 +224,4 @@ L(no_extra):
+ 			ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mmx/lshift.asm b/mpn/x86/k6/mmx/lshift.asm
+index 45be58263..eee1eb869 100644
+--- a/mpn/x86/k6/mmx/lshift.asm
++++ b/mpn/x86/k6/mmx/lshift.asm
+@@ -128,3 +128,4 @@ L(top):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mmx/popham.asm b/mpn/x86/k6/mmx/popham.asm
+index 2b19d0b5e..efeb1b4cb 100644
+--- a/mpn/x86/k6/mmx/popham.asm
++++ b/mpn/x86/k6/mmx/popham.asm
+@@ -234,3 +234,4 @@ HAM(`	nop			C code alignment')
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mmx/rshift.asm b/mpn/x86/k6/mmx/rshift.asm
+index cd0382f32..ae53711cb 100644
+--- a/mpn/x86/k6/mmx/rshift.asm
++++ b/mpn/x86/k6/mmx/rshift.asm
+@@ -128,3 +128,4 @@ Zdisp(	movd,	%mm0, 0,(%ecx,%eax,4))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mod_34lsub1.asm b/mpn/x86/k6/mod_34lsub1.asm
+index 7e30503e5..05f89795c 100644
+--- a/mpn/x86/k6/mod_34lsub1.asm
++++ b/mpn/x86/k6/mod_34lsub1.asm
+@@ -188,3 +188,4 @@ L(combine):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mul_1.asm b/mpn/x86/k6/mul_1.asm
+index 3ef7ec24f..2139f3673 100644
+--- a/mpn/x86/k6/mul_1.asm
++++ b/mpn/x86/k6/mul_1.asm
+@@ -290,3 +290,4 @@ L(finish_not_one):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/mul_basecase.asm b/mpn/x86/k6/mul_basecase.asm
+index 7030001c3..ab202a2ce 100644
+--- a/mpn/x86/k6/mul_basecase.asm
++++ b/mpn/x86/k6/mul_basecase.asm
+@@ -610,3 +610,4 @@ Zdisp(	addl,	%ecx, disp0,(%edi))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/pre_mod_1.asm b/mpn/x86/k6/pre_mod_1.asm
+index 34db20d38..1e4cb17e9 100644
+--- a/mpn/x86/k6/pre_mod_1.asm
++++ b/mpn/x86/k6/pre_mod_1.asm
+@@ -144,3 +144,4 @@ L(q1_ff):
+ 
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k6/sqr_basecase.asm b/mpn/x86/k6/sqr_basecase.asm
+index b7ecb5cc8..f3a101a0f 100644
+--- a/mpn/x86/k6/sqr_basecase.asm
++++ b/mpn/x86/k6/sqr_basecase.asm
+@@ -678,3 +678,4 @@ L(pic_calc):
+ 
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/aors_n.asm b/mpn/x86/k7/aors_n.asm
+index 1a0807202..bfdf3d40a 100644
+--- a/mpn/x86/k7/aors_n.asm
++++ b/mpn/x86/k7/aors_n.asm
+@@ -256,3 +256,4 @@ L(even):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/com.asm b/mpn/x86/k7/mmx/com.asm
+index a258c224f..cf48facfd 100644
+--- a/mpn/x86/k7/mmx/com.asm
++++ b/mpn/x86/k7/mmx/com.asm
+@@ -123,3 +123,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/copyd.asm b/mpn/x86/k7/mmx/copyd.asm
+index 59ece4092..3bc9ff8b8 100644
+--- a/mpn/x86/k7/mmx/copyd.asm
++++ b/mpn/x86/k7/mmx/copyd.asm
+@@ -142,3 +142,4 @@ L(done):
+ 
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/copyi.asm b/mpn/x86/k7/mmx/copyi.asm
+index 9a28f927e..f0648fa09 100644
+--- a/mpn/x86/k7/mmx/copyi.asm
++++ b/mpn/x86/k7/mmx/copyi.asm
+@@ -155,3 +155,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/divrem_1.asm b/mpn/x86/k7/mmx/divrem_1.asm
+index cf343280b..370bfbb88 100644
+--- a/mpn/x86/k7/mmx/divrem_1.asm
++++ b/mpn/x86/k7/mmx/divrem_1.asm
+@@ -830,3 +830,4 @@ L(fraction_entry):
+ 	jmp	L(fraction_done)
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/lshift.asm b/mpn/x86/k7/mmx/lshift.asm
+index b3383cf2c..4140e82bb 100644
+--- a/mpn/x86/k7/mmx/lshift.asm
++++ b/mpn/x86/k7/mmx/lshift.asm
+@@ -479,3 +479,4 @@ L(end_even_unaligned):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/popham.asm b/mpn/x86/k7/mmx/popham.asm
+index 95965b74d..f29540a0a 100644
+--- a/mpn/x86/k7/mmx/popham.asm
++++ b/mpn/x86/k7/mmx/popham.asm
+@@ -211,3 +211,4 @@ L(loaded):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mmx/rshift.asm b/mpn/x86/k7/mmx/rshift.asm
+index 345d23a25..0da1f9341 100644
+--- a/mpn/x86/k7/mmx/rshift.asm
++++ b/mpn/x86/k7/mmx/rshift.asm
+@@ -478,3 +478,4 @@ L(end_even_unaligned):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mod_1_1.asm b/mpn/x86/k7/mod_1_1.asm
+index 1bbe6f92d..8da9519b0 100644
+--- a/mpn/x86/k7/mod_1_1.asm
++++ b/mpn/x86/k7/mod_1_1.asm
+@@ -219,3 +219,4 @@ PROLOGUE(mpn_mod_1_1p_cps)
+ 	pop	%ebp
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mod_1_4.asm b/mpn/x86/k7/mod_1_4.asm
+index bb7597edd..fe1da5bba 100644
+--- a/mpn/x86/k7/mod_1_4.asm
++++ b/mpn/x86/k7/mod_1_4.asm
+@@ -258,3 +258,4 @@ C CAUTION: This is the same code as in pentium4/sse2/mod_1_4.asm
+ 	pop	%ebp
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mod_34lsub1.asm b/mpn/x86/k7/mod_34lsub1.asm
+index ee3ad0409..0c1b8c84e 100644
+--- a/mpn/x86/k7/mod_34lsub1.asm
++++ b/mpn/x86/k7/mod_34lsub1.asm
+@@ -186,3 +186,4 @@ L(combine):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/mul_basecase.asm b/mpn/x86/k7/mul_basecase.asm
+index 4dfb50088..b96fda7e0 100644
+--- a/mpn/x86/k7/mul_basecase.asm
++++ b/mpn/x86/k7/mul_basecase.asm
+@@ -600,3 +600,4 @@ deflit(`disp1', eval(disp0-0 + 4))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/k7/sqr_basecase.asm b/mpn/x86/k7/sqr_basecase.asm
+index 7b6a97e0d..df47ee421 100644
+--- a/mpn/x86/k7/sqr_basecase.asm
++++ b/mpn/x86/k7/sqr_basecase.asm
+@@ -633,3 +633,4 @@ L(diag):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/lshift.asm b/mpn/x86/lshift.asm
+index 6ee6153cc..95f5321e0 100644
+--- a/mpn/x86/lshift.asm
++++ b/mpn/x86/lshift.asm
+@@ -104,3 +104,4 @@ L(end):	shll	%cl,%ebx		C compute least significant limb
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/mmx/sec_tabselect.asm b/mpn/x86/mmx/sec_tabselect.asm
+index aae158abf..543dec164 100644
+--- a/mpn/x86/mmx/sec_tabselect.asm
++++ b/mpn/x86/mmx/sec_tabselect.asm
+@@ -161,3 +161,4 @@ L(b00):	pop	%ebp
+ 	emms
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/mod_34lsub1.asm b/mpn/x86/mod_34lsub1.asm
+index e09e702c6..df52d371c 100644
+--- a/mpn/x86/mod_34lsub1.asm
++++ b/mpn/x86/mod_34lsub1.asm
+@@ -181,3 +181,4 @@ L(combine):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/mul_1.asm b/mpn/x86/mul_1.asm
+index 421de6222..dbbc0e339 100644
+--- a/mpn/x86/mul_1.asm
++++ b/mpn/x86/mul_1.asm
+@@ -138,3 +138,4 @@ L(end):	movl	%ebx,%eax
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/mul_basecase.asm b/mpn/x86/mul_basecase.asm
+index 8339732a8..c32fd7e0e 100644
+--- a/mpn/x86/mul_basecase.asm
++++ b/mpn/x86/mul_basecase.asm
+@@ -221,3 +221,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/aors_n.asm b/mpn/x86/p6/aors_n.asm
+index df51c2e6f..b4a32150f 100644
+--- a/mpn/x86/p6/aors_n.asm
++++ b/mpn/x86/p6/aors_n.asm
+@@ -154,3 +154,4 @@ PROLOGUE(func_nc)
+ 	movl	20(%esp), %edx
+ 	jmp	L(start)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/aorsmul_1.asm b/mpn/x86/p6/aorsmul_1.asm
+index bc8c49c62..d6bc549e3 100644
+--- a/mpn/x86/p6/aorsmul_1.asm
++++ b/mpn/x86/p6/aorsmul_1.asm
+@@ -318,3 +318,4 @@ deflit(`disp0',	eval(UNROLL_BYTES ifelse(UNROLL_BYTES,256,-128)))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/copyd.asm b/mpn/x86/p6/copyd.asm
+index 1be763683..bd42da18b 100644
+--- a/mpn/x86/p6/copyd.asm
++++ b/mpn/x86/p6/copyd.asm
+@@ -176,3 +176,4 @@ L(zero):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/gcd_1.asm b/mpn/x86/p6/gcd_1.asm
+index eafbf4a79..e4c7a8f60 100644
+--- a/mpn/x86/p6/gcd_1.asm
++++ b/mpn/x86/p6/gcd_1.asm
+@@ -159,3 +159,4 @@ L(movl_eip_to_ebx):
+ 	ret
+ ')
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/lshsub_n.asm b/mpn/x86/p6/lshsub_n.asm
+index 7ada21364..2ceb98bd8 100644
+--- a/mpn/x86/p6/lshsub_n.asm
++++ b/mpn/x86/p6/lshsub_n.asm
+@@ -167,3 +167,4 @@ L(ent):	mov	   0(up,n,4), %eax
+ 	jmp	   L(top)
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/mmx/divrem_1.asm b/mpn/x86/p6/mmx/divrem_1.asm
+index 5300616c1..b6057ddcc 100644
+--- a/mpn/x86/p6/mmx/divrem_1.asm
++++ b/mpn/x86/p6/mmx/divrem_1.asm
+@@ -765,3 +765,4 @@ L(fraction_top):
+ 	jmp	L(fraction_done)
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/mod_34lsub1.asm b/mpn/x86/p6/mod_34lsub1.asm
+index b88ab5d17..46b38060d 100644
+--- a/mpn/x86/p6/mod_34lsub1.asm
++++ b/mpn/x86/p6/mod_34lsub1.asm
+@@ -188,3 +188,4 @@ L(done_0):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/mul_basecase.asm b/mpn/x86/p6/mul_basecase.asm
+index d87bc12b6..03ae0d6b2 100644
+--- a/mpn/x86/p6/mul_basecase.asm
++++ b/mpn/x86/p6/mul_basecase.asm
+@@ -605,3 +605,4 @@ deflit(`disp1', eval(disp0 + 4))
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/p6/sqr_basecase.asm b/mpn/x86/p6/sqr_basecase.asm
+index 8fc7fdf37..ca29e8084 100644
+--- a/mpn/x86/p6/sqr_basecase.asm
++++ b/mpn/x86/p6/sqr_basecase.asm
+@@ -647,3 +647,4 @@ L(pic_calc):
+ 
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/aors_n.asm b/mpn/x86/pentium/aors_n.asm
+index 01ebfb96a..ca124a54f 100644
+--- a/mpn/x86/pentium/aors_n.asm
++++ b/mpn/x86/pentium/aors_n.asm
+@@ -201,3 +201,4 @@ L(end2):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/aorsmul_1.asm b/mpn/x86/pentium/aorsmul_1.asm
+index d83cc4513..5cec8b3ad 100644
+--- a/mpn/x86/pentium/aorsmul_1.asm
++++ b/mpn/x86/pentium/aorsmul_1.asm
+@@ -142,3 +142,4 @@ L(top):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/com.asm b/mpn/x86/pentium/com.asm
+index b0805452a..00064fffe 100644
+--- a/mpn/x86/pentium/com.asm
++++ b/mpn/x86/pentium/com.asm
+@@ -179,3 +179,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/copyd.asm b/mpn/x86/pentium/copyd.asm
+index 72a543b2a..c7f74b5fc 100644
+--- a/mpn/x86/pentium/copyd.asm
++++ b/mpn/x86/pentium/copyd.asm
+@@ -144,3 +144,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/copyi.asm b/mpn/x86/pentium/copyi.asm
+index d983d6b46..bc7744eb8 100644
+--- a/mpn/x86/pentium/copyi.asm
++++ b/mpn/x86/pentium/copyi.asm
+@@ -162,3 +162,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/logops_n.asm b/mpn/x86/pentium/logops_n.asm
+index 18773172e..41a9477ba 100644
+--- a/mpn/x86/pentium/logops_n.asm
++++ b/mpn/x86/pentium/logops_n.asm
+@@ -174,3 +174,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/lshift.asm b/mpn/x86/pentium/lshift.asm
+index 2a31f36c6..68cba52e9 100644
+--- a/mpn/x86/pentium/lshift.asm
++++ b/mpn/x86/pentium/lshift.asm
+@@ -241,3 +241,4 @@ L(L1):	movl	%edx,(%edi)		C store last limb
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mmx/lshift.asm b/mpn/x86/pentium/mmx/lshift.asm
+index 04b0ddcc8..9e18c861e 100644
+--- a/mpn/x86/pentium/mmx/lshift.asm
++++ b/mpn/x86/pentium/mmx/lshift.asm
+@@ -461,3 +461,4 @@ L(finish_zero_unaligned):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mmx/mul_1.asm b/mpn/x86/pentium/mmx/mul_1.asm
+index 4ced577b1..b04a718f8 100644
+--- a/mpn/x86/pentium/mmx/mul_1.asm
++++ b/mpn/x86/pentium/mmx/mul_1.asm
+@@ -369,3 +369,4 @@ L(small_done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mmx/rshift.asm b/mpn/x86/pentium/mmx/rshift.asm
+index e3b274bb6..5493d2054 100644
+--- a/mpn/x86/pentium/mmx/rshift.asm
++++ b/mpn/x86/pentium/mmx/rshift.asm
+@@ -466,3 +466,4 @@ L(finish_zero_unaligned):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mod_34lsub1.asm b/mpn/x86/pentium/mod_34lsub1.asm
+index 2d88223b8..0945de825 100644
+--- a/mpn/x86/pentium/mod_34lsub1.asm
++++ b/mpn/x86/pentium/mod_34lsub1.asm
+@@ -190,3 +190,4 @@ L(combine):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mul_1.asm b/mpn/x86/pentium/mul_1.asm
+index a0858af2b..2c4913071 100644
+--- a/mpn/x86/pentium/mul_1.asm
++++ b/mpn/x86/pentium/mul_1.asm
+@@ -175,3 +175,4 @@ L(top):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mul_2.asm b/mpn/x86/pentium/mul_2.asm
+index 4c7beb5df..e94e07120 100644
+--- a/mpn/x86/pentium/mul_2.asm
++++ b/mpn/x86/pentium/mul_2.asm
+@@ -148,3 +148,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/mul_basecase.asm b/mpn/x86/pentium/mul_basecase.asm
+index 50e15d356..ff269bb9d 100644
+--- a/mpn/x86/pentium/mul_basecase.asm
++++ b/mpn/x86/pentium/mul_basecase.asm
+@@ -140,4 +140,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
+-
++ASM_END()
+diff --git a/mpn/x86/pentium/rshift.asm b/mpn/x86/pentium/rshift.asm
+index 2105c4c93..d98080de6 100644
+--- a/mpn/x86/pentium/rshift.asm
++++ b/mpn/x86/pentium/rshift.asm
+@@ -241,3 +241,4 @@ L(L1):	movl	%edx,(%edi)		C store last limb
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium/sqr_basecase.asm b/mpn/x86/pentium/sqr_basecase.asm
+index b11d767da..ee64eb371 100644
+--- a/mpn/x86/pentium/sqr_basecase.asm
++++ b/mpn/x86/pentium/sqr_basecase.asm
+@@ -526,3 +526,4 @@ L(diag):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/copyd.asm b/mpn/x86/pentium4/copyd.asm
+index 82af81c52..bf06a0534 100644
+--- a/mpn/x86/pentium4/copyd.asm
++++ b/mpn/x86/pentium4/copyd.asm
+@@ -69,3 +69,4 @@ L(end):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/copyi.asm b/mpn/x86/pentium4/copyi.asm
+index b6148879f..acbb3f462 100644
+--- a/mpn/x86/pentium4/copyi.asm
++++ b/mpn/x86/pentium4/copyi.asm
+@@ -91,3 +91,4 @@ L(replmovs):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/mmx/popham.asm b/mpn/x86/pentium4/mmx/popham.asm
+index 9563cb57e..f7a612487 100644
+--- a/mpn/x86/pentium4/mmx/popham.asm
++++ b/mpn/x86/pentium4/mmx/popham.asm
+@@ -201,3 +201,4 @@ L(loaded):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/add_n.asm b/mpn/x86/pentium4/sse2/add_n.asm
+index 8e2380e49..e32963560 100644
+--- a/mpn/x86/pentium4/sse2/add_n.asm
++++ b/mpn/x86/pentium4/sse2/add_n.asm
+@@ -99,3 +99,4 @@ L(top):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/addlsh1_n.asm b/mpn/x86/pentium4/sse2/addlsh1_n.asm
+index 93b63b201..e801f7b4f 100644
+--- a/mpn/x86/pentium4/sse2/addlsh1_n.asm
++++ b/mpn/x86/pentium4/sse2/addlsh1_n.asm
+@@ -106,3 +106,4 @@ L(top):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/addmul_1.asm b/mpn/x86/pentium4/sse2/addmul_1.asm
+index 78102072b..62a76753a 100644
+--- a/mpn/x86/pentium4/sse2/addmul_1.asm
++++ b/mpn/x86/pentium4/sse2/addmul_1.asm
+@@ -187,3 +187,4 @@ PROLOGUE(mpn_addmul_1c)
+ 	movd	20(%esp), %mm6
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/cnd_add_n.asm b/mpn/x86/pentium4/sse2/cnd_add_n.asm
+index b3f3474e6..7183b9422 100644
+--- a/mpn/x86/pentium4/sse2/cnd_add_n.asm
++++ b/mpn/x86/pentium4/sse2/cnd_add_n.asm
+@@ -93,3 +93,4 @@ L(top):	movd	(%ebx,%ecx,4), %mm2
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/cnd_sub_n.asm b/mpn/x86/pentium4/sse2/cnd_sub_n.asm
+index 339a23e0b..ba0fc47ad 100644
+--- a/mpn/x86/pentium4/sse2/cnd_sub_n.asm
++++ b/mpn/x86/pentium4/sse2/cnd_sub_n.asm
+@@ -112,3 +112,4 @@ L(done_mm1):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/divrem_1.asm b/mpn/x86/pentium4/sse2/divrem_1.asm
+index 0146fab11..d8619e047 100644
+--- a/mpn/x86/pentium4/sse2/divrem_1.asm
++++ b/mpn/x86/pentium4/sse2/divrem_1.asm
+@@ -643,3 +643,4 @@ L(fraction_top):
+ 	jmp	L(fraction_done)
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/mod_1_1.asm b/mpn/x86/pentium4/sse2/mod_1_1.asm
+index ee88babee..2e5a5146b 100644
+--- a/mpn/x86/pentium4/sse2/mod_1_1.asm
++++ b/mpn/x86/pentium4/sse2/mod_1_1.asm
+@@ -164,3 +164,4 @@ C CAUTION: This is the same code as in k7/mod_1_1.asm
+ 	pop	%ebp
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/mod_1_4.asm b/mpn/x86/pentium4/sse2/mod_1_4.asm
+index eb2edb629..5ef3c4aef 100644
+--- a/mpn/x86/pentium4/sse2/mod_1_4.asm
++++ b/mpn/x86/pentium4/sse2/mod_1_4.asm
+@@ -267,3 +267,4 @@ C CAUTION: This is the same code as in k7/mod_1_4.asm
+ 	pop	%ebp
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/mod_34lsub1.asm b/mpn/x86/pentium4/sse2/mod_34lsub1.asm
+index 31e25b79b..5b6b9a765 100644
+--- a/mpn/x86/pentium4/sse2/mod_34lsub1.asm
++++ b/mpn/x86/pentium4/sse2/mod_34lsub1.asm
+@@ -173,3 +173,4 @@ L(combine):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/mul_1.asm b/mpn/x86/pentium4/sse2/mul_1.asm
+index 6347b8bf6..9e4f3fc88 100644
+--- a/mpn/x86/pentium4/sse2/mul_1.asm
++++ b/mpn/x86/pentium4/sse2/mul_1.asm
+@@ -162,3 +162,4 @@ PROLOGUE(mpn_mul_1c)
+ 	movd	20(%esp), %mm6
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/mul_basecase.asm b/mpn/x86/pentium4/sse2/mul_basecase.asm
+index 6e3775ae0..0bad75610 100644
+--- a/mpn/x86/pentium4/sse2/mul_basecase.asm
++++ b/mpn/x86/pentium4/sse2/mul_basecase.asm
+@@ -660,3 +660,4 @@ L(oel3):
+ 	pop	%esi			C				   3
+ 	ret				C				   3
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/rsh1add_n.asm b/mpn/x86/pentium4/sse2/rsh1add_n.asm
+index f421d1323..543a637de 100644
+--- a/mpn/x86/pentium4/sse2/rsh1add_n.asm
++++ b/mpn/x86/pentium4/sse2/rsh1add_n.asm
+@@ -124,3 +124,4 @@ L(done):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/sqr_basecase.asm b/mpn/x86/pentium4/sse2/sqr_basecase.asm
+index 2dd57d25d..9695d42c5 100644
+--- a/mpn/x86/pentium4/sse2/sqr_basecase.asm
++++ b/mpn/x86/pentium4/sse2/sqr_basecase.asm
+@@ -703,3 +703,4 @@ L(diag):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/sub_n.asm b/mpn/x86/pentium4/sse2/sub_n.asm
+index 5ba1c018e..2cd5b2297 100644
+--- a/mpn/x86/pentium4/sse2/sub_n.asm
++++ b/mpn/x86/pentium4/sse2/sub_n.asm
+@@ -117,3 +117,4 @@ L(done_mm1):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/pentium4/sse2/submul_1.asm b/mpn/x86/pentium4/sse2/submul_1.asm
+index 020675bd7..1172f0a5a 100644
+--- a/mpn/x86/pentium4/sse2/submul_1.asm
++++ b/mpn/x86/pentium4/sse2/submul_1.asm
+@@ -180,3 +180,4 @@ L(eod):	paddq	%mm6, %mm4		C add 0xFFFFFFFE00000001
+ 	movd	%mm0, 8(%edx)		C result
+ 	jmp	L(rt)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/rshift.asm b/mpn/x86/rshift.asm
+index a60dcaa4b..1cedc0ddc 100644
+--- a/mpn/x86/rshift.asm
++++ b/mpn/x86/rshift.asm
+@@ -106,3 +106,4 @@ L(end):	shrl	%cl,%ebx		C compute most significant limb
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/sec_tabselect.asm b/mpn/x86/sec_tabselect.asm
+index c7c2e059f..3a8fa1729 100644
+--- a/mpn/x86/sec_tabselect.asm
++++ b/mpn/x86/sec_tabselect.asm
+@@ -113,3 +113,4 @@ L(outer_end):
+ 	pop	%edi
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/sqr_basecase.asm b/mpn/x86/sqr_basecase.asm
+index 39f8a8980..3414b057c 100644
+--- a/mpn/x86/sqr_basecase.asm
++++ b/mpn/x86/sqr_basecase.asm
+@@ -357,3 +357,4 @@ L(diag):
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/udiv.asm b/mpn/x86/udiv.asm
+index a3ee08860..2531ef72c 100644
+--- a/mpn/x86/udiv.asm
++++ b/mpn/x86/udiv.asm
+@@ -50,3 +50,4 @@ deflit(`FRAME',0)
+ 	movl	%edx, (%ecx)
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86/umul.asm b/mpn/x86/umul.asm
+index 34fe43440..5c1da35c9 100644
+--- a/mpn/x86/umul.asm
++++ b/mpn/x86/umul.asm
+@@ -49,3 +49,4 @@ deflit(`FRAME',0)
+ 	movl	%edx, %eax
+ 	ret
+ EPILOGUE()
++ASM_END()
+-- 
+2.24.1
+
diff --git a/0004-x86_64-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch b/0004-x86_64-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
new file mode 100644
index 0000000..f67daea
--- /dev/null
+++ b/0004-x86_64-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
@@ -0,0 +1,39 @@
+From a72cc2a4548aeba67bb01f3650c88d7e01ecbc68 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:27:50 -0800
+Subject: [PATCH 04/11] x86_64-defs.m4: Use X86_GNU_PROPERTY and X86_ENDBR
+
+1. Add X86_ENDBR to PROLOGUE_cpu to place "endbr64" at function entry.
+2. Define ASM_END to use X86_GNU_PROPERTY for .note.gnu.property section.
+
+	* mpn/x86_64/x86_64-defs.m4 (PROLOGUE_cpu): Add X86_ENDBR.
+	(ASM_END): New.
+---
+ mpn/x86_64/x86_64-defs.m4 | 4 ++++
+ 1 file changed, 4 insertions(+)
+
+diff --git a/mpn/x86_64/x86_64-defs.m4 b/mpn/x86_64/x86_64-defs.m4
+index a626419bb..a7b64815c 100644
+--- a/mpn/x86_64/x86_64-defs.m4
++++ b/mpn/x86_64/x86_64-defs.m4
+@@ -93,6 +93,7 @@ m4_assert_numargs(1)
+ `	GLOBL	$1
+ 	TYPE($1,`function')
+ $1:
++	X86_ENDBR
+ ')
+ 
+ 
+@@ -142,6 +143,9 @@ ifdef(`PIC',
+ 	`movabs	`$'$1, $2')
+ ')
+ 
++dnl ASM_END
++
++define(`ASM_END', `X86_GNU_PROPERTY')
+ 
+ define(`DEF_OBJECT',
+ m4_assert_numargs_range(1,2)
+-- 
+2.24.1
+
diff --git a/0005-x86_64-Append-ASM_END-to-assembly-codes.patch b/0005-x86_64-Append-ASM_END-to-assembly-codes.patch
new file mode 100644
index 0000000..45150ee
--- /dev/null
+++ b/0005-x86_64-Append-ASM_END-to-assembly-codes.patch
@@ -0,0 +1,1368 @@
+From 256f48c3cb01fe85dda515747e9fec6bc3ac3346 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:35:45 -0800
+Subject: [PATCH 05/11] x86_64: Append ASM_END to assembly codes
+
+Append ASM_END to x86_64 assembly codes to generate .note.gnu.property
+section when Intel CET is enabled.
+
+	* mpn/x86_64/addaddmul_1msb0.asm: Append ASM_END.
+	* mpn/x86_64/addmul_2.asm: Likewise.
+	* mpn/x86_64/aorrlsh1_n.asm: Likewise.
+	* mpn/x86_64/aorrlshC_n.asm: Likewise.
+	* mpn/x86_64/aorrlsh_n.asm: Likewise.
+	* mpn/x86_64/aors_err1_n.asm: Likewise.
+	* mpn/x86_64/aors_err2_n.asm: Likewise.
+	* mpn/x86_64/aors_err3_n.asm: Likewise.
+	* mpn/x86_64/aors_n.asm: Likewise.
+	* mpn/x86_64/aorsmul_1.asm: Likewise.
+	* mpn/x86_64/atom/addmul_2.asm: Likewise.
+	* mpn/x86_64/atom/aorrlsh1_n.asm: Likewise.
+	* mpn/x86_64/atom/aorrlsh2_n.asm: Likewise.
+	* mpn/x86_64/atom/lshift.asm: Likewise.
+	* mpn/x86_64/atom/lshiftc.asm: Likewise.
+	* mpn/x86_64/atom/mul_2.asm: Likewise.
+	* mpn/x86_64/atom/rsh1aors_n.asm: Likewise.
+	* mpn/x86_64/atom/rshift.asm: Likewise.
+	* mpn/x86_64/atom/sublsh1_n.asm: Likewise.
+	* mpn/x86_64/bd1/mul_2.asm: Likewise.
+	* mpn/x86_64/bd1/mul_basecase.asm: Likewise.
+	* mpn/x86_64/bdiv_dbm1c.asm: Likewise.
+	* mpn/x86_64/bdiv_q_1.asm: Likewise.
+	* mpn/x86_64/bobcat/aors_n.asm: Likewise.
+	* mpn/x86_64/bobcat/aorsmul_1.asm: Likewise.
+	* mpn/x86_64/bobcat/copyd.asm: Likewise.
+	* mpn/x86_64/bobcat/copyi.asm: Likewise.
+	* mpn/x86_64/bobcat/mul_1.asm: Likewise.
+	* mpn/x86_64/bobcat/mul_basecase.asm: Likewise.
+	* mpn/x86_64/bobcat/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/cnd_aors_n.asm: Likewise.
+	* mpn/x86_64/com.asm: Likewise.
+	* mpn/x86_64/copyd.asm: Likewise.
+	* mpn/x86_64/copyi.asm: Likewise.
+	* mpn/x86_64/core2/aors_err1_n.asm: Likewise.
+	* mpn/x86_64/core2/aors_n.asm: Likewise.
+	* mpn/x86_64/core2/aorsmul_1.asm: Likewise.
+	* mpn/x86_64/core2/divrem_1.asm: Likewise.
+	* mpn/x86_64/core2/gcd_1.asm: Likewise.
+	* mpn/x86_64/core2/lshift.asm: Likewise.
+	* mpn/x86_64/core2/lshiftc.asm: Likewise.
+	* mpn/x86_64/core2/mul_basecase.asm: Likewise.
+	* mpn/x86_64/core2/mullo_basecase.asm: Likewise.
+	* mpn/x86_64/core2/rsh1aors_n.asm: Likewise.
+	* mpn/x86_64/core2/rshift.asm: Likewise.
+	* mpn/x86_64/core2/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/core2/sublshC_n.asm: Likewise.
+	* mpn/x86_64/coreibwl/mul_basecase.asm: Likewise.
+	* mpn/x86_64/coreibwl/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/coreihwl/addmul_2.asm: Likewise.
+	* mpn/x86_64/coreihwl/aorsmul_1.asm: Likewise.
+	* mpn/x86_64/coreihwl/mul_2.asm: Likewise.
+	* mpn/x86_64/coreihwl/mul_basecase.asm: Likewise.
+	* mpn/x86_64/coreihwl/mullo_basecase.asm: Likewise.
+	* mpn/x86_64/coreihwl/redc_1.asm: Likewise.
+	* mpn/x86_64/coreihwl/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/coreinhm/aorrlsh_n.asm: Likewise.
+	* mpn/x86_64/coreisbr/addmul_2.asm: Likewise.
+	* mpn/x86_64/coreisbr/aorrlshC_n.asm: Likewise.
+	* mpn/x86_64/coreisbr/aorrlsh_n.asm: Likewise.
+	* mpn/x86_64/coreisbr/aors_n.asm: Likewise.
+	* mpn/x86_64/coreisbr/mul_1.asm: Likewise.
+	* mpn/x86_64/coreisbr/mul_2.asm: Likewise.
+	* mpn/x86_64/coreisbr/mul_basecase.asm: Likewise.
+	* mpn/x86_64/coreisbr/mullo_basecase.asm: Likewise.
+	* mpn/x86_64/coreisbr/popcount.asm: Likewise.
+	* mpn/x86_64/coreisbr/rsh1aors_n.asm: Likewise.
+	* mpn/x86_64/coreisbr/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/div_qr_1n_pi1.asm: Likewise.
+	* mpn/x86_64/div_qr_2n_pi1.asm: Likewise.
+	* mpn/x86_64/div_qr_2u_pi1.asm: Likewise.
+	* mpn/x86_64/dive_1.asm: Likewise.
+	* mpn/x86_64/divrem_1.asm: Likewise.
+	* mpn/x86_64/divrem_2.asm: Likewise.
+	* mpn/x86_64/fastavx/copyd.asm: Likewise.
+	* mpn/x86_64/fastavx/copyi.asm: Likewise.
+	* mpn/x86_64/fastsse/com-palignr.asm: Likewise.
+	* mpn/x86_64/fastsse/com.asm: Likewise.
+	* mpn/x86_64/fastsse/copyd-palignr.asm: Likewise.
+	* mpn/x86_64/fastsse/copyd.asm: Likewise.
+	* mpn/x86_64/fastsse/copyi-palignr.asm: Likewise.
+	* mpn/x86_64/fastsse/copyi.asm: Likewise.
+	* mpn/x86_64/fastsse/lshift-movdqu2.asm: Likewise.
+	* mpn/x86_64/fastsse/lshift.asm: Likewise.
+	* mpn/x86_64/fastsse/lshiftc-movdqu2.asm: Likewise.
+	* mpn/x86_64/fastsse/lshiftc.asm: Likewise.
+	* mpn/x86_64/fastsse/rshift-movdqu2.asm: Likewise.
+	* mpn/x86_64/fastsse/sec_tabselect.asm: Likewise.
+	* mpn/x86_64/fat/fat_entry.asm: Likewise.
+	* mpn/x86_64/gcd_1.asm: Likewise.
+	* mpn/x86_64/k10/hamdist.asm: Likewise.
+	* mpn/x86_64/k10/popcount.asm: Likewise.
+	* mpn/x86_64/k8/aorrlsh_n.asm: Likewise.
+	* mpn/x86_64/k8/div_qr_1n_pi1.asm: Likewise.
+	* mpn/x86_64/k8/mul_basecase.asm: Likewise.
+	* mpn/x86_64/k8/mullo_basecase.asm: Likewise.
+	* mpn/x86_64/k8/mulmid_basecase.asm: Likewise.
+	* mpn/x86_64/k8/redc_1.asm: Likewise.
+	* mpn/x86_64/k8/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/logops_n.asm: Likewise.
+	* mpn/x86_64/lshift.asm: Likewise.
+	* mpn/x86_64/lshiftc.asm: Likewise.
+	* mpn/x86_64/lshsub_n.asm: Likewise.
+	* mpn/x86_64/missing.asm: Likewise.
+	* mpn/x86_64/mod_1_2.asm: Likewise.
+	* mpn/x86_64/mod_1_4.asm: Likewise.
+	* mpn/x86_64/mod_34lsub1.asm: Likewise.
+	* mpn/x86_64/mode1o.asm: Likewise.
+	* mpn/x86_64/mul_1.asm: Likewise.
+	* mpn/x86_64/mul_2.asm: Likewise.
+	* mpn/x86_64/nano/dive_1.asm: Likewise.
+	* mpn/x86_64/pentium4/aors_n.asm: Likewise.
+	* mpn/x86_64/pentium4/lshift.asm: Likewise.
+	* mpn/x86_64/pentium4/lshiftc.asm: Likewise.
+	* mpn/x86_64/pentium4/mod_34lsub1.asm: Likewise.
+	* mpn/x86_64/pentium4/rsh1aors_n.asm: Likewise.
+	* mpn/x86_64/pentium4/rshift.asm: Likewise.
+	* mpn/x86_64/popham.asm: Likewise.
+	* mpn/x86_64/rsh1aors_n.asm: Likewise.
+	* mpn/x86_64/rshift.asm: Likewise.
+	* mpn/x86_64/sec_tabselect.asm: Likewise.
+	* mpn/x86_64/sqr_diag_addlsh1.asm: Likewise.
+	* mpn/x86_64/sublsh1_n.asm: Likewise.
+---
+ mpn/x86_64/addaddmul_1msb0.asm         | 1 +
+ mpn/x86_64/addmul_2.asm                | 1 +
+ mpn/x86_64/aorrlsh1_n.asm              | 1 +
+ mpn/x86_64/aorrlshC_n.asm              | 1 +
+ mpn/x86_64/aorrlsh_n.asm               | 1 +
+ mpn/x86_64/aors_err1_n.asm             | 1 +
+ mpn/x86_64/aors_err2_n.asm             | 1 +
+ mpn/x86_64/aors_err3_n.asm             | 1 +
+ mpn/x86_64/aors_n.asm                  | 1 +
+ mpn/x86_64/aorsmul_1.asm               | 1 +
+ mpn/x86_64/atom/addmul_2.asm           | 1 +
+ mpn/x86_64/atom/aorrlsh1_n.asm         | 1 +
+ mpn/x86_64/atom/aorrlsh2_n.asm         | 1 +
+ mpn/x86_64/atom/lshift.asm             | 1 +
+ mpn/x86_64/atom/lshiftc.asm            | 1 +
+ mpn/x86_64/atom/mul_2.asm              | 1 +
+ mpn/x86_64/atom/rsh1aors_n.asm         | 1 +
+ mpn/x86_64/atom/rshift.asm             | 1 +
+ mpn/x86_64/atom/sublsh1_n.asm          | 1 +
+ mpn/x86_64/bd1/mul_2.asm               | 1 +
+ mpn/x86_64/bd1/mul_basecase.asm        | 1 +
+ mpn/x86_64/bdiv_dbm1c.asm              | 1 +
+ mpn/x86_64/bdiv_q_1.asm                | 1 +
+ mpn/x86_64/bobcat/aors_n.asm           | 1 +
+ mpn/x86_64/bobcat/aorsmul_1.asm        | 1 +
+ mpn/x86_64/bobcat/copyd.asm            | 1 +
+ mpn/x86_64/bobcat/copyi.asm            | 1 +
+ mpn/x86_64/bobcat/mul_1.asm            | 1 +
+ mpn/x86_64/bobcat/mul_basecase.asm     | 1 +
+ mpn/x86_64/bobcat/sqr_basecase.asm     | 1 +
+ mpn/x86_64/cnd_aors_n.asm              | 1 +
+ mpn/x86_64/com.asm                     | 1 +
+ mpn/x86_64/copyd.asm                   | 1 +
+ mpn/x86_64/copyi.asm                   | 1 +
+ mpn/x86_64/core2/aors_err1_n.asm       | 1 +
+ mpn/x86_64/core2/aors_n.asm            | 2 +-
+ mpn/x86_64/core2/aorsmul_1.asm         | 1 +
+ mpn/x86_64/core2/divrem_1.asm          | 1 +
+ mpn/x86_64/core2/gcd_1.asm             | 1 +
+ mpn/x86_64/core2/lshift.asm            | 1 +
+ mpn/x86_64/core2/lshiftc.asm           | 1 +
+ mpn/x86_64/core2/mul_basecase.asm      | 1 +
+ mpn/x86_64/core2/mullo_basecase.asm    | 1 +
+ mpn/x86_64/core2/rsh1aors_n.asm        | 1 +
+ mpn/x86_64/core2/rshift.asm            | 1 +
+ mpn/x86_64/core2/sqr_basecase.asm      | 1 +
+ mpn/x86_64/core2/sublshC_n.asm         | 1 +
+ mpn/x86_64/coreibwl/mul_basecase.asm   | 1 +
+ mpn/x86_64/coreibwl/sqr_basecase.asm   | 1 +
+ mpn/x86_64/coreihwl/addmul_2.asm       | 1 +
+ mpn/x86_64/coreihwl/aorsmul_1.asm      | 1 +
+ mpn/x86_64/coreihwl/mul_2.asm          | 1 +
+ mpn/x86_64/coreihwl/mul_basecase.asm   | 1 +
+ mpn/x86_64/coreihwl/mullo_basecase.asm | 1 +
+ mpn/x86_64/coreihwl/redc_1.asm         | 1 +
+ mpn/x86_64/coreihwl/sqr_basecase.asm   | 1 +
+ mpn/x86_64/coreinhm/aorrlsh_n.asm      | 1 +
+ mpn/x86_64/coreisbr/addmul_2.asm       | 1 +
+ mpn/x86_64/coreisbr/aorrlshC_n.asm     | 1 +
+ mpn/x86_64/coreisbr/aorrlsh_n.asm      | 1 +
+ mpn/x86_64/coreisbr/aors_n.asm         | 1 +
+ mpn/x86_64/coreisbr/mul_1.asm          | 1 +
+ mpn/x86_64/coreisbr/mul_2.asm          | 1 +
+ mpn/x86_64/coreisbr/mul_basecase.asm   | 1 +
+ mpn/x86_64/coreisbr/mullo_basecase.asm | 1 +
+ mpn/x86_64/coreisbr/popcount.asm       | 1 +
+ mpn/x86_64/coreisbr/rsh1aors_n.asm     | 1 +
+ mpn/x86_64/coreisbr/sqr_basecase.asm   | 1 +
+ mpn/x86_64/div_qr_1n_pi1.asm           | 1 +
+ mpn/x86_64/div_qr_2n_pi1.asm           | 1 +
+ mpn/x86_64/div_qr_2u_pi1.asm           | 1 +
+ mpn/x86_64/dive_1.asm                  | 1 +
+ mpn/x86_64/divrem_1.asm                | 1 +
+ mpn/x86_64/divrem_2.asm                | 1 +
+ mpn/x86_64/fastavx/copyd.asm           | 1 +
+ mpn/x86_64/fastavx/copyi.asm           | 1 +
+ mpn/x86_64/fastsse/com-palignr.asm     | 1 +
+ mpn/x86_64/fastsse/com.asm             | 1 +
+ mpn/x86_64/fastsse/copyd-palignr.asm   | 1 +
+ mpn/x86_64/fastsse/copyd.asm           | 1 +
+ mpn/x86_64/fastsse/copyi-palignr.asm   | 1 +
+ mpn/x86_64/fastsse/copyi.asm           | 1 +
+ mpn/x86_64/fastsse/lshift-movdqu2.asm  | 1 +
+ mpn/x86_64/fastsse/lshift.asm          | 1 +
+ mpn/x86_64/fastsse/lshiftc-movdqu2.asm | 1 +
+ mpn/x86_64/fastsse/lshiftc.asm         | 1 +
+ mpn/x86_64/fastsse/rshift-movdqu2.asm  | 1 +
+ mpn/x86_64/fastsse/sec_tabselect.asm   | 1 +
+ mpn/x86_64/fat/fat_entry.asm           | 1 +
+ mpn/x86_64/gcd_1.asm                   | 1 +
+ mpn/x86_64/k10/hamdist.asm             | 1 +
+ mpn/x86_64/k10/popcount.asm            | 1 +
+ mpn/x86_64/k8/aorrlsh_n.asm            | 1 +
+ mpn/x86_64/k8/div_qr_1n_pi1.asm        | 1 +
+ mpn/x86_64/k8/mul_basecase.asm         | 1 +
+ mpn/x86_64/k8/mullo_basecase.asm       | 1 +
+ mpn/x86_64/k8/mulmid_basecase.asm      | 1 +
+ mpn/x86_64/k8/redc_1.asm               | 1 +
+ mpn/x86_64/k8/sqr_basecase.asm         | 1 +
+ mpn/x86_64/logops_n.asm                | 1 +
+ mpn/x86_64/lshift.asm                  | 1 +
+ mpn/x86_64/lshiftc.asm                 | 1 +
+ mpn/x86_64/lshsub_n.asm                | 1 +
+ mpn/x86_64/missing.asm                 | 1 +
+ mpn/x86_64/mod_1_2.asm                 | 1 +
+ mpn/x86_64/mod_1_4.asm                 | 1 +
+ mpn/x86_64/mod_34lsub1.asm             | 1 +
+ mpn/x86_64/mode1o.asm                  | 1 +
+ mpn/x86_64/mul_1.asm                   | 1 +
+ mpn/x86_64/mul_2.asm                   | 1 +
+ mpn/x86_64/nano/dive_1.asm             | 1 +
+ mpn/x86_64/pentium4/aors_n.asm         | 1 +
+ mpn/x86_64/pentium4/lshift.asm         | 1 +
+ mpn/x86_64/pentium4/lshiftc.asm        | 1 +
+ mpn/x86_64/pentium4/mod_34lsub1.asm    | 1 +
+ mpn/x86_64/pentium4/rsh1aors_n.asm     | 1 +
+ mpn/x86_64/pentium4/rshift.asm         | 1 +
+ mpn/x86_64/popham.asm                  | 1 +
+ mpn/x86_64/rsh1aors_n.asm              | 1 +
+ mpn/x86_64/rshift.asm                  | 1 +
+ mpn/x86_64/sec_tabselect.asm           | 1 +
+ mpn/x86_64/sqr_diag_addlsh1.asm        | 1 +
+ mpn/x86_64/sublsh1_n.asm               | 1 +
+ 123 files changed, 123 insertions(+), 1 deletion(-)
+
+diff --git a/mpn/x86_64/addaddmul_1msb0.asm b/mpn/x86_64/addaddmul_1msb0.asm
+index 87c21b4ac..2d03ddb9b 100644
+--- a/mpn/x86_64/addaddmul_1msb0.asm
++++ b/mpn/x86_64/addaddmul_1msb0.asm
+@@ -168,3 +168,4 @@ L(end):	cmp	$1, R32(n)
+ 	pop	%r12
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/addmul_2.asm b/mpn/x86_64/addmul_2.asm
+index 18307d719..832a4b41d 100644
+--- a/mpn/x86_64/addmul_2.asm
++++ b/mpn/x86_64/addmul_2.asm
+@@ -182,3 +182,4 @@ L(end):	xor	R32(w1), R32(w1)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aorrlsh1_n.asm b/mpn/x86_64/aorrlsh1_n.asm
+index 6ee087282..1441a6caf 100644
+--- a/mpn/x86_64/aorrlsh1_n.asm
++++ b/mpn/x86_64/aorrlsh1_n.asm
+@@ -168,3 +168,4 @@ ifdef(`OPERATION_rsblsh1_n',`
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aorrlshC_n.asm b/mpn/x86_64/aorrlshC_n.asm
+index 5a9fd4dfb..a6fa7536c 100644
+--- a/mpn/x86_64/aorrlshC_n.asm
++++ b/mpn/x86_64/aorrlshC_n.asm
+@@ -158,3 +158,4 @@ ifelse(ADDSUB,add,`
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aorrlsh_n.asm b/mpn/x86_64/aorrlsh_n.asm
+index 5ca128fbf..57f0e77d3 100644
+--- a/mpn/x86_64/aorrlsh_n.asm
++++ b/mpn/x86_64/aorrlsh_n.asm
+@@ -174,3 +174,4 @@ L(end):	add	R32(%rbx), R32(%rbx)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aors_err1_n.asm b/mpn/x86_64/aors_err1_n.asm
+index 54d0b3f9b..8c42ea197 100644
+--- a/mpn/x86_64/aors_err1_n.asm
++++ b/mpn/x86_64/aors_err1_n.asm
+@@ -223,3 +223,4 @@ L(end):
+ 	pop	%rbx
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aors_err2_n.asm b/mpn/x86_64/aors_err2_n.asm
+index ce5c2a49b..0227e5db5 100644
+--- a/mpn/x86_64/aors_err2_n.asm
++++ b/mpn/x86_64/aors_err2_n.asm
+@@ -170,3 +170,4 @@ L(end):
+ 	pop	%rbx
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aors_err3_n.asm b/mpn/x86_64/aors_err3_n.asm
+index bb6d0c536..37047db1f 100644
+--- a/mpn/x86_64/aors_err3_n.asm
++++ b/mpn/x86_64/aors_err3_n.asm
+@@ -154,3 +154,4 @@ L(end):
+ 	pop	%rbx
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aors_n.asm b/mpn/x86_64/aors_n.asm
+index 8941f7a17..ba23c14ef 100644
+--- a/mpn/x86_64/aors_n.asm
++++ b/mpn/x86_64/aors_n.asm
+@@ -167,3 +167,4 @@ L(end):	lea	32(up), up
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/aorsmul_1.asm b/mpn/x86_64/aorsmul_1.asm
+index e3fc00575..4031a2126 100644
+--- a/mpn/x86_64/aorsmul_1.asm
++++ b/mpn/x86_64/aorsmul_1.asm
+@@ -178,3 +178,4 @@ IFDOS(``pop	%rdi		'')
+ IFDOS(``pop	%rsi		'')
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/addmul_2.asm b/mpn/x86_64/atom/addmul_2.asm
+index c1dcdc44a..c1d945189 100644
+--- a/mpn/x86_64/atom/addmul_2.asm
++++ b/mpn/x86_64/atom/addmul_2.asm
+@@ -184,3 +184,4 @@ L(end):	mul	v1
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/aorrlsh1_n.asm b/mpn/x86_64/atom/aorrlsh1_n.asm
+index f44de19fe..693a302b8 100644
+--- a/mpn/x86_64/atom/aorrlsh1_n.asm
++++ b/mpn/x86_64/atom/aorrlsh1_n.asm
+@@ -236,3 +236,4 @@ IFDOS(`	mov	56(%rsp), %r8	')
+ 	sbb	R32(%rbp), R32(%rbp)	C save acy
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/aorrlsh2_n.asm b/mpn/x86_64/atom/aorrlsh2_n.asm
+index 02fb29dd7..c6ded740a 100644
+--- a/mpn/x86_64/atom/aorrlsh2_n.asm
++++ b/mpn/x86_64/atom/aorrlsh2_n.asm
+@@ -189,3 +189,4 @@ ifdef(`OPERATION_rsblsh2_n',`
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/lshift.asm b/mpn/x86_64/atom/lshift.asm
+index 1b37d5dcc..894b912cf 100644
+--- a/mpn/x86_64/atom/lshift.asm
++++ b/mpn/x86_64/atom/lshift.asm
+@@ -121,3 +121,4 @@ L(end):	shl	R8(%rcx), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/lshiftc.asm b/mpn/x86_64/atom/lshiftc.asm
+index 7385f8fd4..40d8fff05 100644
+--- a/mpn/x86_64/atom/lshiftc.asm
++++ b/mpn/x86_64/atom/lshiftc.asm
+@@ -125,3 +125,4 @@ L(end):	shl	R8(%rcx), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/mul_2.asm b/mpn/x86_64/atom/mul_2.asm
+index f3fc3afdd..faa4be552 100644
+--- a/mpn/x86_64/atom/mul_2.asm
++++ b/mpn/x86_64/atom/mul_2.asm
+@@ -184,3 +184,4 @@ L(end):	mul	v1
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/rsh1aors_n.asm b/mpn/x86_64/atom/rsh1aors_n.asm
+index 6f5f6384a..f3952c073 100644
+--- a/mpn/x86_64/atom/rsh1aors_n.asm
++++ b/mpn/x86_64/atom/rsh1aors_n.asm
+@@ -285,3 +285,4 @@ L(cj1):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/rshift.asm b/mpn/x86_64/atom/rshift.asm
+index 29c027de4..f4c59e113 100644
+--- a/mpn/x86_64/atom/rshift.asm
++++ b/mpn/x86_64/atom/rshift.asm
+@@ -119,3 +119,4 @@ L(end):	shr	R8(cnt), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/atom/sublsh1_n.asm b/mpn/x86_64/atom/sublsh1_n.asm
+index 1306acde2..762e1ee85 100644
+--- a/mpn/x86_64/atom/sublsh1_n.asm
++++ b/mpn/x86_64/atom/sublsh1_n.asm
+@@ -240,3 +240,4 @@ IFDOS(`	mov	56(%rsp), %r8	')
+ 	sbb	R32(%rbp), R32(%rbp)	C save acy
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bd1/mul_2.asm b/mpn/x86_64/bd1/mul_2.asm
+index 4ed5f3056..293847cd3 100644
+--- a/mpn/x86_64/bd1/mul_2.asm
++++ b/mpn/x86_64/bd1/mul_2.asm
+@@ -190,3 +190,4 @@ L(end):	mov	-8(up,n,8), %rax
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bd1/mul_basecase.asm b/mpn/x86_64/bd1/mul_basecase.asm
+index e47ba587c..ebae74dc6 100644
+--- a/mpn/x86_64/bd1/mul_basecase.asm
++++ b/mpn/x86_64/bd1/mul_basecase.asm
+@@ -414,3 +414,4 @@ L(ret2):pop	%rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bdiv_dbm1c.asm b/mpn/x86_64/bdiv_dbm1c.asm
+index a53bd52be..c383ee3d2 100644
+--- a/mpn/x86_64/bdiv_dbm1c.asm
++++ b/mpn/x86_64/bdiv_dbm1c.asm
+@@ -104,3 +104,4 @@ L(lo1):	sub	%rax, %r8
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bdiv_q_1.asm b/mpn/x86_64/bdiv_q_1.asm
+index 02eacbe6a..ebd73a7c9 100644
+--- a/mpn/x86_64/bdiv_q_1.asm
++++ b/mpn/x86_64/bdiv_q_1.asm
+@@ -165,3 +165,4 @@ L(one):	shr	R8(%rcx), %rax
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/aors_n.asm b/mpn/x86_64/bobcat/aors_n.asm
+index 22287b855..e23b1e7d1 100644
+--- a/mpn/x86_64/bobcat/aors_n.asm
++++ b/mpn/x86_64/bobcat/aors_n.asm
+@@ -148,3 +148,4 @@ PROLOGUE(func_nc)
+ IFDOS(`	mov	56(%rsp), %r8	')
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/aorsmul_1.asm b/mpn/x86_64/bobcat/aorsmul_1.asm
+index 415a17cb7..4ba09f387 100644
+--- a/mpn/x86_64/bobcat/aorsmul_1.asm
++++ b/mpn/x86_64/bobcat/aorsmul_1.asm
+@@ -181,3 +181,4 @@ IFDOS(`	pop	%rdi		')
+ IFDOS(`	pop	%rsi		')
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/copyd.asm b/mpn/x86_64/bobcat/copyd.asm
+index 877714e90..23fb80b3a 100644
+--- a/mpn/x86_64/bobcat/copyd.asm
++++ b/mpn/x86_64/bobcat/copyd.asm
+@@ -89,3 +89,4 @@ L(end):	cmp	$-4, R32(n)
+ L(ret):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/copyi.asm b/mpn/x86_64/bobcat/copyi.asm
+index ee0f57865..25718e642 100644
+--- a/mpn/x86_64/bobcat/copyi.asm
++++ b/mpn/x86_64/bobcat/copyi.asm
+@@ -92,3 +92,4 @@ L(end):	cmp	$4, R32(n)
+ L(ret):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/mul_1.asm b/mpn/x86_64/bobcat/mul_1.asm
+index ab428a88a..0ef142755 100644
+--- a/mpn/x86_64/bobcat/mul_1.asm
++++ b/mpn/x86_64/bobcat/mul_1.asm
+@@ -185,3 +185,4 @@ IFDOS(`	pop	%rdi		')
+ IFDOS(`	pop	%rsi		')
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/mul_basecase.asm b/mpn/x86_64/bobcat/mul_basecase.asm
+index e7d46bfcf..17261909c 100644
+--- a/mpn/x86_64/bobcat/mul_basecase.asm
++++ b/mpn/x86_64/bobcat/mul_basecase.asm
+@@ -484,3 +484,4 @@ L(ret):	pop	%r13
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/bobcat/sqr_basecase.asm b/mpn/x86_64/bobcat/sqr_basecase.asm
+index 0e417a1eb..8f665d1db 100644
+--- a/mpn/x86_64/bobcat/sqr_basecase.asm
++++ b/mpn/x86_64/bobcat/sqr_basecase.asm
+@@ -563,3 +563,4 @@ L(esd):	add	%rbx, w0
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/cnd_aors_n.asm b/mpn/x86_64/cnd_aors_n.asm
+index 13a2ab3be..b720ecbab 100644
+--- a/mpn/x86_64/cnd_aors_n.asm
++++ b/mpn/x86_64/cnd_aors_n.asm
+@@ -181,3 +181,4 @@ L(end):	neg	R32(%rax)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/com.asm b/mpn/x86_64/com.asm
+index 006acaf64..ec72e1912 100644
+--- a/mpn/x86_64/com.asm
++++ b/mpn/x86_64/com.asm
+@@ -93,3 +93,4 @@ L(e10):	movq	24(up,n,8), %r9
+ L(ret):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/copyd.asm b/mpn/x86_64/copyd.asm
+index a5e6e595e..02ab53f1b 100644
+--- a/mpn/x86_64/copyd.asm
++++ b/mpn/x86_64/copyd.asm
+@@ -91,3 +91,4 @@ L(end):	shr	R32(n)
+ 	mov	%r9, -16(rp)
+ 1:	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/copyi.asm b/mpn/x86_64/copyi.asm
+index bafce7a09..8c6dbdcf7 100644
+--- a/mpn/x86_64/copyi.asm
++++ b/mpn/x86_64/copyi.asm
+@@ -90,3 +90,4 @@ L(end):	shr	R32(n)
+ 	mov	%r9, 16(rp)
+ 1:	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/aors_err1_n.asm b/mpn/x86_64/core2/aors_err1_n.asm
+index 3f875aefa..c9c6c366f 100644
+--- a/mpn/x86_64/core2/aors_err1_n.asm
++++ b/mpn/x86_64/core2/aors_err1_n.asm
+@@ -223,3 +223,4 @@ L(end):
+ 	pop	%rbx
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/aors_n.asm b/mpn/x86_64/core2/aors_n.asm
+index 74a1bce48..62f58474f 100644
+--- a/mpn/x86_64/core2/aors_n.asm
++++ b/mpn/x86_64/core2/aors_n.asm
+@@ -138,4 +138,4 @@ PROLOGUE(func_nc)
+ IFDOS(`	mov	56(%rsp), %r8	')
+ 	jmp	L(start)
+ EPILOGUE()
+-
++ASM_END()
+diff --git a/mpn/x86_64/core2/aorsmul_1.asm b/mpn/x86_64/core2/aorsmul_1.asm
+index 6b313dd83..556c97f5d 100644
+--- a/mpn/x86_64/core2/aorsmul_1.asm
++++ b/mpn/x86_64/core2/aorsmul_1.asm
+@@ -176,3 +176,4 @@ L(n1):	mov	8(rp), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/divrem_1.asm b/mpn/x86_64/core2/divrem_1.asm
+index 1b3f1394e..d41c49441 100644
+--- a/mpn/x86_64/core2/divrem_1.asm
++++ b/mpn/x86_64/core2/divrem_1.asm
+@@ -241,3 +241,4 @@ L(ret):	pop	%rbx
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/gcd_1.asm b/mpn/x86_64/core2/gcd_1.asm
+index bdb940c3a..be1ee24a3 100644
+--- a/mpn/x86_64/core2/gcd_1.asm
++++ b/mpn/x86_64/core2/gcd_1.asm
+@@ -144,3 +144,4 @@ L(end):	pop	%rcx
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/lshift.asm b/mpn/x86_64/core2/lshift.asm
+index 8ccafeca6..f28a31162 100644
+--- a/mpn/x86_64/core2/lshift.asm
++++ b/mpn/x86_64/core2/lshift.asm
+@@ -147,3 +147,4 @@ L(end):	shld	R8(cnt), %r8, %r11
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/lshiftc.asm b/mpn/x86_64/core2/lshiftc.asm
+index 65c7b2f1b..02892e67d 100644
+--- a/mpn/x86_64/core2/lshiftc.asm
++++ b/mpn/x86_64/core2/lshiftc.asm
+@@ -157,3 +157,4 @@ L(end):	shld	R8(cnt), %r8, %r11
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/mul_basecase.asm b/mpn/x86_64/core2/mul_basecase.asm
+index d16be852f..8a184330b 100644
+--- a/mpn/x86_64/core2/mul_basecase.asm
++++ b/mpn/x86_64/core2/mul_basecase.asm
+@@ -973,3 +973,4 @@ L(lo3):	mul	v0
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/mullo_basecase.asm b/mpn/x86_64/core2/mullo_basecase.asm
+index 0f03d867f..11814d520 100644
+--- a/mpn/x86_64/core2/mullo_basecase.asm
++++ b/mpn/x86_64/core2/mullo_basecase.asm
+@@ -425,3 +425,4 @@ L(n3):	mov	(vp_param), %r9
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/rsh1aors_n.asm b/mpn/x86_64/core2/rsh1aors_n.asm
+index 27eed3712..5b4fe7ea4 100644
+--- a/mpn/x86_64/core2/rsh1aors_n.asm
++++ b/mpn/x86_64/core2/rsh1aors_n.asm
+@@ -167,3 +167,4 @@ L(end):	shrd	$1, %rbx, %rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/rshift.asm b/mpn/x86_64/core2/rshift.asm
+index ab32ec85d..b0ff7018e 100644
+--- a/mpn/x86_64/core2/rshift.asm
++++ b/mpn/x86_64/core2/rshift.asm
+@@ -145,3 +145,4 @@ L(end):	shrd	R8(cnt), %r8, %r11
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/sqr_basecase.asm b/mpn/x86_64/core2/sqr_basecase.asm
+index a112c1b52..65286b0fc 100644
+--- a/mpn/x86_64/core2/sqr_basecase.asm
++++ b/mpn/x86_64/core2/sqr_basecase.asm
+@@ -982,3 +982,4 @@ L(n3):	mov	%rax, %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/core2/sublshC_n.asm b/mpn/x86_64/core2/sublshC_n.asm
+index 5acc46b03..d73bd44d0 100644
+--- a/mpn/x86_64/core2/sublshC_n.asm
++++ b/mpn/x86_64/core2/sublshC_n.asm
+@@ -156,3 +156,4 @@ L(end):	shr	$RSH, %r11
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreibwl/mul_basecase.asm b/mpn/x86_64/coreibwl/mul_basecase.asm
+index 50f3ce587..d33f14b48 100644
+--- a/mpn/x86_64/coreibwl/mul_basecase.asm
++++ b/mpn/x86_64/coreibwl/mul_basecase.asm
+@@ -365,3 +365,4 @@ L(atab):JMPENT(	L(f0), L(atab))
+ 	JMPENT(	L(f7), L(atab))
+ 	TEXT
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreibwl/sqr_basecase.asm b/mpn/x86_64/coreibwl/sqr_basecase.asm
+index 447ba00e4..f55b6fcd4 100644
+--- a/mpn/x86_64/coreibwl/sqr_basecase.asm
++++ b/mpn/x86_64/coreibwl/sqr_basecase.asm
+@@ -838,3 +838,4 @@ L(atab):JMPENT(	L(f6), L(atab))
+ 	JMPENT(	L(f5), L(atab))
+ 	TEXT
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/addmul_2.asm b/mpn/x86_64/coreihwl/addmul_2.asm
+index 54aebc888..b47175dff 100644
+--- a/mpn/x86_64/coreihwl/addmul_2.asm
++++ b/mpn/x86_64/coreihwl/addmul_2.asm
+@@ -236,3 +236,4 @@ L(end):	mulx(	v0, %rax, w3)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/aorsmul_1.asm b/mpn/x86_64/coreihwl/aorsmul_1.asm
+index fd5a26d00..a266f04f1 100644
+--- a/mpn/x86_64/coreihwl/aorsmul_1.asm
++++ b/mpn/x86_64/coreihwl/aorsmul_1.asm
+@@ -196,3 +196,4 @@ L(ret):	pop	%r13
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/mul_2.asm b/mpn/x86_64/coreihwl/mul_2.asm
+index 5bdb1aa64..e5bd936d8 100644
+--- a/mpn/x86_64/coreihwl/mul_2.asm
++++ b/mpn/x86_64/coreihwl/mul_2.asm
+@@ -171,3 +171,4 @@ L(end):	mulx(	v1, %rdx, %rax)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/mul_basecase.asm b/mpn/x86_64/coreihwl/mul_basecase.asm
+index b2656c8e9..14826e823 100644
+--- a/mpn/x86_64/coreihwl/mul_basecase.asm
++++ b/mpn/x86_64/coreihwl/mul_basecase.asm
+@@ -439,3 +439,4 @@ L(ret2):pop	%rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/mullo_basecase.asm b/mpn/x86_64/coreihwl/mullo_basecase.asm
+index 9986e8bcf..7903f8cf0 100644
+--- a/mpn/x86_64/coreihwl/mullo_basecase.asm
++++ b/mpn/x86_64/coreihwl/mullo_basecase.asm
+@@ -424,3 +424,4 @@ L(n3):	mov	(vp), %r9
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/redc_1.asm b/mpn/x86_64/coreihwl/redc_1.asm
+index b1d6c0a7d..3b09a73d1 100644
+--- a/mpn/x86_64/coreihwl/redc_1.asm
++++ b/mpn/x86_64/coreihwl/redc_1.asm
+@@ -435,3 +435,4 @@ L(ret):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreihwl/sqr_basecase.asm b/mpn/x86_64/coreihwl/sqr_basecase.asm
+index 641cdf349..b6ea890c1 100644
+--- a/mpn/x86_64/coreihwl/sqr_basecase.asm
++++ b/mpn/x86_64/coreihwl/sqr_basecase.asm
+@@ -504,3 +504,4 @@ L(dend):adc	%rbx, %rdx
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreinhm/aorrlsh_n.asm b/mpn/x86_64/coreinhm/aorrlsh_n.asm
+index eed64e701..3f25eea2b 100644
+--- a/mpn/x86_64/coreinhm/aorrlsh_n.asm
++++ b/mpn/x86_64/coreinhm/aorrlsh_n.asm
+@@ -198,3 +198,4 @@ IFDOS(`	mov	64(%rsp), %r9	')	C cy
+ 	sbb	R32(%rbx), R32(%rbx)	C initialise CF save register
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/addmul_2.asm b/mpn/x86_64/coreisbr/addmul_2.asm
+index 21f0bf465..45c7b15cb 100644
+--- a/mpn/x86_64/coreisbr/addmul_2.asm
++++ b/mpn/x86_64/coreisbr/addmul_2.asm
+@@ -222,3 +222,4 @@ L(end):	mul	v1
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/aorrlshC_n.asm b/mpn/x86_64/coreisbr/aorrlshC_n.asm
+index 23ace4188..6af7da8ad 100644
+--- a/mpn/x86_64/coreisbr/aorrlshC_n.asm
++++ b/mpn/x86_64/coreisbr/aorrlshC_n.asm
+@@ -171,3 +171,4 @@ L(end):	shr	$RSH, %rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/aorrlsh_n.asm b/mpn/x86_64/coreisbr/aorrlsh_n.asm
+index db8ee6884..56ca4979f 100644
+--- a/mpn/x86_64/coreisbr/aorrlsh_n.asm
++++ b/mpn/x86_64/coreisbr/aorrlsh_n.asm
+@@ -213,3 +213,4 @@ IFDOS(`	mov	64(%rsp), %r9	')	C cy
+ 	sbb	R32(%rbx), R32(%rbx)	C initialise CF save register
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/aors_n.asm b/mpn/x86_64/coreisbr/aors_n.asm
+index 01abf78a0..930fd7d8b 100644
+--- a/mpn/x86_64/coreisbr/aors_n.asm
++++ b/mpn/x86_64/coreisbr/aors_n.asm
+@@ -196,3 +196,4 @@ PROLOGUE(func_nc)
+ IFDOS(`	mov	56(%rsp), %r8	')
+ 	jmp	L(ent)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/mul_1.asm b/mpn/x86_64/coreisbr/mul_1.asm
+index ded7d899c..11d6ea009 100644
+--- a/mpn/x86_64/coreisbr/mul_1.asm
++++ b/mpn/x86_64/coreisbr/mul_1.asm
+@@ -159,3 +159,4 @@ IFDOS(``pop	%rdi		'')
+ IFDOS(``pop	%rsi		'')
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/mul_2.asm b/mpn/x86_64/coreisbr/mul_2.asm
+index ffee78a38..5b9a0b40b 100644
+--- a/mpn/x86_64/coreisbr/mul_2.asm
++++ b/mpn/x86_64/coreisbr/mul_2.asm
+@@ -161,3 +161,4 @@ L(end):	mul	v0
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/mul_basecase.asm b/mpn/x86_64/coreisbr/mul_basecase.asm
+index 35fd1cc00..d5c7e5b43 100644
+--- a/mpn/x86_64/coreisbr/mul_basecase.asm
++++ b/mpn/x86_64/coreisbr/mul_basecase.asm
+@@ -405,3 +405,4 @@ L(ret2):pop	%rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/mullo_basecase.asm b/mpn/x86_64/coreisbr/mullo_basecase.asm
+index a41a8acee..acf7776ac 100644
+--- a/mpn/x86_64/coreisbr/mullo_basecase.asm
++++ b/mpn/x86_64/coreisbr/mullo_basecase.asm
+@@ -382,3 +382,4 @@ L(n3):	mov	(vp_param), %r9
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/popcount.asm b/mpn/x86_64/coreisbr/popcount.asm
+index a5be33e6a..ef532a959 100644
+--- a/mpn/x86_64/coreisbr/popcount.asm
++++ b/mpn/x86_64/coreisbr/popcount.asm
+@@ -116,3 +116,4 @@ L(cj1):	add	%r11, %rax
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/rsh1aors_n.asm b/mpn/x86_64/coreisbr/rsh1aors_n.asm
+index fd2eaea7b..eefad99ae 100644
+--- a/mpn/x86_64/coreisbr/rsh1aors_n.asm
++++ b/mpn/x86_64/coreisbr/rsh1aors_n.asm
+@@ -191,3 +191,4 @@ L(end):	shrd	$1, %rbx, %rbp
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/coreisbr/sqr_basecase.asm b/mpn/x86_64/coreisbr/sqr_basecase.asm
+index 46a36121f..1600e2552 100644
+--- a/mpn/x86_64/coreisbr/sqr_basecase.asm
++++ b/mpn/x86_64/coreisbr/sqr_basecase.asm
+@@ -482,3 +482,4 @@ L(dend):add	%r8, %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/div_qr_1n_pi1.asm b/mpn/x86_64/div_qr_1n_pi1.asm
+index cb072e979..6232d84d4 100644
+--- a/mpn/x86_64/div_qr_1n_pi1.asm
++++ b/mpn/x86_64/div_qr_1n_pi1.asm
+@@ -245,3 +245,4 @@ L(q_incr_loop):
+ 	lea	8(U1), U1
+ 	jmp	L(q_incr_loop)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/div_qr_2n_pi1.asm b/mpn/x86_64/div_qr_2n_pi1.asm
+index 5e59a0ac5..c189c33bb 100644
+--- a/mpn/x86_64/div_qr_2n_pi1.asm
++++ b/mpn/x86_64/div_qr_2n_pi1.asm
+@@ -156,3 +156,4 @@ L(fix):	C Unlikely update. u2 >= d1
+ 	sbb	d1, u2
+ 	jmp	L(bck)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/div_qr_2u_pi1.asm b/mpn/x86_64/div_qr_2u_pi1.asm
+index 85af96fbf..f2ac526a5 100644
+--- a/mpn/x86_64/div_qr_2u_pi1.asm
++++ b/mpn/x86_64/div_qr_2u_pi1.asm
+@@ -198,3 +198,4 @@ L(fix_qh):	C Unlikely update. u2 >= d1
+ 	sbb	d1, u2
+ 	jmp	L(bck_qh)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/dive_1.asm b/mpn/x86_64/dive_1.asm
+index 988bdab63..1929091b8 100644
+--- a/mpn/x86_64/dive_1.asm
++++ b/mpn/x86_64/dive_1.asm
+@@ -156,3 +156,4 @@ L(one):	shr	R8(%rcx), %rax
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/divrem_1.asm b/mpn/x86_64/divrem_1.asm
+index d4d61ad9d..edfd89351 100644
+--- a/mpn/x86_64/divrem_1.asm
++++ b/mpn/x86_64/divrem_1.asm
+@@ -312,3 +312,4 @@ L(ret):	pop	%rbx
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/divrem_2.asm b/mpn/x86_64/divrem_2.asm
+index 296c9b673..88dd83a8b 100644
+--- a/mpn/x86_64/divrem_2.asm
++++ b/mpn/x86_64/divrem_2.asm
+@@ -188,3 +188,4 @@ L(fix):	seta	%dl
+ 	sbb	%r11, %rbx
+ 	jmp	L(bck)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastavx/copyd.asm b/mpn/x86_64/fastavx/copyd.asm
+index 56d472f83..a69a62430 100644
+--- a/mpn/x86_64/fastavx/copyd.asm
++++ b/mpn/x86_64/fastavx/copyd.asm
+@@ -170,3 +170,4 @@ L(bc):	test	$4, R8(n)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastavx/copyi.asm b/mpn/x86_64/fastavx/copyi.asm
+index 760774797..f50aa4717 100644
+--- a/mpn/x86_64/fastavx/copyi.asm
++++ b/mpn/x86_64/fastavx/copyi.asm
+@@ -167,3 +167,4 @@ L(bc):	test	$4, R8(n)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/com-palignr.asm b/mpn/x86_64/fastsse/com-palignr.asm
+index c7155d115..c0df12693 100644
+--- a/mpn/x86_64/fastsse/com-palignr.asm
++++ b/mpn/x86_64/fastsse/com-palignr.asm
+@@ -308,3 +308,4 @@ L(end):	test	$1, R8(n)
+ 1:	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/com.asm b/mpn/x86_64/fastsse/com.asm
+index 307fb7537..d45bc4693 100644
+--- a/mpn/x86_64/fastsse/com.asm
++++ b/mpn/x86_64/fastsse/com.asm
+@@ -165,3 +165,4 @@ L(sma):	add	$14, n
+ L(don):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/copyd-palignr.asm b/mpn/x86_64/fastsse/copyd-palignr.asm
+index fac6f8a83..fa1e4a4cf 100644
+--- a/mpn/x86_64/fastsse/copyd-palignr.asm
++++ b/mpn/x86_64/fastsse/copyd-palignr.asm
+@@ -252,3 +252,4 @@ L(end):	test	$1, R8(n)
+ 1:	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/copyd.asm b/mpn/x86_64/fastsse/copyd.asm
+index 5b8b8bf5c..45c0ceccf 100644
+--- a/mpn/x86_64/fastsse/copyd.asm
++++ b/mpn/x86_64/fastsse/copyd.asm
+@@ -156,3 +156,4 @@ L(sma):	test	$8, R8(n)
+ L(don):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/copyi-palignr.asm b/mpn/x86_64/fastsse/copyi-palignr.asm
+index 22f13f1d8..30b8333be 100644
+--- a/mpn/x86_64/fastsse/copyi-palignr.asm
++++ b/mpn/x86_64/fastsse/copyi-palignr.asm
+@@ -296,3 +296,4 @@ L(end):	test	$1, R8(n)
+ 1:	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/copyi.asm b/mpn/x86_64/fastsse/copyi.asm
+index b2f3b9ddb..08eaf93a1 100644
+--- a/mpn/x86_64/fastsse/copyi.asm
++++ b/mpn/x86_64/fastsse/copyi.asm
+@@ -175,3 +175,4 @@ dnl	jnc	1b
+ L(ret):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/lshift-movdqu2.asm b/mpn/x86_64/fastsse/lshift-movdqu2.asm
+index a05e850a1..217f2cdef 100644
+--- a/mpn/x86_64/fastsse/lshift-movdqu2.asm
++++ b/mpn/x86_64/fastsse/lshift-movdqu2.asm
+@@ -180,3 +180,4 @@ L(end8):movq	(ap), %xmm0
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/lshift.asm b/mpn/x86_64/fastsse/lshift.asm
+index f76972a22..94d1098d3 100644
+--- a/mpn/x86_64/fastsse/lshift.asm
++++ b/mpn/x86_64/fastsse/lshift.asm
+@@ -167,3 +167,4 @@ L(end8):movq	(ap), %xmm0
+ 	movq	%xmm0, (rp)
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/lshiftc-movdqu2.asm b/mpn/x86_64/fastsse/lshiftc-movdqu2.asm
+index 8250910c5..9f144358b 100644
+--- a/mpn/x86_64/fastsse/lshiftc-movdqu2.asm
++++ b/mpn/x86_64/fastsse/lshiftc-movdqu2.asm
+@@ -191,3 +191,4 @@ L(end8):movq	(ap), %xmm0
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/lshiftc.asm b/mpn/x86_64/fastsse/lshiftc.asm
+index d2520690e..2f798254b 100644
+--- a/mpn/x86_64/fastsse/lshiftc.asm
++++ b/mpn/x86_64/fastsse/lshiftc.asm
+@@ -177,3 +177,4 @@ L(end8):movq	(ap), %xmm0
+ 	movq	%xmm0, (rp)
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/rshift-movdqu2.asm b/mpn/x86_64/fastsse/rshift-movdqu2.asm
+index 1e270b13c..15bcc0271 100644
+--- a/mpn/x86_64/fastsse/rshift-movdqu2.asm
++++ b/mpn/x86_64/fastsse/rshift-movdqu2.asm
+@@ -199,3 +199,4 @@ L(bc):	dec	R32(n)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fastsse/sec_tabselect.asm b/mpn/x86_64/fastsse/sec_tabselect.asm
+index e3df110be..e6f9b64d2 100644
+--- a/mpn/x86_64/fastsse/sec_tabselect.asm
++++ b/mpn/x86_64/fastsse/sec_tabselect.asm
+@@ -190,3 +190,4 @@ L(tp1):	movdqa	%xmm8, %xmm0
+ L(b000):FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/fat/fat_entry.asm b/mpn/x86_64/fat/fat_entry.asm
+index 8f7599dd5..799b64dd4 100644
+--- a/mpn/x86_64/fat/fat_entry.asm
++++ b/mpn/x86_64/fat/fat_entry.asm
+@@ -205,3 +205,4 @@ PROLOGUE(__gmpn_cpuid)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/gcd_1.asm b/mpn/x86_64/gcd_1.asm
+index ac4aceddc..e08c0725c 100644
+--- a/mpn/x86_64/gcd_1.asm
++++ b/mpn/x86_64/gcd_1.asm
+@@ -163,3 +163,4 @@ L(shift_alot):
+ 	mov	%rax, %rcx
+ 	jmp	L(mid)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k10/hamdist.asm b/mpn/x86_64/k10/hamdist.asm
+index 44b67b5e4..a71be47b3 100644
+--- a/mpn/x86_64/k10/hamdist.asm
++++ b/mpn/x86_64/k10/hamdist.asm
+@@ -101,3 +101,4 @@ L(top):	mov	(ap,n,8), %r8
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k10/popcount.asm b/mpn/x86_64/k10/popcount.asm
+index 3814aeabf..735d25a30 100644
+--- a/mpn/x86_64/k10/popcount.asm
++++ b/mpn/x86_64/k10/popcount.asm
+@@ -136,3 +136,4 @@ C 1 = n mod 8
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/aorrlsh_n.asm b/mpn/x86_64/k8/aorrlsh_n.asm
+index ff3a1842f..3ab7050b0 100644
+--- a/mpn/x86_64/k8/aorrlsh_n.asm
++++ b/mpn/x86_64/k8/aorrlsh_n.asm
+@@ -215,3 +215,4 @@ L(cj1):	mov	%r9, 8(rp,n,8)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/div_qr_1n_pi1.asm b/mpn/x86_64/k8/div_qr_1n_pi1.asm
+index 861402b22..a3d3dd869 100644
+--- a/mpn/x86_64/k8/div_qr_1n_pi1.asm
++++ b/mpn/x86_64/k8/div_qr_1n_pi1.asm
+@@ -247,3 +247,4 @@ L(q_incr_loop):
+ 	lea	8(U1), U1
+ 	jmp	L(q_incr_loop)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/mul_basecase.asm b/mpn/x86_64/k8/mul_basecase.asm
+index ca2efb9b2..8b114ce8b 100644
+--- a/mpn/x86_64/k8/mul_basecase.asm
++++ b/mpn/x86_64/k8/mul_basecase.asm
+@@ -467,3 +467,4 @@ L(ret):	pop	%r15
+ 	ret
+ 
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/mullo_basecase.asm b/mpn/x86_64/k8/mullo_basecase.asm
+index fa00f4234..fc6a4396d 100644
+--- a/mpn/x86_64/k8/mullo_basecase.asm
++++ b/mpn/x86_64/k8/mullo_basecase.asm
+@@ -434,3 +434,4 @@ L(ret):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/mulmid_basecase.asm b/mpn/x86_64/k8/mulmid_basecase.asm
+index 86f1414ed..d7d1f27c6 100644
+--- a/mpn/x86_64/k8/mulmid_basecase.asm
++++ b/mpn/x86_64/k8/mulmid_basecase.asm
+@@ -557,3 +557,4 @@ L(ret):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/redc_1.asm b/mpn/x86_64/k8/redc_1.asm
+index 9327b21b1..4cb65af49 100644
+--- a/mpn/x86_64/k8/redc_1.asm
++++ b/mpn/x86_64/k8/redc_1.asm
+@@ -589,3 +589,4 @@ L(ret):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/k8/sqr_basecase.asm b/mpn/x86_64/k8/sqr_basecase.asm
+index 60cf945a4..f2c70b06b 100644
+--- a/mpn/x86_64/k8/sqr_basecase.asm
++++ b/mpn/x86_64/k8/sqr_basecase.asm
+@@ -805,3 +805,4 @@ L(d1):	mov	%r11, 24(rp,j,8)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/logops_n.asm b/mpn/x86_64/logops_n.asm
+index b277f5896..cb20cf9e5 100644
+--- a/mpn/x86_64/logops_n.asm
++++ b/mpn/x86_64/logops_n.asm
+@@ -242,3 +242,4 @@ L(ret):	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
+ ')
++ASM_END()
+diff --git a/mpn/x86_64/lshift.asm b/mpn/x86_64/lshift.asm
+index f368944b8..60e84414a 100644
+--- a/mpn/x86_64/lshift.asm
++++ b/mpn/x86_64/lshift.asm
+@@ -245,3 +245,4 @@ L(ast):	mov	(up), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/lshiftc.asm b/mpn/x86_64/lshiftc.asm
+index c4ba04a17..f6fe4c9b6 100644
+--- a/mpn/x86_64/lshiftc.asm
++++ b/mpn/x86_64/lshiftc.asm
+@@ -180,3 +180,4 @@ L(ast):	mov	(up), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/lshsub_n.asm b/mpn/x86_64/lshsub_n.asm
+index 4d428c0bd..62877d781 100644
+--- a/mpn/x86_64/lshsub_n.asm
++++ b/mpn/x86_64/lshsub_n.asm
+@@ -170,3 +170,4 @@ L(end):
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/missing.asm b/mpn/x86_64/missing.asm
+index 9b65c89dd..22dac17f0 100644
+--- a/mpn/x86_64/missing.asm
++++ b/mpn/x86_64/missing.asm
+@@ -128,3 +128,4 @@ PROLOGUE(__gmp_adcx)
+ 	ret
+ EPILOGUE()
+ PROTECT(__gmp_adcx)
++ASM_END()
+diff --git a/mpn/x86_64/mod_1_2.asm b/mpn/x86_64/mod_1_2.asm
+index 09d856e6e..c102072ad 100644
+--- a/mpn/x86_64/mod_1_2.asm
++++ b/mpn/x86_64/mod_1_2.asm
+@@ -237,3 +237,4 @@ ifdef(`SHLD_SLOW',`
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/mod_1_4.asm b/mpn/x86_64/mod_1_4.asm
+index ae34617c7..cf8f9ec81 100644
+--- a/mpn/x86_64/mod_1_4.asm
++++ b/mpn/x86_64/mod_1_4.asm
+@@ -268,3 +268,4 @@ ifdef(`SHLD_SLOW',`
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/mod_34lsub1.asm b/mpn/x86_64/mod_34lsub1.asm
+index 62bdcfac6..065a731cc 100644
+--- a/mpn/x86_64/mod_34lsub1.asm
++++ b/mpn/x86_64/mod_34lsub1.asm
+@@ -203,3 +203,4 @@ L(0):	add	%r9, %rax
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/mode1o.asm b/mpn/x86_64/mode1o.asm
+index 2cd2b0884..3377435fc 100644
+--- a/mpn/x86_64/mode1o.asm
++++ b/mpn/x86_64/mode1o.asm
+@@ -169,3 +169,4 @@ L(one):
+ 
+ EPILOGUE(mpn_modexact_1c_odd)
+ EPILOGUE(mpn_modexact_1_odd)
++ASM_END()
+diff --git a/mpn/x86_64/mul_1.asm b/mpn/x86_64/mul_1.asm
+index b032afc9d..e3895a48f 100644
+--- a/mpn/x86_64/mul_1.asm
++++ b/mpn/x86_64/mul_1.asm
+@@ -181,3 +181,4 @@ IFDOS(``pop	%rdi		'')
+ IFDOS(``pop	%rsi		'')
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/mul_2.asm b/mpn/x86_64/mul_2.asm
+index f408c5225..03646fad9 100644
+--- a/mpn/x86_64/mul_2.asm
++++ b/mpn/x86_64/mul_2.asm
+@@ -190,3 +190,4 @@ L(m22):	mul	v1
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/nano/dive_1.asm b/mpn/x86_64/nano/dive_1.asm
+index e9a07631c..aead4d551 100644
+--- a/mpn/x86_64/nano/dive_1.asm
++++ b/mpn/x86_64/nano/dive_1.asm
+@@ -164,3 +164,4 @@ L(one):	shr	R8(%rcx), %rax
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/aors_n.asm b/mpn/x86_64/pentium4/aors_n.asm
+index 8e6ee1bae..3751e381d 100644
+--- a/mpn/x86_64/pentium4/aors_n.asm
++++ b/mpn/x86_64/pentium4/aors_n.asm
+@@ -194,3 +194,4 @@ L(ret):	mov	R32(%rbx), R32(%rax)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/lshift.asm b/mpn/x86_64/pentium4/lshift.asm
+index d3b521364..72ac197c7 100644
+--- a/mpn/x86_64/pentium4/lshift.asm
++++ b/mpn/x86_64/pentium4/lshift.asm
+@@ -164,3 +164,4 @@ L(ast):	movq	(up), %mm2
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/lshiftc.asm b/mpn/x86_64/pentium4/lshiftc.asm
+index fc6467657..45ad1e293 100644
+--- a/mpn/x86_64/pentium4/lshiftc.asm
++++ b/mpn/x86_64/pentium4/lshiftc.asm
+@@ -177,3 +177,4 @@ L(ast):	movq	(up), %mm2
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/mod_34lsub1.asm b/mpn/x86_64/pentium4/mod_34lsub1.asm
+index f34b3f079..bf83f6278 100644
+--- a/mpn/x86_64/pentium4/mod_34lsub1.asm
++++ b/mpn/x86_64/pentium4/mod_34lsub1.asm
+@@ -165,3 +165,4 @@ L(combine):
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/rsh1aors_n.asm b/mpn/x86_64/pentium4/rsh1aors_n.asm
+index 5528ce47d..219a809cf 100644
+--- a/mpn/x86_64/pentium4/rsh1aors_n.asm
++++ b/mpn/x86_64/pentium4/rsh1aors_n.asm
+@@ -332,3 +332,4 @@ L(cj1):	or	%r14, %rbx
+ L(c3):	mov	$1, R8(%rax)
+ 	jmp	L(rc3)
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/pentium4/rshift.asm b/mpn/x86_64/pentium4/rshift.asm
+index b7c1ee2cd..848045f46 100644
+--- a/mpn/x86_64/pentium4/rshift.asm
++++ b/mpn/x86_64/pentium4/rshift.asm
+@@ -167,3 +167,4 @@ L(ast):	movq	(up), %mm2
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/popham.asm b/mpn/x86_64/popham.asm
+index 9005f8177..8c46c5097 100644
+--- a/mpn/x86_64/popham.asm
++++ b/mpn/x86_64/popham.asm
+@@ -175,3 +175,4 @@ L(end):
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/rsh1aors_n.asm b/mpn/x86_64/rsh1aors_n.asm
+index a3e9cc5d2..797e2507a 100644
+--- a/mpn/x86_64/rsh1aors_n.asm
++++ b/mpn/x86_64/rsh1aors_n.asm
+@@ -187,3 +187,4 @@ L(end):	mov	%rbx, (rp)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/rshift.asm b/mpn/x86_64/rshift.asm
+index 3f344f1df..0fc58775b 100644
+--- a/mpn/x86_64/rshift.asm
++++ b/mpn/x86_64/rshift.asm
+@@ -174,3 +174,4 @@ L(ast):	mov	(up), %r10
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/sec_tabselect.asm b/mpn/x86_64/sec_tabselect.asm
+index e8aed261e..5dce3c1c0 100644
+--- a/mpn/x86_64/sec_tabselect.asm
++++ b/mpn/x86_64/sec_tabselect.asm
+@@ -174,3 +174,4 @@ L(b00):	pop	%r15
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/sqr_diag_addlsh1.asm b/mpn/x86_64/sqr_diag_addlsh1.asm
+index 4ad034c85..3ea1abc31 100644
+--- a/mpn/x86_64/sqr_diag_addlsh1.asm
++++ b/mpn/x86_64/sqr_diag_addlsh1.asm
+@@ -114,3 +114,4 @@ L(end):	add	%r10, %r8
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+diff --git a/mpn/x86_64/sublsh1_n.asm b/mpn/x86_64/sublsh1_n.asm
+index c6d829fcb..c18f32a9d 100644
+--- a/mpn/x86_64/sublsh1_n.asm
++++ b/mpn/x86_64/sublsh1_n.asm
+@@ -158,3 +158,4 @@ L(end):	add	R32(%rbp), R32(%rax)
+ 	FUNC_EXIT()
+ 	ret
+ EPILOGUE()
++ASM_END()
+-- 
+2.24.1
+
diff --git a/0006-x86_64-k10-popcount.asm-Prepend-X86_NOTRACK-to-jmp-r.patch b/0006-x86_64-k10-popcount.asm-Prepend-X86_NOTRACK-to-jmp-r.patch
new file mode 100644
index 0000000..36c7e1e
--- /dev/null
+++ b/0006-x86_64-k10-popcount.asm-Prepend-X86_NOTRACK-to-jmp-r.patch
@@ -0,0 +1,41 @@
+From 7b23f9d94ab97f56717db9fea81de9a4243af58b Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Wed, 29 Jan 2020 10:58:30 -0800
+Subject: [PATCH 06/11] x86_64/k10/popcount.asm: Prepend X86_NOTRACK to "jmp
+ *%rdx"
+
+Since K10 popcount.asm uses a trick to implment jump tables with LEA,
+prepend X86_NOTRACK to "jmp *%rdx" to disable indirect branch tracking
+when Intel CET is enabled.
+
+	* mpn/x86_64/k10/popcount.asm: Prepend X86_NOTRACK to
+	"jmp *%rdx".
+---
+ mpn/x86_64/k10/popcount.asm | 4 ++--
+ 1 file changed, 2 insertions(+), 2 deletions(-)
+
+diff --git a/mpn/x86_64/k10/popcount.asm b/mpn/x86_64/k10/popcount.asm
+index 735d25a30..45bcba5b0 100644
+--- a/mpn/x86_64/k10/popcount.asm
++++ b/mpn/x86_64/k10/popcount.asm
+@@ -79,7 +79,7 @@ C	neg	R32(%rcx)
+ 
+ 	lea	L(top)(%rip), %rdx
+ 	lea	(%rdx,%rcx,2), %rdx
+-	jmp	*%rdx
++	X86_NOTRACK jmp	*%rdx
+ ',`
+ 	lea	(up,n,8), up
+ 
+@@ -101,7 +101,7 @@ C	lea	(%rcx,%rcx,4), %rcx	C 10x
+ 
+ 	lea	L(top)(%rip), %rdx
+ 	add	%rcx, %rdx
+-	jmp	*%rdx
++	X86_NOTRACK jmp	*%rdx
+ ')
+ 
+ 	ALIGN(32)
+-- 
+2.24.1
+
diff --git a/0007-mpn-x86_64-Add-X86_ENDBR-to-indirect-branch-targets.patch b/0007-mpn-x86_64-Add-X86_ENDBR-to-indirect-branch-targets.patch
new file mode 100644
index 0000000..8f6f31c
--- /dev/null
+++ b/0007-mpn-x86_64-Add-X86_ENDBR-to-indirect-branch-targets.patch
@@ -0,0 +1,851 @@
+From 28e483e6d99b49105a5beebca7f21081272d2db6 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:53:47 -0800
+Subject: [PATCH 07/11] mpn/x86_64: Add X86_ENDBR to indirect branch targets
+
+Add X86_ENDBR to indirect branch targets to support Intel CET.
+
+	* mpn/x86_64/core2/mul_basecase.asm: Add X86_ENDBR to indirect
+	branch targets.
+	* mpn/x86_64/coreibwl/addmul_1.asm: Likewise.
+	* mpn/x86_64/coreibwl/mul_1.asm: Likewise.
+	* mpn/x86_64/coreibwl/mul_basecase.asm: Likewise.
+	* mpn/x86_64/coreibwl/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/k8/mul_basecase.asm: Likewise.
+	* mpn/x86_64/k8/mullo_basecase.asm: Likewise.
+	* mpn/x86_64/k8/mulmid_basecase.asm: Likewise.
+	* mpn/x86_64/k8/redc_1.asm: Likewise.
+	* mpn/x86_64/k8/sqr_basecase.asm: Likewise.
+	* mpn/x86_64/mod_34lsub1.asm: Likewise.
+---
+ mpn/x86_64/core2/mul_basecase.asm    |  4 +++
+ mpn/x86_64/coreibwl/addmul_1.asm     | 24 +++++++++-----
+ mpn/x86_64/coreibwl/mul_1.asm        | 24 +++++++++-----
+ mpn/x86_64/coreibwl/mul_basecase.asm | 46 +++++++++++++++++---------
+ mpn/x86_64/coreibwl/sqr_basecase.asm | 48 ++++++++++++++++++----------
+ mpn/x86_64/k8/mul_basecase.asm       |  7 ++++
+ mpn/x86_64/k8/mullo_basecase.asm     | 11 +++++--
+ mpn/x86_64/k8/mulmid_basecase.asm    |  8 +++++
+ mpn/x86_64/k8/redc_1.asm             | 17 ++++++----
+ mpn/x86_64/k8/sqr_basecase.asm       | 17 +++++++---
+ mpn/x86_64/mod_34lsub1.asm           | 27 ++++++++++------
+ 11 files changed, 162 insertions(+), 71 deletions(-)
+
+diff --git a/mpn/x86_64/core2/mul_basecase.asm b/mpn/x86_64/core2/mul_basecase.asm
+index 8a184330b..0dcf0f8bf 100644
+--- a/mpn/x86_64/core2/mul_basecase.asm
++++ b/mpn/x86_64/core2/mul_basecase.asm
+@@ -347,6 +347,7 @@ L(m2e0):mul	v1
+ 	jz	L(ret2)
+ 
+ L(do_am0):
++	X86_ENDBR
+ 	push	%r15
+ 	push	vn_param
+ 
+@@ -520,6 +521,7 @@ L(m2e1):mul	v1
+ 	jz	L(ret2)
+ 
+ L(do_am1):
++	X86_ENDBR
+ 	push	%r15
+ 	push	vn_param
+ 
+@@ -693,6 +695,7 @@ L(m2e2):mul	v1
+ 	jz	L(ret2)
+ 
+ L(do_am2):
++	X86_ENDBR
+ 	push	%r15
+ 	push	vn_param
+ 
+@@ -866,6 +869,7 @@ L(m2e3):mul	v1
+ 	jz	L(ret2)
+ 
+ L(do_am3):
++	X86_ENDBR
+ 	push	%r15
+ 	push	vn_param
+ 
+diff --git a/mpn/x86_64/coreibwl/addmul_1.asm b/mpn/x86_64/coreibwl/addmul_1.asm
+index aaa58e725..5d7424a38 100644
+--- a/mpn/x86_64/coreibwl/addmul_1.asm
++++ b/mpn/x86_64/coreibwl/addmul_1.asm
+@@ -107,33 +107,39 @@ L(tab):	JMPENT(	L(f0), L(tab))
+ 	JMPENT(	L(f7), L(tab))
+ 	TEXT
+ 
+-L(f0):	mulx(	(up), %r10, %r8)
++L(f0):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	-8(up), up
+ 	lea	-8(rp), rp
+ 	lea	-1(n), n
+ 	jmp	L(b0)
+ 
+-L(f3):	mulx(	(up), %r9, %rax)
++L(f3):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	16(up), up
+ 	lea	-48(rp), rp
+ 	jmp	L(b3)
+ 
+-L(f4):	mulx(	(up), %r10, %r8)
++L(f4):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	24(up), up
+ 	lea	-40(rp), rp
+ 	jmp	L(b4)
+ 
+-L(f5):	mulx(	(up), %r9, %rax)
++L(f5):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	32(up), up
+ 	lea	-32(rp), rp
+ 	jmp	L(b5)
+ 
+-L(f6):	mulx(	(up), %r10, %r8)
++L(f6):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	40(up), up
+ 	lea	-24(rp), rp
+ 	jmp	L(b6)
+ 
+-L(f1):	mulx(	(up), %r9, %rax)
++L(f1):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	jrcxz	L(1)
+ 	jmp	L(b1)
+ L(1):	add	(rp), %r9
+@@ -151,7 +157,8 @@ ifdef(`PIC',
+ `	nop;nop;nop;nop',
+ `	nop;nop;nop;nop;nop;nop;nop;nop;nop;nop;nop')
+ 
+-L(f2):	mulx(	(up), %r10, %r8)
++L(f2):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	8(up), up
+ 	lea	8(rp), rp
+ 	mulx(	(up), %r9, %rax)
+@@ -195,7 +202,8 @@ L(b3):	adox(	48,(rp), %r9)
+ 	mulx(	(up), %r9, %rax)
+ 	jmp	L(top)
+ 
+-L(f7):	mulx(	(up), %r9, %rax)
++L(f7):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	-16(up), up
+ 	lea	-16(rp), rp
+ 	jmp	L(b7)
+diff --git a/mpn/x86_64/coreibwl/mul_1.asm b/mpn/x86_64/coreibwl/mul_1.asm
+index a271e6cc8..27fbe0b0a 100644
+--- a/mpn/x86_64/coreibwl/mul_1.asm
++++ b/mpn/x86_64/coreibwl/mul_1.asm
+@@ -106,48 +106,56 @@ L(tab):	JMPENT(	L(f0), L(tab))
+ 	JMPENT(	L(f7), L(tab))
+ 	TEXT
+ 
+-L(f0):	mulx(	(up), %r10, %r8)
++L(f0):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	56(up), up
+ 	lea	-8(rp), rp
+ 	jmp	L(b0)
+ 
+-L(f3):	mulx(	(up), %r9, %rax)
++L(f3):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	16(up), up
+ 	lea	16(rp), rp
+ 	inc	n
+ 	jmp	L(b3)
+ 
+-L(f4):	mulx(	(up), %r10, %r8)
++L(f4):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	24(up), up
+ 	lea	24(rp), rp
+ 	inc	n
+ 	jmp	L(b4)
+ 
+-L(f5):	mulx(	(up), %r9, %rax)
++L(f5):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	32(up), up
+ 	lea	32(rp), rp
+ 	inc	n
+ 	jmp	L(b5)
+ 
+-L(f6):	mulx(	(up), %r10, %r8)
++L(f6):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	40(up), up
+ 	lea	40(rp), rp
+ 	inc	n
+ 	jmp	L(b6)
+ 
+-L(f7):	mulx(	(up), %r9, %rax)
++L(f7):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	lea	48(up), up
+ 	lea	48(rp), rp
+ 	inc	n
+ 	jmp	L(b7)
+ 
+-L(f1):	mulx(	(up), %r9, %rax)
++L(f1):	X86_ENDBR
++	mulx(	(up), %r9, %rax)
+ 	test	n, n
+ 	jnz	L(b1)
+ L(1):	mov	%r9, (rp)
+ 	ret
+ 
+-L(f2):	mulx(	(up), %r10, %r8)
++L(f2):	X86_ENDBR
++	mulx(	(up), %r10, %r8)
+ 	lea	8(up), up
+ 	lea	8(rp), rp
+ 	mulx(	(up), %r9, %rax)
+diff --git a/mpn/x86_64/coreibwl/mul_basecase.asm b/mpn/x86_64/coreibwl/mul_basecase.asm
+index d33f14b48..0003faa4c 100644
+--- a/mpn/x86_64/coreibwl/mul_basecase.asm
++++ b/mpn/x86_64/coreibwl/mul_basecase.asm
+@@ -155,45 +155,53 @@ ifdef(`PIC',
+ 	jmp	*(%r10,%rax,8)
+ ')
+ 
+-L(mf0):	mulx(	(up), w2, w3)
++L(mf0):	X86_ENDBR
++	mulx(	(up), w2, w3)
+ 	lea	56(up), up
+ 	lea	-8(rp), rp
+ 	jmp	L(mb0)
+ 
+-L(mf3):	mulx(	(up), w0, w1)
++L(mf3):	X86_ENDBR
++	mulx(	(up), w0, w1)
+ 	lea	16(up), up
+ 	lea	16(rp), rp
+ 	inc	n
+ 	jmp	L(mb3)
+ 
+-L(mf4):	mulx(	(up), w2, w3)
++L(mf4):	X86_ENDBR
++	mulx(	(up), w2, w3)
+ 	lea	24(up), up
+ 	lea	24(rp), rp
+ 	inc	n
+ 	jmp	L(mb4)
+ 
+-L(mf5):	mulx(	(up), w0, w1)
++L(mf5):	X86_ENDBR
++	mulx(	(up), w0, w1)
+ 	lea	32(up), up
+ 	lea	32(rp), rp
+ 	inc	n
+ 	jmp	L(mb5)
+ 
+-L(mf6):	mulx(	(up), w2, w3)
++L(mf6):	X86_ENDBR
++	mulx(	(up), w2, w3)
+ 	lea	40(up), up
+ 	lea	40(rp), rp
+ 	inc	n
+ 	jmp	L(mb6)
+ 
+-L(mf7):	mulx(	(up), w0, w1)
++L(mf7):	X86_ENDBR
++	mulx(	(up), w0, w1)
+ 	lea	48(up), up
+ 	lea	48(rp), rp
+ 	inc	n
+ 	jmp	L(mb7)
+ 
+-L(mf1):	mulx(	(up), w0, w1)
++L(mf1):	X86_ENDBR
++	mulx(	(up), w0, w1)
+ 	jmp	L(mb1)
+ 
+-L(mf2):	mulx(	(up), w2, w3)
++L(mf2):	X86_ENDBR
++	mulx(	(up), w2, w3)
+ 	lea	8(up), up
+ 	lea	8(rp), rp
+ 	mulx(	(up), w0, w1)
+@@ -254,32 +262,39 @@ L(outer):
+ 	lea	8(vp), vp
+ 	jmp	*jaddr
+ 
+-L(f0):	mulx(	8,(up), w2, w3)
++L(f0):	X86_ENDBR
++	mulx(	8,(up), w2, w3)
+ 	lea	8(rp,unneg,8), rp
+ 	lea	-1(n), n
+ 	jmp	L(b0)
+ 
+-L(f3):	mulx(	-16,(up), w0, w1)
++L(f3):	X86_ENDBR
++	mulx(	-16,(up), w0, w1)
+ 	lea	-56(rp,unneg,8), rp
+ 	jmp	L(b3)
+ 
+-L(f4):	mulx(	-24,(up), w2, w3)
++L(f4):	X86_ENDBR
++	mulx(	-24,(up), w2, w3)
+ 	lea	-56(rp,unneg,8), rp
+ 	jmp	L(b4)
+ 
+-L(f5):	mulx(	-32,(up), w0, w1)
++L(f5):	X86_ENDBR
++	mulx(	-32,(up), w0, w1)
+ 	lea	-56(rp,unneg,8), rp
+ 	jmp	L(b5)
+ 
+-L(f6):	mulx(	-40,(up), w2, w3)
++L(f6):	X86_ENDBR
++	mulx(	-40,(up), w2, w3)
+ 	lea	-56(rp,unneg,8), rp
+ 	jmp	L(b6)
+ 
+-L(f7):	mulx(	16,(up), w0, w1)
++L(f7):	X86_ENDBR
++	mulx(	16,(up), w0, w1)
+ 	lea	8(rp,unneg,8), rp
+ 	jmp	L(b7)
+ 
+-L(f1):	mulx(	(up), w0, w1)
++L(f1):	X86_ENDBR
++	mulx(	(up), w0, w1)
+ 	lea	8(rp,unneg,8), rp
+ 	jmp	L(b1)
+ 
+@@ -301,6 +316,7 @@ L(done):
+ 	ret
+ 
+ L(f2):
++	X86_ENDBR
+ 	mulx(	-8,(up), w2, w3)
+ 	lea	8(rp,unneg,8), rp
+ 	mulx(	(up), w0, w1)
+diff --git a/mpn/x86_64/coreibwl/sqr_basecase.asm b/mpn/x86_64/coreibwl/sqr_basecase.asm
+index f55b6fcd4..ff42fe888 100644
+--- a/mpn/x86_64/coreibwl/sqr_basecase.asm
++++ b/mpn/x86_64/coreibwl/sqr_basecase.asm
+@@ -184,42 +184,50 @@ ifdef(`PIC',
+ 	jmp	*(%r10,%rax,8)
+ ')
+ 
+-L(mf0):	mulx(	8,(up), w2, w3)
++L(mf0):	X86_ENDBR
++	mulx(	8,(up), w2, w3)
+ 	lea	64(up), up
+ C	lea	(rp), rp
+ 	jmp	L(mb0)
+ 
+-L(mf3):	mulx(	8,(up), w0, w1)
++L(mf3):	X86_ENDBR
++	mulx(	8,(up), w0, w1)
+ 	lea	24(up), up
+ 	lea	24(rp), rp
+ 	jmp	L(mb3)
+ 
+-L(mf4):	mulx(	8,(up), w2, w3)
++L(mf4):	X86_ENDBR
++	mulx(	8,(up), w2, w3)
+ 	lea	32(up), up
+ 	lea	32(rp), rp
+ 	jmp	L(mb4)
+ 
+-L(mf5):	mulx(	8,(up), w0, w1)
++L(mf5):	X86_ENDBR
++	mulx(	8,(up), w0, w1)
+ 	lea	40(up), up
+ 	lea	40(rp), rp
+ 	jmp	L(mb5)
+ 
+-L(mf6):	mulx(	8,(up), w2, w3)
++L(mf6):	X86_ENDBR
++	mulx(	8,(up), w2, w3)
+ 	lea	48(up), up
+ 	lea	48(rp), rp
+ 	jmp	L(mb6)
+ 
+-L(mf7):	mulx(	8,(up), w0, w1)
++L(mf7):	X86_ENDBR
++	mulx(	8,(up), w0, w1)
+ 	lea	56(up), up
+ 	lea	56(rp), rp
+ 	jmp	L(mb7)
+ 
+-L(mf1):	mulx(	8,(up), w0, w1)
++L(mf1):	X86_ENDBR
++	mulx(	8,(up), w0, w1)
+ 	lea	8(up), up
+ 	lea	8(rp), rp
+ 	jmp	L(mb1)
+ 
+-L(mf2):	mulx(	8,(up), w2, w3)
++L(mf2):	X86_ENDBR
++	mulx(	8,(up), w2, w3)
+ 	lea	16(up), up
+ 	lea	16(rp), rp
+ 	dec	R32(n)
+@@ -275,7 +283,8 @@ L(ed0):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f7):	lea	-64(up,un_save,8), up
++L(f7):	X86_ENDBR
++	lea	-64(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	mov	8(up), u0
+ 	mulx(	16,(up), w0, w1)
+@@ -326,7 +335,8 @@ L(ed1):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f0):	lea	-64(up,un_save,8), up
++L(f0):	X86_ENDBR
++	lea	-64(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	mov	(up), u0
+ 	mulx(	8,(up), w2, w3)
+@@ -377,7 +387,8 @@ L(ed2):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f1):	lea	(up,un_save,8), up
++L(f1):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	lea	8(un_save), un_save
+ 	mov	-8(up), u0
+@@ -429,7 +440,8 @@ L(ed3):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f2):	lea	(up,un_save,8), up
++L(f2):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	jz	L(corner2)
+ 	mov	-16(up), u0
+@@ -482,7 +494,8 @@ L(ed4):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f3):	lea	(up,un_save,8), up
++L(f3):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	jz	L(corner3)
+ 	mov	-24(up), u0
+@@ -534,7 +547,8 @@ L(ed5):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f4):	lea	(up,un_save,8), up
++L(f4):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	mov	-32(up), u0
+ 	mulx(	-24,(up), w2, w3)
+@@ -585,7 +599,8 @@ L(ed6):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f5):	lea	(up,un_save,8), up
++L(f5):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	mov	-40(up), u0
+ 	mulx(	-32,(up), w0, w1)
+@@ -636,7 +651,8 @@ L(ed7):	adox(	(rp), w0)
+ 	mov	w0, (rp)
+ 	adc	%rcx, w1		C relies on rcx = 0
+ 	mov	w1, 8(rp)
+-L(f6):	lea	(up,un_save,8), up
++L(f6):	X86_ENDBR
++	lea	(up,un_save,8), up
+ 	or	R32(un_save), R32(n)
+ 	mov	-48(up), u0
+ 	mulx(	-40,(up), w2, w3)
+diff --git a/mpn/x86_64/k8/mul_basecase.asm b/mpn/x86_64/k8/mul_basecase.asm
+index 8b114ce8b..9126c2b80 100644
+--- a/mpn/x86_64/k8/mul_basecase.asm
++++ b/mpn/x86_64/k8/mul_basecase.asm
+@@ -335,8 +335,10 @@ C     addmul_2 for remaining vp's
+ 	C adjusted value of n that is reloaded on each iteration
+ 
+ L(addmul_outer_0):
++	X86_ENDBR
+ 	add	$3, un
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 
+ 	mov	un, n
+ 	mov	-24(up,un,8), %rax
+@@ -348,6 +350,7 @@ L(addmul_outer_0):
+ 	jmp	L(addmul_entry_0)
+ 
+ L(addmul_outer_1):
++	X86_ENDBR
+ 	mov	un, n
+ 	mov	(up,un,8), %rax
+ 	mul	v0
+@@ -358,8 +361,10 @@ L(addmul_outer_1):
+ 	jmp	L(addmul_entry_1)
+ 
+ L(addmul_outer_2):
++	X86_ENDBR
+ 	add	$1, un
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 
+ 	mov	un, n
+ 	mov	-8(up,un,8), %rax
+@@ -372,8 +377,10 @@ L(addmul_outer_2):
+ 	jmp	L(addmul_entry_2)
+ 
+ L(addmul_outer_3):
++	X86_ENDBR
+ 	add	$2, un
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 
+ 	mov	un, n
+ 	mov	-16(up,un,8), %rax
+diff --git a/mpn/x86_64/k8/mullo_basecase.asm b/mpn/x86_64/k8/mullo_basecase.asm
+index fc6a4396d..4a931a535 100644
+--- a/mpn/x86_64/k8/mullo_basecase.asm
++++ b/mpn/x86_64/k8/mullo_basecase.asm
+@@ -99,12 +99,14 @@ dnl	JMPENT(	L(2m4), L(tab))			C 10
+ dnl	JMPENT(	L(3m4), L(tab))			C 11
+ 	TEXT
+ 
+-L(1):	imul	%r8, %rax
++L(1):	X86_ENDBR
++	imul	%r8, %rax
+ 	mov	%rax, (rp)
+ 	FUNC_EXIT()
+ 	ret
+ 
+-L(2):	mov	8(vp_param), %r11
++L(2):	X86_ENDBR
++	mov	8(vp_param), %r11
+ 	imul	%rax, %r11		C u0 x v1
+ 	mul	%r8			C u0 x v0
+ 	mov	%rax, (rp)
+@@ -115,7 +117,8 @@ L(2):	mov	8(vp_param), %r11
+ 	FUNC_EXIT()
+ 	ret
+ 
+-L(3):	mov	8(vp_param), %r9	C v1
++L(3):	X86_ENDBR
++	mov	8(vp_param), %r9	C v1
+ 	mov	16(vp_param), %r11
+ 	mul	%r8			C u0 x v0 -> <r1,r0>
+ 	mov	%rax, (rp)		C r0
+@@ -335,6 +338,7 @@ L(mul_2_entry_1):
+ 
+ 
+ L(addmul_outer_1):
++	X86_ENDBR
+ 	lea	-2(n), j
+ 	mov	-16(up,n,8), %rax
+ 	mul	v0
+@@ -346,6 +350,7 @@ L(addmul_outer_1):
+ 	jmp	L(addmul_entry_1)
+ 
+ L(addmul_outer_3):
++	X86_ENDBR
+ 	lea	0(n), j
+ 	mov	-16(up,n,8), %rax
+ 	xor	R32(w3), R32(w3)
+diff --git a/mpn/x86_64/k8/mulmid_basecase.asm b/mpn/x86_64/k8/mulmid_basecase.asm
+index d7d1f27c6..7d5f1588f 100644
+--- a/mpn/x86_64/k8/mulmid_basecase.asm
++++ b/mpn/x86_64/k8/mulmid_basecase.asm
+@@ -329,6 +329,7 @@ C     addmul_2 for remaining vp's
+ 
+ 	ALIGN(16)
+ L(addmul_prologue_0):
++	X86_ENDBR
+ 	mov	-8(up,n,8), %rax
+ 	mul	v1
+ 	mov	%rax, w1
+@@ -338,6 +339,7 @@ L(addmul_prologue_0):
+ 
+ 	ALIGN(16)
+ L(addmul_prologue_1):
++	X86_ENDBR
+ 	mov	16(up,n,8), %rax
+ 	mul	v1
+ 	mov	%rax, w0
+@@ -348,6 +350,7 @@ L(addmul_prologue_1):
+ 
+ 	ALIGN(16)
+ L(addmul_prologue_2):
++	X86_ENDBR
+ 	mov	8(up,n,8), %rax
+ 	mul	v1
+ 	mov	%rax, w3
+@@ -357,6 +360,7 @@ L(addmul_prologue_2):
+ 
+ 	ALIGN(16)
+ L(addmul_prologue_3):
++	X86_ENDBR
+ 	mov	(up,n,8), %rax
+ 	mul	v1
+ 	mov	%rax, w2
+@@ -471,6 +475,7 @@ L(diag_prologue_0):
+ 	mov	vp, vp_inner
+ 	mov	vn, n
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 	mov     -8(up,n,8), %rax
+ 	jmp	L(diag_entry_0)
+ 
+@@ -480,6 +485,7 @@ L(diag_prologue_1):
+ 	add	$3, vn
+ 	mov	vn, n
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 	mov     -8(vp_inner), %rax
+ 	jmp	L(diag_entry_1)
+ 
+@@ -489,6 +495,7 @@ L(diag_prologue_2):
+ 	add	$2, vn
+ 	mov	vn, n
+ 	lea	0(%rip), outer_addr
++	X86_ENDBR
+ 	mov	16(vp_inner), %rax
+ 	jmp	L(diag_entry_2)
+ 
+@@ -507,6 +514,7 @@ L(diag_entry_0):
+ 	adc     %rdx, w1
+ 	adc     $0, w2
+ L(diag_entry_3):
++	X86_ENDBR
+ 	mov     -16(up,n,8), %rax
+ 	mulq    8(vp_inner)
+ 	add     %rax, w0
+diff --git a/mpn/x86_64/k8/redc_1.asm b/mpn/x86_64/k8/redc_1.asm
+index 4cb65af49..3e241af27 100644
+--- a/mpn/x86_64/k8/redc_1.asm
++++ b/mpn/x86_64/k8/redc_1.asm
+@@ -125,7 +125,8 @@ L(tab):	JMPENT(	L(0), L(tab))
+ 	TEXT
+ 
+ 	ALIGN(16)
+-L(1):	mov	(mp_param), %rax
++L(1):	X86_ENDBR
++	mov	(mp_param), %rax
+ 	mul	q0
+ 	add	8(up), %rax
+ 	adc	16(up), %rdx
+@@ -136,7 +137,8 @@ L(1):	mov	(mp_param), %rax
+ 
+ 
+ 	ALIGN(16)
+-L(2):	mov	(mp_param), %rax
++L(2):	X86_ENDBR
++	mov	(mp_param), %rax
+ 	mul	q0
+ 	xor	R32(%r14), R32(%r14)
+ 	mov	%rax, %r10
+@@ -171,7 +173,8 @@ L(2):	mov	(mp_param), %rax
+ 	jmp	L(ret)
+ 
+ 
+-L(3):	mov	(mp_param), %rax
++L(3):	X86_ENDBR
++	mov	(mp_param), %rax
+ 	mul	q0
+ 	mov	%rax, %rbx
+ 	mov	%rdx, %r10
+@@ -248,7 +251,7 @@ L(3):	mov	(mp_param), %rax
+ 
+ 
+ 	ALIGN(16)
+-L(2m4):
++L(2m4):	X86_ENDBR
+ L(lo2):	mov	(mp,nneg,8), %rax
+ 	mul	q0
+ 	xor	R32(%r14), R32(%r14)
+@@ -324,7 +327,7 @@ L(le2):	add	%r10, (up)
+ 
+ 
+ 	ALIGN(16)
+-L(1m4):
++L(1m4):	X86_ENDBR
+ L(lo1):	mov	(mp,nneg,8), %rax
+ 	xor	%r9, %r9
+ 	xor	R32(%rbx), R32(%rbx)
+@@ -398,7 +401,7 @@ L(le1):	add	%r10, (up)
+ 
+ 	ALIGN(16)
+ L(0):
+-L(0m4):
++L(0m4):	X86_ENDBR
+ L(lo0):	mov	(mp,nneg,8), %rax
+ 	mov	nneg, i
+ 	mul	q0
+@@ -463,7 +466,7 @@ L(le0):	add	%r10, (up)
+ 
+ 
+ 	ALIGN(16)
+-L(3m4):
++L(3m4):	X86_ENDBR
+ L(lo3):	mov	(mp,nneg,8), %rax
+ 	mul	q0
+ 	mov	%rax, %rbx
+diff --git a/mpn/x86_64/k8/sqr_basecase.asm b/mpn/x86_64/k8/sqr_basecase.asm
+index f2c70b06b..37858b497 100644
+--- a/mpn/x86_64/k8/sqr_basecase.asm
++++ b/mpn/x86_64/k8/sqr_basecase.asm
+@@ -131,7 +131,8 @@ L(tab):	JMPENT(	L(4), L(tab))
+ 	JMPENT(	L(3m4), L(tab))
+ 	TEXT
+ 
+-L(1):	mov	(up), %rax
++L(1):	X86_ENDBR
++	mov	(up), %rax
+ 	mul	%rax
+ 	add	$40, %rsp
+ 	mov	%rax, (rp)
+@@ -139,7 +140,8 @@ L(1):	mov	(up), %rax
+ 	FUNC_EXIT()
+ 	ret
+ 
+-L(2):	mov	(up), %rax
++L(2):	X86_ENDBR
++	mov	(up), %rax
+ 	mov	%rax, %r8
+ 	mul	%rax
+ 	mov	8(up), %r11
+@@ -165,7 +167,8 @@ L(2):	mov	(up), %rax
+ 	FUNC_EXIT()
+ 	ret
+ 
+-L(3):	mov	(up), %rax
++L(3):	X86_ENDBR
++	mov	(up), %rax
+ 	mov	%rax, %r10
+ 	mul	%rax
+ 	mov	8(up), %r11
+@@ -210,7 +213,8 @@ L(3):	mov	(up), %rax
+ 	FUNC_EXIT()
+ 	ret
+ 
+-L(4):	mov	(up), %rax
++L(4):	X86_ENDBR
++	mov	(up), %rax
+ 	mov	%rax, %r11
+ 	mul	%rax
+ 	mov	8(up), %rbx
+@@ -282,6 +286,7 @@ L(4):	mov	(up), %rax
+ 
+ 
+ L(0m4):
++	X86_ENDBR
+ 	lea	-16(rp,n,8), tp		C point tp in middle of result operand
+ 	mov	(up), v0
+ 	mov	8(up), %rax
+@@ -340,6 +345,7 @@ L(L3):	xor	R32(w1), R32(w1)
+ 
+ 
+ L(1m4):
++	X86_ENDBR
+ 	lea	8(rp,n,8), tp		C point tp in middle of result operand
+ 	mov	(up), v0		C u0
+ 	mov	8(up), %rax		C u1
+@@ -418,6 +424,7 @@ L(m2x):	mov	(up,j,8), %rax
+ 
+ 
+ L(2m4):
++	X86_ENDBR
+ 	lea	-16(rp,n,8), tp		C point tp in middle of result operand
+ 	mov	(up), v0
+ 	mov	8(up), %rax
+@@ -474,7 +481,7 @@ L(L1):	xor	R32(w0), R32(w0)
+ 	jmp	L(dowhile_mid)
+ 
+ 
+-L(3m4):
++L(3m4):	X86_ENDBR
+ 	lea	8(rp,n,8), tp		C point tp in middle of result operand
+ 	mov	(up), v0		C u0
+ 	mov	8(up), %rax		C u1
+diff --git a/mpn/x86_64/mod_34lsub1.asm b/mpn/x86_64/mod_34lsub1.asm
+index 065a731cc..61bb76f73 100644
+--- a/mpn/x86_64/mod_34lsub1.asm
++++ b/mpn/x86_64/mod_34lsub1.asm
+@@ -135,46 +135,55 @@ L(tab):	JMPENT(	L(0), L(tab))
+ 	JMPENT(	L(8), L(tab))
+ 	TEXT
+ 
+-L(6):	add	(ap), %rax
++L(6):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	adc	$0, %r9
+ 	add	$24, ap
+-L(3):	add	(ap), %rax
++L(3):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	jmp	L(cj1)
+ 
+-L(7):	add	(ap), %rax
++L(7):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	adc	$0, %r9
+ 	add	$24, ap
+-L(4):	add	(ap), %rax
++L(4):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	adc	$0, %r9
+ 	add	$24, ap
+-L(1):	add	(ap), %rax
++L(1):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	$0, %rcx
+ 	jmp	L(cj2)
+ 
+-L(8):	add	(ap), %rax
++L(8):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	adc	$0, %r9
+ 	add	$24, ap
+-L(5):	add	(ap), %rax
++L(5):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 	adc	16(ap), %rdx
+ 	adc	$0, %r9
+ 	add	$24, ap
+-L(2):	add	(ap), %rax
++L(2):	X86_ENDBR
++	add	(ap), %rax
+ 	adc	8(ap), %rcx
+ 
+ L(cj2):	adc	$0, %rdx
+ L(cj1):	adc	$0, %r9
+-L(0):	add	%r9, %rax
++L(0):	X86_ENDBR
++	add	%r9, %rax
+ 	adc	$0, %rcx
+ 	adc	$0, %rdx
+ 	adc	$0, %rax
+-- 
+2.24.1
+
diff --git a/0008-x86-aors_n.asm-Add-X86_ENDBR-to-indirect-jump-target.patch b/0008-x86-aors_n.asm-Add-X86_ENDBR-to-indirect-jump-target.patch
new file mode 100644
index 0000000..e99349e
--- /dev/null
+++ b/0008-x86-aors_n.asm-Add-X86_ENDBR-to-indirect-jump-target.patch
@@ -0,0 +1,130 @@
+From e031819595df547725bfe41d88915ba2a1d822ed Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Wed, 29 Jan 2020 20:10:12 -0800
+Subject: [PATCH 08/11] x86/aors_n.asm: Add X86_ENDBR to indirect jump targets
+
+x86/aors_n.asm uses a trick to implment jump tables with LEA.  We can't
+use conditional branches nor normal jump tables since jump table entries
+use EFLAGS set by jump table index.  This patch adds X86_ENDBR to indirect
+jump targets and adjust destination for X86_ENDBR.
+
+	* mpn/x86/aors_n.asm: Save and restore %ebx if X86_ENDBR is
+	endbr32.  Add X86_ENDBR to indirect jump targets and adjust
+	jump destination for X86_ENDBR.
+---
+ mpn/x86/aors_n.asm | 32 ++++++++++++++++++++++++++++++++
+ 1 file changed, 32 insertions(+)
+
+diff --git a/mpn/x86/aors_n.asm b/mpn/x86/aors_n.asm
+index 95d006a5a..94fa16ed8 100644
+--- a/mpn/x86/aors_n.asm
++++ b/mpn/x86/aors_n.asm
+@@ -80,6 +80,9 @@ deflit(`FRAME',0)
+ 	movl	PARAM_SRC2,%edx
+ 	movl	PARAM_SIZE,%ecx
+ 
++ifelse(X86_ENDBR,`endbr32',
++`	pushl	%ebx		FRAME_pushl()')
++
+ 	movl	%ecx,%eax
+ 	shrl	$3,%ecx			C compute count for unrolled loop
+ 	negl	%eax
+@@ -92,6 +95,10 @@ deflit(`FRAME',0)
+ 	subl	%eax,%edx		C ... enter the loop
+ 	shrl	$2,%eax			C restore previous value
+ 
++	C Count for 4-byte endbr32.
++ifelse(X86_ENDBR,`endbr32',
++`	leal	-4(,%eax,4),%ebx')
++
+ ifdef(`PIC',`
+ 	C Calculate start address in loop for PIC.  Due to limitations in
+ 	C old gas, LF(M4_function_n,oop)-L(0a)-3 cannot be put into the leal
+@@ -105,6 +112,10 @@ L(0a):	leal	(%eax,%eax,8),%eax
+ 	leal	L(oop)-3(%eax,%eax,8),%eax
+ ')
+ 
++	C Adjust for endbr32
++ifelse(X86_ENDBR,`endbr32',
++`	addl	%ebx,%eax')
++
+ 	C These lines initialize carry from the 5th parameter.  Should be
+ 	C possible to simplify.
+ 	pushl	%ebp		FRAME_pushl()
+@@ -129,6 +140,9 @@ deflit(`FRAME',0)
+ 	movl	PARAM_SRC2,%edx
+ 	movl	PARAM_SIZE,%ecx
+ 
++ifelse(X86_ENDBR,`endbr32',
++`	pushl	%ebx		FRAME_pushl()')
++
+ 	movl	%ecx,%eax
+ 	shrl	$3,%ecx			C compute count for unrolled loop
+ 	negl	%eax
+@@ -141,6 +155,10 @@ deflit(`FRAME',0)
+ 	subl	%eax,%edx		C ... enter the loop
+ 	shrl	$2,%eax			C restore previous value
+ 
++	C Count for 4-byte endbr32.
++ifelse(X86_ENDBR,`endbr32',
++`	leal	-4(,%eax,4),%ebx')
++
+ ifdef(`PIC',`
+ 	C Calculate start address in loop for PIC.  Due to limitations in
+ 	C some assemblers, L(oop)-L(0b)-3 cannot be put into the leal
+@@ -153,6 +171,10 @@ L(0b):	leal	(%eax,%eax,8),%eax
+ 	C Calculate start address in loop for non-PIC.
+ 	leal	L(oop)-3(%eax,%eax,8),%eax
+ ')
++	C Adjust for endbr32
++ifelse(X86_ENDBR,`endbr32',
++`	addl	%ebx,%eax')
++
+ 	jmp	*%eax			C jump into loop
+ 
+ L(oopgo):
+@@ -165,24 +187,31 @@ L(oopgo):
+ L(oop):	movl	(%esi),%eax
+ 	M4_inst	(%edx),%eax
+ 	movl	%eax,(%edi)
++	X86_ENDBR
+ 	movl	4(%esi),%eax
+ 	M4_inst	4(%edx),%eax
+ 	movl	%eax,4(%edi)
++	X86_ENDBR
+ 	movl	8(%esi),%eax
+ 	M4_inst	8(%edx),%eax
+ 	movl	%eax,8(%edi)
++	X86_ENDBR
+ 	movl	12(%esi),%eax
+ 	M4_inst	12(%edx),%eax
+ 	movl	%eax,12(%edi)
++	X86_ENDBR
+ 	movl	16(%esi),%eax
+ 	M4_inst	16(%edx),%eax
+ 	movl	%eax,16(%edi)
++	X86_ENDBR
+ 	movl	20(%esi),%eax
+ 	M4_inst	20(%edx),%eax
+ 	movl	%eax,20(%edi)
++	X86_ENDBR
+ 	movl	24(%esi),%eax
+ 	M4_inst	24(%edx),%eax
+ 	movl	%eax,24(%edi)
++	X86_ENDBR
+ 	movl	28(%esi),%eax
+ 	M4_inst	28(%edx),%eax
+ 	movl	%eax,28(%edi)
+@@ -195,6 +224,9 @@ L(oop):	movl	(%esi),%eax
+ 	sbbl	%eax,%eax
+ 	negl	%eax
+ 
++ifelse(X86_ENDBR,`endbr32',
++`	popl	%ebx')
++
+ 	popl	%esi
+ 	popl	%edi
+ 	ret
+-- 
+2.24.1
+
diff --git a/0009-x86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch b/0009-x86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch
new file mode 100644
index 0000000..a33e93f
--- /dev/null
+++ b/0009-x86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch
@@ -0,0 +1,90 @@
+From 5462be715a566ab5ecb5d9471c785c56ebd1dce6 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 03:24:52 -0800
+Subject: [PATCH 09/11] x86/p6: Prepend X86_NOTRACK to "jmp *%reg"
+
+Since some P6 .asm files uses a trick to implment jump tables with LEA,
+prepend X86_NOTRACK to "jmp *%reg" to disable indirect branch tracking
+when Intel CET is enabled.
+
+	* mpn/x86/p6/aors_n.asm: Prepend X86_NOTRACK to "jmp *%reg".
+	* mpn/x86/p6/aorsmul_1.asm: Likewise.
+	* mpn/x86/p6/lshsub_n.asm: Likewise.
+	* mpn/x86/p6/mul_basecase.asm: Likewise.
+	* mpn/x86/p6/sqr_basecase.asm: Likewise.
+---
+ mpn/x86/p6/aors_n.asm       | 2 +-
+ mpn/x86/p6/aorsmul_1.asm    | 2 +-
+ mpn/x86/p6/lshsub_n.asm     | 2 +-
+ mpn/x86/p6/mul_basecase.asm | 2 +-
+ mpn/x86/p6/sqr_basecase.asm | 2 +-
+ 5 files changed, 5 insertions(+), 5 deletions(-)
+
+diff --git a/mpn/x86/p6/aors_n.asm b/mpn/x86/p6/aors_n.asm
+index b4a32150f..ab172df7e 100644
+--- a/mpn/x86/p6/aors_n.asm
++++ b/mpn/x86/p6/aors_n.asm
+@@ -90,7 +90,7 @@ L(here):
+ ')
+ 
+ 	shr	%edx				C set cy flag
+-	jmp	*%eax
++	X86_NOTRACK jmp	*%eax
+ 
+ ifdef(`PIC',`
+ L(pic_calc):
+diff --git a/mpn/x86/p6/aorsmul_1.asm b/mpn/x86/p6/aorsmul_1.asm
+index d6bc549e3..2a3b122ee 100644
+--- a/mpn/x86/p6/aorsmul_1.asm
++++ b/mpn/x86/p6/aorsmul_1.asm
+@@ -240,7 +240,7 @@ L(here):
+ 	cmovnz(	%ebx, %ecx)	C high,low carry other way around
+ 	cmovnz(	%eax, %ebx)
+ 
+-	jmp	*%edx
++	X86_NOTRACK jmp	*%edx
+ 
+ 
+ ifdef(`PIC',`
+diff --git a/mpn/x86/p6/lshsub_n.asm b/mpn/x86/p6/lshsub_n.asm
+index 2ceb98bd8..17db5d5e0 100644
+--- a/mpn/x86/p6/lshsub_n.asm
++++ b/mpn/x86/p6/lshsub_n.asm
+@@ -82,7 +82,7 @@ L(here):
+ 	pxor	%mm1, %mm1
+ 	pxor	%mm0, %mm0
+ 
+-	jmp	*%eax
++	X86_NOTRACK jmp	*%eax
+ 
+ ifdef(`PIC',`
+ L(pic_calc):
+diff --git a/mpn/x86/p6/mul_basecase.asm b/mpn/x86/p6/mul_basecase.asm
+index 03ae0d6b2..521b31e01 100644
+--- a/mpn/x86/p6/mul_basecase.asm
++++ b/mpn/x86/p6/mul_basecase.asm
+@@ -524,7 +524,7 @@ L(unroll_outer_entry):
+ 	xorl	%eax, %ebx		C carries other way for odd index
+ 	xorl	%eax, %ecx
+ 
+-	jmp	*%edx
++	X86_NOTRACK jmp	*%edx
+ 
+ 
+ C -----------------------------------------------------------------------------
+diff --git a/mpn/x86/p6/sqr_basecase.asm b/mpn/x86/p6/sqr_basecase.asm
+index ca29e8084..f71304f39 100644
+--- a/mpn/x86/p6/sqr_basecase.asm
++++ b/mpn/x86/p6/sqr_basecase.asm
+@@ -447,7 +447,7 @@ define(cmovX,`ifelse(eval(UNROLL_COUNT%2),1,`cmovz($@)',`cmovnz($@)')')
+ 	cmovX(	%ebx, %ecx)	C high carry reverse
+ 	cmovX(	%eax, %ebx)	C low carry reverse
+ 	movl	%edx, VAR_JMP
+-	jmp	*%edx
++	X86_NOTRACK jmp	*%edx
+ 
+ 
+ 	C Must be on an even address here so the low bit of the jump address
+-- 
+2.24.1
+
diff --git a/0010-x86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch b/0010-x86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch
new file mode 100644
index 0000000..59d1f43
--- /dev/null
+++ b/0010-x86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch
@@ -0,0 +1,60 @@
+From ae92ea1b8c9846a9d966aa8186b473a11d52c615 Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:00:13 -0800
+Subject: [PATCH 10/11] x86/k6: Prepend X86_NOTRACK to "jmp *%reg"
+
+Since some K6 .asm files uses a trick to implment jump tables with LEA,
+prepend X86_NOTRACK to "jmp *%reg" to disable indirect branch tracking
+when Intel CET is enabled.
+
+	* mpn/x86/k6/aorsmul_1.asm: Prepend X86_NOTRACK to "jmp *%reg".
+	* mpn/x86/k6/mul_basecase.asm: Likewise.
+	* mpn/x86/k6/sqr_basecase.asm: Likewise.
+---
+ mpn/x86/k6/aorsmul_1.asm    | 2 +-
+ mpn/x86/k6/mul_basecase.asm | 2 +-
+ mpn/x86/k6/sqr_basecase.asm | 2 +-
+ 3 files changed, 3 insertions(+), 3 deletions(-)
+
+diff --git a/mpn/x86/k6/aorsmul_1.asm b/mpn/x86/k6/aorsmul_1.asm
+index 78be9d250..018644d15 100644
+--- a/mpn/x86/k6/aorsmul_1.asm
++++ b/mpn/x86/k6/aorsmul_1.asm
+@@ -321,7 +321,7 @@ L(here):
+ 	movl	%eax, %esi
+ L(noswap):
+ 
+-	jmp	*%edx
++	X86_NOTRACK jmp	*%edx
+ 
+ 
+ ifdef(`PIC',`
+diff --git a/mpn/x86/k6/mul_basecase.asm b/mpn/x86/k6/mul_basecase.asm
+index ab202a2ce..0022894aa 100644
+--- a/mpn/x86/k6/mul_basecase.asm
++++ b/mpn/x86/k6/mul_basecase.asm
+@@ -542,7 +542,7 @@ L(unroll_outer_entry):
+ 	movl	%edx, %ecx
+ L(unroll_noswap):
+ 
+-	jmp	*%eax
++	X86_NOTRACK jmp	*%eax
+ 
+ 
+ 
+diff --git a/mpn/x86/k6/sqr_basecase.asm b/mpn/x86/k6/sqr_basecase.asm
+index f3a101a0f..f4b8df414 100644
+--- a/mpn/x86/k6/sqr_basecase.asm
++++ b/mpn/x86/k6/sqr_basecase.asm
+@@ -467,7 +467,7 @@ ifelse(eval(UNROLL_COUNT%2),0,
+ 	movl	%eax, %ecx
+ L(unroll_noswap):
+ 
+-	jmp	*%edx
++	X86_NOTRACK jmp	*%edx
+ 
+ 
+ 	C Must be on an even address here so the low bit of the jump address
+-- 
+2.24.1
+
diff --git a/0011-x86-k7-Prepend-X86_NOTRACK-to-indirect-branches.patch b/0011-x86-k7-Prepend-X86_NOTRACK-to-indirect-branches.patch
new file mode 100644
index 0000000..78c6b3d
--- /dev/null
+++ b/0011-x86-k7-Prepend-X86_NOTRACK-to-indirect-branches.patch
@@ -0,0 +1,90 @@
+From d8c0f42618c119113ce4055f2822f9579ef8402d Mon Sep 17 00:00:00 2001
+From: "H.J. Lu" <hjl.tools@gmail.com>
+Date: Thu, 30 Jan 2020 04:01:45 -0800
+Subject: [PATCH 11/11] x86/k7: Prepend X86_NOTRACK to indirect branches
+
+Since some K7 .asm files uses a trick to implment jump tables with LEA,
+prepend X86_NOTRACK to indirect branches to disable indirect branch
+tracking when Intel CET is enabled.
+
+	* mpn/x86/k7/aors_n.asm: Prepend X86_NOTRACK to indirect branches.
+	* mpn/x86/k7/mmx/lshift.asm: Likewise.
+	* mpn/x86/k7/mmx/rshift.asm: Likewise.
+	* mpn/x86/k7/mul_basecase.asm: Likewise.
+	* mpn/x86/k7/sqr_basecase.asm: Likewise.
+---
+ mpn/x86/k7/aors_n.asm       | 2 +-
+ mpn/x86/k7/mmx/lshift.asm   | 2 +-
+ mpn/x86/k7/mmx/rshift.asm   | 2 +-
+ mpn/x86/k7/mul_basecase.asm | 2 +-
+ mpn/x86/k7/sqr_basecase.asm | 2 +-
+ 5 files changed, 5 insertions(+), 5 deletions(-)
+
+diff --git a/mpn/x86/k7/aors_n.asm b/mpn/x86/k7/aors_n.asm
+index bfdf3d40a..b3def5df6 100644
+--- a/mpn/x86/k7/aors_n.asm
++++ b/mpn/x86/k7/aors_n.asm
+@@ -188,7 +188,7 @@ L(here):
+ 	leal	ifelse(UNROLL_BYTES,256,128) (%edx,%edi,4), %edx
+ 	leal	ifelse(UNROLL_BYTES,256,128) (%ebp,%edi,4), %edi
+ 
+-	jmp	*%esi
++	X86_NOTRACK jmp	*%esi
+ 
+ 
+ ifdef(`PIC',`
+diff --git a/mpn/x86/k7/mmx/lshift.asm b/mpn/x86/k7/mmx/lshift.asm
+index 4140e82bb..77bc86ed2 100644
+--- a/mpn/x86/k7/mmx/lshift.asm
++++ b/mpn/x86/k7/mmx/lshift.asm
+@@ -280,7 +280,7 @@ L(here):
+ 	leal	ifelse(UNROLL_BYTES,256,128) -8(%edx,%eax,2), %edx
+ 	leal	ifelse(UNROLL_BYTES,256,128) (%edi,%eax,2), %edi
+ 	movl	PARAM_SIZE, %eax	C for use at end
+-	jmp	*%esi
++	X86_NOTRACK jmp	*%esi
+ 
+ 
+ ifdef(`PIC',`
+diff --git a/mpn/x86/k7/mmx/rshift.asm b/mpn/x86/k7/mmx/rshift.asm
+index 0da1f9341..8119adc1c 100644
+--- a/mpn/x86/k7/mmx/rshift.asm
++++ b/mpn/x86/k7/mmx/rshift.asm
+@@ -280,7 +280,7 @@ L(here):
+ 	leal	ifelse(UNROLL_BYTES,256,128) (%edi,%eax,2), %edi
+ 	movl	PARAM_SIZE, %eax	C for use at end
+ 
+-	jmp	*%esi
++	X86_NOTRACK jmp	*%esi
+ 
+ 
+ ifdef(`PIC',`
+diff --git a/mpn/x86/k7/mul_basecase.asm b/mpn/x86/k7/mul_basecase.asm
+index b96fda7e0..1e352cd6d 100644
+--- a/mpn/x86/k7/mul_basecase.asm
++++ b/mpn/x86/k7/mul_basecase.asm
+@@ -511,7 +511,7 @@ L(unroll_outer_entry):
+ 	cmovnz(	%eax, %ebx)
+ 
+ 	C Extra fetch of VAR_JMP is bad, but registers are tight
+-	jmp	*VAR_JMP
++	X86_NOTRACK jmp	*VAR_JMP
+ 
+ 
+ C -----------------------------------------------------------------------------
+diff --git a/mpn/x86/k7/sqr_basecase.asm b/mpn/x86/k7/sqr_basecase.asm
+index df47ee421..0f79ef015 100644
+--- a/mpn/x86/k7/sqr_basecase.asm
++++ b/mpn/x86/k7/sqr_basecase.asm
+@@ -425,7 +425,7 @@ define(cmovX,`ifelse(eval(UNROLL_COUNT%2),0,`cmovz($@)',`cmovnz($@)')')
+ 
+ 	movl	%eax, VAR_JMP
+ 
+-	jmp	*%eax
++	X86_NOTRACK jmp	*%eax
+ 
+ 
+ ifdef(`PIC',`
+-- 
+2.24.1
+
diff --git a/gmp.spec b/gmp.spec
index 7b67303..3c48c49 100644
--- a/gmp.spec
+++ b/gmp.spec
@@ -1,3 +1,15 @@
+Patch100001: 0001-x86-Add-GMP_ASM_X86_CET_MACROS-to-acinclude.m4.patch
+Patch100002: 0002-x86-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
+Patch100003: 0003-x86-ppend-missing-ASM_END-to-asm-files.patch
+Patch100004: 0004-x86_64-defs.m4-Use-X86_GNU_PROPERTY-and-X86_ENDBR.patch
+Patch100005: 0005-x86_64-Append-ASM_END-to-assembly-codes.patch
+Patch100006: 0006-x86_64-k10-popcount.asm-Prepend-X86_NOTRACK-to-jmp-r.patch
+Patch100007: 0007-mpn-x86_64-Add-X86_ENDBR-to-indirect-branch-targets.patch
+Patch100008: 0008-x86-aors_n.asm-Add-X86_ENDBR-to-indirect-jump-target.patch
+Patch100009: 0009-x86-p6-Prepend-X86_NOTRACK-to-jmp-reg.patch
+Patch100010: 0010-x86-k6-Prepend-X86_NOTRACK-to-jmp-reg.patch
+Patch100011: 0011-x86-k7-Prepend-X86_NOTRACK-to-indirect-branches.patch
+
 #
 # Important for %%{ix86}:
 # This rpm has to be build on a CPU with sse2 support like Pentium 4 !
-- 
2.25.1

